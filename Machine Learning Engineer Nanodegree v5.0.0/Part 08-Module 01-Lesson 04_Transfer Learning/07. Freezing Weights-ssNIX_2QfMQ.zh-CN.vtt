WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.580
在上一步

00:00:01.580 --> 00:00:04.570
我加载了具有预训练权重的 VGG 模型

00:00:04.570 --> 00:00:06.505
现在我要执行两个任务

00:00:06.505 --> 00:00:09.550
首先 我要冻结 features 层级中的权重

00:00:09.550 --> 00:00:13.865
因此在训练期间 所有预训练的卷积权重将不变

00:00:13.865 --> 00:00:16.830
VGG 网络的这部分将充当固定特征提取器

00:00:16.830 --> 00:00:21.100
并以相同的方式应用到所有输入图像上

00:00:21.100 --> 00:00:22.710
接下来 我将最后的线性层级

00:00:22.710 --> 00:00:26.375
替换为一个输出 5 个类别分数的层级

00:00:26.375 --> 00:00:28.920
并训练这 3 个全连接层

00:00:28.920 --> 00:00:31.315
下拉 我们先解决第一个任务

00:00:31.315 --> 00:00:33.085
即冻结一些预训练的权重

00:00:33.085 --> 00:00:34.855
要冻结卷积权重

00:00:34.855 --> 00:00:39.715
我将遍历 VGG features 参数列表中的每个参数

00:00:39.715 --> 00:00:42.650
features 是指

00:00:42.650 --> 00:00:45.540
包含所有卷积层和池化层的一组层级的名称

00:00:45.540 --> 00:00:47.600
对于每个权重

00:00:47.600 --> 00:00:50.160
require_grad 属性为 false

00:00:50.160 --> 00:00:53.360
在训练期间 PyTorch 会自动跟踪

00:00:53.360 --> 00:00:56.935
训练损失相对于模型权重的梯度

00:00:56.935 --> 00:00:59.225
但是如果将这个属性设为 false

00:00:59.225 --> 00:01:03.690
这些权重将被忽略并且在计算梯度时不会考虑它们

00:01:03.690 --> 00:01:06.950
换句话说 通过将这个参数属性设为 false

00:01:06.950 --> 00:01:10.905
我们冻结了这些权重 它们将保留预训练的值

00:01:10.905 --> 00:01:14.480
接下来 由你来更改模型的最后一个层级

00:01:14.480 --> 00:01:17.060
你学习过的知识应该足以完成这个任务

00:01:17.060 --> 00:01:21.420
你只需按照名称和编号引用这个最后全连接层

00:01:21.420 --> 00:01:23.975
并将它设为新的线性层级

00:01:23.975 --> 00:01:27.090
新线性层级具有正确的输入数量和 5 个输出

00:01:27.090 --> 00:01:28.720
要定义一个层级

00:01:28.720 --> 00:01:33.730
你要使用 nn.linear，就像在 net 类的 init 函数中定义层级一样

00:01:33.730 --> 00:01:36.215
这部分将由你来完成

00:01:36.215 --> 00:01:38.405
我还布置了一道练习

00:01:38.405 --> 00:01:40.595
我将这个训练循环留空了

00:01:40.595 --> 00:01:43.519
我们已演示过好几个训练循环示例

00:01:43.519 --> 00:01:45.580
请你参考前面的课程内容

00:01:45.580 --> 00:01:46.700
或凭记忆编写一个

00:01:46.700 --> 00:01:50.510
遍历训练数据的周期和批次循环

00:01:50.510 --> 00:01:54.110
此外 请记录训练损失并输出损失

00:01:54.110 --> 00:01:57.600
接下来我将演示如何添加最后的层级并训练整个模型

