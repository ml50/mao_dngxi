WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:06.135
我们已经加载了预训练的 vgg16 模型并冻结了 features 参数

00:00:06.135 --> 00:00:08.970
下个任务是替换模型的最后层级

00:00:08.970 --> 00:00:11.795
以便针对 5 个花朵类别输出 5 个值

00:00:11.795 --> 00:00:14.965
而不是输出一千个类别

00:00:14.965 --> 00:00:17.365
几行代码就能搞定

00:00:17.365 --> 00:00:21.030
首先 我需要获取要更改层级的信息

00:00:21.030 --> 00:00:24.645
我将用名称引用它 输入 vgg16.classifier[6]

00:00:24.645 --> 00:00:26.660
输出模型架构后发现

00:00:26.660 --> 00:00:28.410
classifier 包含 3 个最终全连接层

00:00:28.410 --> 00:00:33.440
6 指向最后的线性层级

00:00:33.440 --> 00:00:36.810
现在我需要定义一个新的线性层级

00:00:36.810 --> 00:00:40.200
输入数量和现有最后层级的输入特征数量一样

00:00:40.200 --> 00:00:43.500
我将这个输入数量另存为 n_inputs

00:00:43.500 --> 00:00:45.860
然后定义新的最后层级

00:00:45.860 --> 00:00:49.850
使用 nn 库照常定义线性层级

00:00:49.850 --> 00:00:52.475
它的输入参数是 n_inputs

00:00:52.475 --> 00:00:55.245
生成的输出数量和类别数量一样

00:00:55.245 --> 00:00:57.430
这个长度应该为 5

00:00:57.430 --> 00:01:00.320
引用我要替换的这个最后层级

00:01:00.320 --> 00:01:03.900
并将其设为刚刚定义的 last_ayer

00:01:03.900 --> 00:01:07.320
这样就会将旧层级替换为新层级

00:01:07.320 --> 00:01:09.875
现在已经创建了完整的 VGG 16 模型

00:01:09.875 --> 00:01:12.470
如果 GPU 可用 则将整个模型移到 GPU 上

00:01:12.470 --> 00:01:16.460
最后输出这个层级的输出特征数量

00:01:16.460 --> 00:01:18.350
检查代码是否正确

00:01:18.350 --> 00:01:22.785
可以看到生成了 5 个输出 和预期的一样

00:01:22.785 --> 00:01:26.780
接下来准备训练整个模型

00:01:26.780 --> 00:01:30.230
我将照常定义损失和优化函数

00:01:30.230 --> 00:01:32.930
但是这次在优化器中

00:01:32.930 --> 00:01:36.335
我仅传入 classifier 的参数

00:01:36.335 --> 00:01:40.510
在训练期间 我只想更改这些 classifier 参数

00:01:40.510 --> 00:01:42.340
然后是训练循环

00:01:42.340 --> 00:01:46.280
建议在 GPU 上训练以加快速度

00:01:46.280 --> 00:01:50.480
因为这个网络依然包含很多参数 即使全连接层也如此

00:01:50.480 --> 00:01:52.775
我只训练 2 个周期

00:01:52.775 --> 00:01:54.530
因为此模型已预训练

00:01:54.530 --> 00:01:56.810
因此只需训练一小会儿

00:01:56.810 --> 00:01:59.675
就能让它适合处理花朵分类任务

00:01:59.675 --> 00:02:03.110
在训练循环里跟踪损失

00:02:03.110 --> 00:02:09.260
第一步是将所有数据移到 GPU 上 然后清理累积的梯度

00:02:09.260 --> 00:02:13.115
然后将图像数据传入 VGG 16 网络

00:02:13.115 --> 00:02:15.630
生成类别分数

00:02:15.630 --> 00:02:18.785
在这里计算交叉熵损失

00:02:18.785 --> 00:02:21.950
并执行一个优化步骤以更改网络权重

00:02:21.950 --> 00:02:25.730
这一步仅附加到 VGG 模型的最后几个层级

00:02:25.730 --> 00:02:27.690
其他权重保持不变

00:02:27.690 --> 00:02:32.210
在这里更新训练损失并每隔 20 个周期输出损失

00:02:32.210 --> 00:02:37.100
可以看出 损失一开始很小 并且起伏不定地降低

00:02:37.100 --> 00:02:40.115
有时候损失会升高 然后再降低

00:02:40.115 --> 00:02:43.900
看看训练两个周期之后效果如何

00:02:43.900 --> 00:02:46.790
在这里遍历测试数据

00:02:46.790 --> 00:02:49.595
检查模型在五个类别上的效果如何

00:02:49.595 --> 00:02:55.450
仅训练两个周期之后 模型的准确率就达到了 74%

00:02:55.450 --> 00:02:57.440
虽然数据集很小

00:02:57.440 --> 00:02:59.330
但是我已成功地将 VGG 网络的经验

00:02:59.330 --> 00:03:03.765
迁移到了这个特定的花朵分类任务上

00:03:03.765 --> 00:03:06.420
我们直观地看看效果

00:03:06.420 --> 00:03:10.345
这些是分类正确和错误的花朵图像

00:03:10.345 --> 00:03:12.500
可以看到迁移学习成功了

00:03:12.500 --> 00:03:14.750
虽然 VGG 一开始

00:03:14.750 --> 00:03:17.670
训练识别一千个不同的图像

00:03:17.670 --> 00:03:20.750
但是它通过寻找颜色和几何图案区分这些图像的经验

00:03:20.750 --> 00:03:25.810
也迁移到了区分花朵图像上

00:03:25.810 --> 00:03:28.280
可以看出模型未能识别的某些图像

00:03:28.280 --> 00:03:31.415
对我们来说也很难识别

00:03:31.415 --> 00:03:35.600
你可以尝试对很多模型应用迁移学习

00:03:35.600 --> 00:03:40.715
甚至可以训练更长的时间或微调整个模型

00:03:40.715 --> 00:03:42.890
请参阅可用的预训练模型的文档

00:03:42.890 --> 00:03:47.055
并尝试自己创建应用场景

00:03:47.055 --> 00:03:49.970
你甚至可以拓展这个示例

00:03:49.970 --> 00:03:53.135
并为园艺家创建种子与花朵模型

00:03:53.135 --> 00:03:57.230
现实中各式各样的数据提供了各种可能性

00:03:57.230 --> 00:04:00.020
你可以利用这些数据训练模型

00:04:00.020 --> 00:04:02.470
充分发挥想象力吧

