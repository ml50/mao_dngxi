WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.360
Ok下面我们在代码中实现迁移学习

00:00:03.360 --> 00:00:05.265
在此 notebook 中 我将使用预训练的 VGG 16 网络

00:00:05.265 --> 00:00:09.330
它的结构如图所示

00:00:09.330 --> 00:00:12.735
我会将它的经验应用到全新的任务上

00:00:12.735 --> 00:00:17.120
我们知道此模型由一系列卷积层和池化层组成

00:00:17.120 --> 00:00:21.690
最后有三个全连接层 充当最终分类器

00:00:21.690 --> 00:00:25.590
在此 notebook 中 我们将使用预训练的模型 该模型训练了很长时间

00:00:25.590 --> 00:00:30.870
在分类 ImageNet 数据集中的图像方面取得了很高的准确率

00:00:30.870 --> 00:00:33.605
此数据集有 1000 个图像类别

00:00:33.605 --> 00:00:36.955
因此最终输出层生成了 1000 个类别分数

00:00:36.955 --> 00:00:40.700
但在此 notebook 中 我将演示如何更改最后的层级

00:00:40.700 --> 00:00:42.860
并微调模型的分类器部分

00:00:42.860 --> 00:00:45.560
以便将它应用到花朵分类任务上

00:00:45.560 --> 00:00:48.130
稍后我将展示花朵数据集

00:00:48.130 --> 00:00:50.555
它包含 5 个不同的花朵类别

00:00:50.555 --> 00:00:53.735
分别是太阳花 郁金香 玫瑰 蒲公英和雏菊

00:00:53.735 --> 00:00:56.490
要针对此任务自定义 VGG 模型

00:00:56.490 --> 00:01:01.020
我打算冻结或锁定卷积层和池化层中的权重

00:01:01.020 --> 00:01:03.050
这部分充当固定特征提取器

00:01:03.050 --> 00:01:06.560
并使所有训练图像经过这部分

00:01:06.560 --> 00:01:08.780
然后将分类部分的最终层级

00:01:08.780 --> 00:01:11.880
替换为新的全连接层

00:01:11.880 --> 00:01:15.705
从而生成 5 个类别分数 而不是 1000 个类别分数

00:01:15.705 --> 00:01:18.275
替换最后一个层级之后

00:01:18.275 --> 00:01:20.810
我将训练所有这三个全连接层

00:01:20.810 --> 00:01:24.365
意味着我将微调其中两个线性层级的权重

00:01:24.365 --> 00:01:27.050
并以全新方式训练最后一个层级中的权重

00:01:27.050 --> 00:01:29.350
我们开始吧

00:01:29.350 --> 00:01:34.465
首先照常加载库并检查 GPU 设备是否可用

00:01:34.465 --> 00:01:36.740
因为我是在讲解练习

00:01:36.740 --> 00:01:38.600
暂时我将使用笔记本 CPU

00:01:38.600 --> 00:01:41.450
然后照常加载数据

00:01:41.450 --> 00:01:45.170
这次 数据位于训练和测试目录中

00:01:45.170 --> 00:01:48.075
每个子目录代表一种花朵类别

00:01:48.075 --> 00:01:53.840
这种结构使我们能够使用 PyTorch 的 ImageFolder 类轻松地加载数据

00:01:53.840 --> 00:01:57.555
该类假定图像都位于标注正确的文件夹里

00:01:57.555 --> 00:02:01.125
也就是说 所有太阳花都位于太阳花文件夹里

00:02:01.125 --> 00:02:06.335
因为 VGG 要求输入图像是 224x224 方形图像

00:02:06.335 --> 00:02:10.620
因此我将使用 data_transform 调整所有图像的大小并加载图像

00:02:10.620 --> 00:02:13.240
暂时只加载训练和测试数据

00:02:13.240 --> 00:02:16.450
你也可以划分出验证集

00:02:16.450 --> 00:02:21.720
可以看出我们只有大约 3,000 张训练图像 测试图像更少

00:02:21.720 --> 00:02:25.290
它比 MNIST 数据集小多了

00:02:25.290 --> 00:02:29.450
我们也可以通过这次试验看看迁移学习对这种小规模数据集来说效果如何

00:02:29.450 --> 00:02:33.710
在这里使用 DataLoader 类分批加载数据

00:02:33.710 --> 00:02:36.280
最后可视化一批数据

00:02:36.280 --> 00:02:39.850
可以看到各种花朵和相应的标签

00:02:39.850 --> 00:02:42.775
并且可以看出这些图像的变化

00:02:42.775 --> 00:02:46.125
有些花朵是特写 而有些镜头拍得很远

00:02:46.125 --> 00:02:48.965
相比于那些经过预处理的、花朵都刻意居中的数据集相比

00:02:48.965 --> 00:02:51.845
这个任务更有挑战性

00:02:51.845 --> 00:02:54.930
加载数据后 接下来定义模型

00:02:54.930 --> 00:02:56.850
使用预训练模型的第一步是

00:02:56.850 --> 00:03:00.535
知道如何查看已经存在的结构

00:03:00.535 --> 00:03:05.070
在这里从 PyTorch 的 models 库中加载 VGG 16 模型

00:03:05.070 --> 00:03:07.525
该库包含很多常用的模型

00:03:07.525 --> 00:03:09.590
我希望此模型已预训练

00:03:09.590 --> 00:03:12.060
按名称调用它并存储在此变量里

00:03:12.060 --> 00:03:15.275
加载完毕后 输出模型并看看所有层级

00:03:15.275 --> 00:03:17.750
可以在这里看到完整的 VGG 网络

00:03:17.750 --> 00:03:21.170
首先 有一系列层级 叫做 features

00:03:21.170 --> 00:03:24.050
它们是一系列卷积层和池化层

00:03:24.050 --> 00:03:27.215
然后在下面是另一组层级 叫做 classifier

00:03:27.215 --> 00:03:30.890
它们是三个全连接线性层级

00:03:30.890 --> 00:03:35.020
还可以看到每个层级有多少输入和输出等

00:03:35.020 --> 00:03:37.360
现在我可以按名称引用任何层级

00:03:37.360 --> 00:03:40.140
无论是一组层级还是单个层级

00:03:40.140 --> 00:03:45.880
例如 我可以输入 vgg16.features 引用这整个层级群组

00:03:45.880 --> 00:03:49.160
或者要引用最后这个线性层级

00:03:49.160 --> 00:03:53.390
我可以输入 vgg16.classifier[6]

00:03:53.390 --> 00:03:55.580
例如 我可以在这里

00:03:55.580 --> 00:03:59.010
访问最后一个线性层级并输出它的输入特征数量和输出特征数量

00:03:59.010 --> 00:04:03.250
可以看出这些值与之前输出的值保持一致

00:04:03.250 --> 00:04:06.275
现在你已经知道如何读取预训练的模型

00:04:06.275 --> 00:04:10.220
接下来我将演示如何冻结特征层级中的权重

00:04:10.220 --> 00:04:15.130
并将最后一个层级替换为适合花朵分类任务的新线性层级

