WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.720
如果你要处理的数据集非常庞大

00:00:03.720 --> 00:00:07.655
并且与 ImageNet 数据库中的图像不太相同 那么该如何使用迁移学习？

00:00:07.655 --> 00:00:11.935
举个例子 优达学城创始人 Sebastian Thrun

00:00:11.935 --> 00:00:13.645
和他的斯坦福团队

00:00:13.645 --> 00:00:18.100
最近利用迁移学习开发了一个诊断皮肤癌的 CNN

00:00:18.100 --> 00:00:22.650
该 CNN 会将病灶分类为良性或恶性

00:00:22.650 --> 00:00:27.480
并且在诊断某些皮肤癌方面达到了皮肤科医生的水平

00:00:27.480 --> 00:00:28.830
他对 Inception 结构应用迁移学习

00:00:28.830 --> 00:00:32.520
并得出了皮肤癌检测模型

00:00:32.520 --> 00:00:34.660
其中 Inception 结构是在ImageNet 数据库上预训练过的模型

00:00:34.660 --> 00:00:36.270
首先 他删除了

00:00:36.270 --> 00:00:41.330
最后的全连接分类层并添加了新的全连接层

00:00:41.330 --> 00:00:44.540
这和我之前介绍的方法相似

00:00:44.540 --> 00:00:48.285
即添加新的分类层级并且定义输出类别大小

00:00:48.285 --> 00:00:52.980
在此例中 每种疾病类别在这一层级都有一个对应输出值

00:00:52.980 --> 00:00:55.240
对于网络中的其他所有层级

00:00:55.240 --> 00:00:58.460
使用预训练的值初始化这些参数

00:00:58.460 --> 00:01:01.070
在训练过程中进一步优化这些参数

00:01:01.070 --> 00:01:03.865
以拟合皮肤病灶数据库

00:01:03.865 --> 00:01:07.985
Sebastian 和他的团队没有将这个预训练的模型

00:01:07.985 --> 00:01:09.860
当做固定特征提取器

00:01:09.860 --> 00:01:12.620
而是作为起点并训练了整个网络

00:01:12.620 --> 00:01:14.930
修改所有权重

00:01:14.930 --> 00:01:17.985
使它们适合处理医学图像分类任务

00:01:17.985 --> 00:01:20.810
在这种方式中 模型一开始能够完全受益于

00:01:20.810 --> 00:01:24.015
在 ImageNet 上预训练的模型

00:01:24.015 --> 00:01:26.630
这是另一种迁移学习

00:01:26.630 --> 00:01:29.900
这种技巧称为微调

00:01:29.900 --> 00:01:34.400
因为需要稍微更改或调整预训练网络中的所有现有参数

00:01:34.400 --> 00:01:39.305
如果你要处理的数据集很庞大 微调通常效果最好

00:01:39.305 --> 00:01:41.810
迁移学习是非常有用的技巧

00:01:41.810 --> 00:01:44.720
但是你应该根据新数据集的大小

00:01:44.720 --> 00:01:48.775
以及与预训练模型之间的相似程度采用不同的方式

00:01:48.775 --> 00:01:52.600
我们建议你尝试不同的方法

00:01:52.600 --> 00:01:55.040
你将在下方的文本部分找到

00:01:55.040 --> 00:01:58.280
关于如何在不同情形下使用迁移学习的更多信息

