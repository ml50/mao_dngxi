WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.339
我们刚刚训练了 PCA 模型 现在我们可以访问底层模型参数

00:00:05.339 --> 00:00:08.669
我们需要训练作业的名称

00:00:08.669 --> 00:00:09.765
我将从这里复制该名称

00:00:09.765 --> 00:00:12.630
还可以从 AWS 控制台中查看名称

00:00:12.630 --> 00:00:17.100
保存的模型工具以 TAR 文件形式存储在 S3 中

00:00:17.100 --> 00:00:19.770
这是一个压缩文件

00:00:19.769 --> 00:00:22.364
位于我们指定的输出路径中

00:00:22.364 --> 00:00:27.015
并且将保存在 output/model.tar.gz 中

00:00:27.015 --> 00:00:31.289
我们可以查看存储在这里的工件并使用它们部署训练过的模型

00:00:31.289 --> 00:00:34.339
在这里复制粘贴训练作业的名称

00:00:34.340 --> 00:00:38.484
model_key 将为之前指定的 prefix

00:00:38.484 --> 00:00:41.054
作业名称和输出扩展路径的组合

00:00:41.054 --> 00:00:43.850
与之前下载 csv 文件相似

00:00:43.850 --> 00:00:46.535
我们将传入 model_key、bucket_name

00:00:46.534 --> 00:00:49.654
并对 boto3.resource 调用 download_file

00:00:49.655 --> 00:00:52.175
还有几行代码

00:00:52.174 --> 00:00:56.029
目的是解压缩这个文件并存储为 model_algo-1

00:00:56.030 --> 00:00:59.390
这个名称在模型之间是一致的

00:00:59.390 --> 00:01:01.310
如果执行此单元格

00:01:01.310 --> 00:01:04.475
将输出 model_key 它是一个确认码

00:01:04.474 --> 00:01:08.719
内置 SageMaker 模型是用 MXNet 构建的

00:01:08.719 --> 00:01:11.420
所以导入 mx 库

00:01:11.420 --> 00:01:13.504
这样就可以获得一些能使用的工具

00:01:13.504 --> 00:01:18.030
通过传入模型名称 (model_algo-1) 加载模型的参数

00:01:19.299 --> 00:01:23.390
mx 库可以将这个加载为 ndarray

00:01:23.390 --> 00:01:27.079
将所有这些保存到 pca_model_params 中 并输出这些参数

00:01:27.079 --> 00:01:31.609
可以看到这个数组主要包含三个值

00:01:31.609 --> 00:01:34.545
分别是 s v 下面是 mean

00:01:34.545 --> 00:01:36.939
我可以通过名称访问这些数组

00:01:36.939 --> 00:01:39.364
我在这里解释了每个值的含义

00:01:39.364 --> 00:01:43.419
mean 表示为了居中成分而减去的均值

00:01:43.420 --> 00:01:45.835
这属于 PCA 计算的一个步骤

00:01:45.834 --> 00:01:48.918
v 表示主成分的组成

00:01:48.918 --> 00:01:53.840
即哪些原始特征线性组合组成了每个主成分

00:01:53.840 --> 00:01:57.310
s 表示成分的奇异值

00:01:57.310 --> 00:02:01.990
我们讨论了如何获得可以解释最大数据集方差的成分

00:02:01.989 --> 00:02:05.629
s 并不能告诉我们精确的百分比数据方差

00:02:05.629 --> 00:02:08.719
但是可以根据这个近似解释方差公式

00:02:08.719 --> 00:02:11.590
帮助我们计算出很逼近的方差百分比

00:02:11.590 --> 00:02:12.784
稍后我会讲解这个公式的

00:02:12.784 --> 00:02:14.329
需要注意的一点是

00:02:14.330 --> 00:02:17.390
在研究主成分和数据方差时

00:02:17.389 --> 00:02:20.139
我们只对 v 和 s 感兴趣

00:02:20.139 --> 00:02:23.359
我将通过名称加载这些参数

00:02:23.360 --> 00:02:26.570
并存储到 DataFrame s 和 v 中

00:02:26.569 --> 00:02:29.734
首先来介绍下 s 和数据方差

00:02:29.735 --> 00:02:31.250
根据 s

00:02:31.250 --> 00:02:34.294
我们可以获得前 n 个主成分

00:02:34.294 --> 00:02:37.504
能够解释的数据方差的近似值

00:02:37.504 --> 00:02:41.014
这就是近似解释方差的公式

00:02:41.014 --> 00:02:45.554
它等于前 n 个成分的平分和

00:02:45.555 --> 00:02:48.875
除以所有成分的平方和

00:02:48.875 --> 00:02:51.349
为何我们对方差感兴趣？

00:02:51.349 --> 00:02:53.614
为何方差很重要？

00:02:53.615 --> 00:02:57.469
通过 PCA 降维的难题是

00:02:57.469 --> 00:03:01.039
决定要使用数据中的前多少个成分

00:03:01.039 --> 00:03:03.864
并最终用于聚类模型

00:03:03.865 --> 00:03:08.890
我们知道我们要向原始训练数据应用 PCA 模型

00:03:08.889 --> 00:03:11.639
模型将返回 33 个主成分

00:03:11.639 --> 00:03:13.459
但是我们仅想用

00:03:13.460 --> 00:03:16.310
前几个成分创建更小的特征空间

00:03:16.310 --> 00:03:18.740
这样可以更好地聚类人口数据

00:03:18.740 --> 00:03:21.485
在 33 个主成分中

00:03:21.485 --> 00:03:24.490
如何选择合适的成分数量

00:03:24.490 --> 00:03:26.939
并在转换训练数据时使用这前几个成分？

00:03:26.939 --> 00:03:28.439
选择前五个成分？

00:03:28.439 --> 00:03:30.254
前十个成分？甚至更多？

00:03:30.254 --> 00:03:32.870
我们知道 PCA 将按照导致最多方差

00:03:32.870 --> 00:03:36.784
到导致最少方差的顺序创建成分

00:03:36.784 --> 00:03:40.099
假设有这样的三维数据

00:03:40.099 --> 00:03:43.189
这个图形示例摘自

00:03:43.189 --> 00:03:46.579
一篇关于整理基因数据的博士论文

00:03:46.580 --> 00:03:50.600
这个三维图形可以解释所有的数据方差

00:03:50.599 --> 00:03:52.159
包括从上到下

00:03:52.159 --> 00:03:53.740
从左到右以及从前到后

00:03:53.740 --> 00:03:57.125
从图中可以看出大多数数据都是相关的

00:03:57.125 --> 00:04:00.455
都靠近一个二维平面

00:04:00.455 --> 00:04:02.495
仅仅通过查看数据的扩散性

00:04:02.495 --> 00:04:05.884
就可以看出这些三维数据具有某种关系

00:04:05.884 --> 00:04:09.439
实际上 我们可以创建新的二维数据

00:04:09.439 --> 00:04:13.550
它们是原始三维数据的线性组合

00:04:13.550 --> 00:04:17.030
这些二维数据以原始数据的中心居中

00:04:17.029 --> 00:04:20.500
并根据这些 PCA 成分直线成一定的角度

00:04:20.500 --> 00:04:22.774
我们将三维数据

00:04:22.774 --> 00:04:26.794
投射到了这个二维成分空间里

00:04:26.795 --> 00:04:29.045
即 PCA 转换空间

00:04:29.045 --> 00:04:33.280
轴由 PCA 成分 PC 1 和 PC 2 确定

00:04:33.279 --> 00:04:38.184
仅使用这些二维数据

00:04:38.185 --> 00:04:40.699
我们依然捕获了 98% 的数据方差

00:04:40.699 --> 00:04:42.229
在这个简单示例中

00:04:42.230 --> 00:04:45.819
降维并没有损害多少数据表示信息

00:04:45.819 --> 00:04:48.694
通常 尤其是在高维数据中

00:04:48.694 --> 00:04:51.920
我们可以捕获的方差量

00:04:51.920 --> 00:04:56.074
与表示数据所使用的成分数量之间有明显的权衡性

00:04:56.074 --> 00:04:57.539
这很好理解

00:04:57.540 --> 00:04:58.920
如果丢失某个维度

00:04:58.920 --> 00:05:01.890
肯定就会丢失一定的数据复杂性信息

00:05:01.889 --> 00:05:04.389
PCA 会考虑这种权衡性

00:05:04.389 --> 00:05:08.000
通常需要我们来选择成分数量

00:05:08.000 --> 00:05:12.769
既可以降低数据维度 又能保持最多的数据方差

00:05:12.769 --> 00:05:14.375
这个数字可能会因

00:05:14.375 --> 00:05:15.740
具体应用而改变

00:05:15.740 --> 00:05:20.990
但是对于发现大型人口数据的一般规律来说 例如在我们的示例中

00:05:20.990 --> 00:05:23.650
保留约 80% 的方差就可以了

00:05:23.649 --> 00:05:25.189
需要注意的一点是

00:05:25.189 --> 00:05:30.125
最大的 s 值将位于这个 s DataFrame 的末尾

00:05:30.125 --> 00:05:33.579
例如 要查看前五个奇异值

00:05:33.579 --> 00:05:38.560
可以查看这个 s DataFrame 中的某个起始索引并输出这些值

00:05:38.560 --> 00:05:41.149
为了选择前 n 个成分

00:05:41.149 --> 00:05:43.250
并计算解释的方差量

00:05:43.250 --> 00:05:46.600
你的任务是完成函数 explained_variance

00:05:46.600 --> 00:05:50.525
这个函数将接受刚刚获得的整个 s DataFrame

00:05:50.524 --> 00:05:53.644
以及 n_top_components 数字

00:05:53.644 --> 00:05:57.969
这个数字表示前一个或前五个成分等等

00:05:57.970 --> 00:06:00.350
然后使用这个近似公式进行计算

00:06:00.350 --> 00:06:03.260
即前 n 个成分的平方和

00:06:03.259 --> 00:06:05.855
除以所有成分的平方和

00:06:05.855 --> 00:06:09.620
并返回近似解释方差的百分比小数值

00:06:09.620 --> 00:06:10.905
编写完代码后

00:06:10.904 --> 00:06:12.329
可以在这里测试代码

00:06:12.329 --> 00:06:14.004
你将能够回答这个问题

00:06:14.004 --> 00:06:16.879
能够解释数据集总方差的至少 80% 的

00:06:16.879 --> 00:06:20.605
最小主成分数量是多少？

00:06:20.605 --> 00:06:22.080
请试着自己完成这项任务

00:06:22.079 --> 00:06:23.314
如果你想检查你的代码

00:06:23.314 --> 00:06:26.430
请观看下个解答视频

