WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.209
除了查看训练过的模型的属性之外

00:00:03.209 --> 00:00:08.219
我们还可以利用这些属性部署 PCA 模型并使用模型做出预测

00:00:08.220 --> 00:00:10.140
为了部署训练过的模型

00:00:10.140 --> 00:00:14.115
我们通过名称调用该模型并调用 deploy()

00:00:14.115 --> 00:00:19.390
然后传入一些参数 将实例数量设为 1

00:00:19.390 --> 00:00:22.740
对于实例类型 端点将使用 ml.t2.medium

00:00:22.739 --> 00:00:27.104
运行这些代码后 可以看到系统自动创建了两项内容

00:00:27.105 --> 00:00:31.445
包括具有特定名称的模型和具有特定名称的端点

00:00:31.445 --> 00:00:32.719
对于内置模型来说

00:00:32.719 --> 00:00:35.435
这两项经常自动一起创建

00:00:35.435 --> 00:00:38.030
但是对于我们稍后将见到的一些自定义模型

00:00:38.030 --> 00:00:41.539
我们需要单独创建模型 然后创建端点

00:00:41.539 --> 00:00:45.350
你还可以考虑使用更强大的实例类型

00:00:45.350 --> 00:00:48.335
但是对我们来说 t2 medium 足够了

00:00:48.335 --> 00:00:51.634
部署需要花费一段时间 部署完毕后

00:00:51.634 --> 00:00:54.464
我们可以将模型应用到训练数据上

00:00:54.465 --> 00:00:57.120
并将数据转换为 PCA 成分

00:00:57.119 --> 00:01:01.579
你已经知道在 SageMaker 中 我们可以将端点连接到 API Gateway

00:01:01.579 --> 00:01:03.890
使网络应用能访问端点

00:01:03.890 --> 00:01:06.320
但是 现在我们将仅使用此预测器

00:01:06.319 --> 00:01:09.619
处理原始训练数据

00:01:09.620 --> 00:01:12.020
并创建降维数据

00:01:12.019 --> 00:01:14.209
部署了预测器后

00:01:14.209 --> 00:01:17.079
我可以使用它修改原始训练数据

00:01:17.079 --> 00:01:18.855
为了向数据应用端点

00:01:18.855 --> 00:01:22.325
我只需调用 .predict 并传入训练数据

00:01:22.325 --> 00:01:26.480
默认情况下 此函数要求输入是 NumPy 数组

00:01:26.480 --> 00:01:29.150
所以传入之前转换的数据

00:01:29.150 --> 00:01:31.984
这些数据就是缩放范围并归一化的整洁 DataFrame

00:01:31.983 --> 00:01:34.924
再转换成 NumPy 数组

00:01:34.924 --> 00:01:36.739
predict() 函数将查看数据集中

00:01:36.739 --> 00:01:39.125
每个数据点的特征

00:01:39.125 --> 00:01:41.885
并将其转换成 PCA 成分

00:01:41.885 --> 00:01:44.344
这个将存储原始 3,000 个左右

00:01:44.344 --> 00:01:47.554
训练数据点的 PCA 成分值

00:01:47.555 --> 00:01:51.900
我们看看第一个数据点的值 通过索引（索引为 0）输出信息

00:01:51.900 --> 00:01:54.380
虽然这些数据仅针对某个郡县

00:01:54.379 --> 00:01:58.339
但是可以看到 key: ”projection” 和 float_32 tensor

00:01:58.340 --> 00:02:01.329
该张量存储了 33 个成分值

00:02:01.329 --> 00:02:03.118
与其他分析结果一样

00:02:03.118 --> 00:02:06.650
前几位的成分实际上位于这个列表的底部

00:02:06.650 --> 00:02:10.609
下面请跟着这些名称和排序信息

00:02:10.609 --> 00:02:13.225
创建一个转换后的 DataFrame

00:02:13.224 --> 00:02:17.194
请完成函数 create_transformed_df

00:02:17.194 --> 00:02:21.319
它的参数包括刚刚生成的 PCA 训练数据列表

00:02:21.319 --> 00:02:23.868
原始 counties_scale dataframe

00:02:23.868 --> 00:02:25.745
以及 n_top_components

00:02:25.745 --> 00:02:29.254
我们需要创建一个 DataFrame 依然以 State-County 为索引

00:02:29.254 --> 00:02:33.424
但是每列都对应于前几位成分中的某个成分

00:02:33.425 --> 00:02:35.359
如果这是前七位成分

00:02:35.359 --> 00:02:37.145
你将看到 7 列数据

00:02:37.145 --> 00:02:39.875
生成的 DataFrame 应该是这样的

00:02:39.875 --> 00:02:42.319
这个函数会创建一个数据集

00:02:42.319 --> 00:02:46.204
其中每个郡县由前几位主成分描述

00:02:46.205 --> 00:02:49.505
这正是接下来的 K 均值聚类所需的数据集

00:02:49.504 --> 00:02:51.389
请试着完成此函数

00:02:51.389 --> 00:02:54.069
完成后 请继续执行后面的步骤

00:02:54.069 --> 00:02:57.689
包括使用完端点后 删除 PCA 模型端点

00:02:57.689 --> 00:03:03.210
并使用新转换的数据训练 K 均值模型

