WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.370
下面讨论下模型设计和算法选择

00:00:05.370 --> 00:00:08.280
选择非监督式还是监督式方法

00:00:08.279 --> 00:00:10.500
与最终目标关系很紧密

00:00:10.500 --> 00:00:16.094
当最终目标相对简单时 非监督式学习通常最有用

00:00:16.094 --> 00:00:20.634
例如 如果你只想分组相似的观察量

00:00:20.635 --> 00:00:25.395
则不需要详细了解每个观察量

00:00:25.394 --> 00:00:28.500
要将车辆分成汽车 自行车和巴士

00:00:28.500 --> 00:00:32.740
你可能不需要知道具体的车辆型号

00:00:32.740 --> 00:00:38.250
但是如果你要区分不同的车辆型号

00:00:38.250 --> 00:00:41.715
例如 Tesla 与 Toyota Prius

00:00:41.715 --> 00:00:45.740
则可能还需要标注车辆图像数据

00:00:45.740 --> 00:00:51.020
从而训练特定的分类模型

00:00:51.020 --> 00:00:53.030
如果有大量无标签数据

00:00:53.030 --> 00:00:58.039
你可能会疑问 如何有效准确地标注这些数据？

00:00:58.039 --> 00:01:02.439
遗憾的是 数据标注是工作量很大的人工任务

00:01:02.439 --> 00:01:07.819
理想情况下 你希望将原始图像发送给

00:01:07.819 --> 00:01:10.354
能在不同型号的车辆周围画出边界框的人士

00:01:10.355 --> 00:01:14.075
因为你要解决的问题是识别车辆型号

00:01:14.075 --> 00:01:16.820
你还可以借助主动学习模型

00:01:16.819 --> 00:01:21.379
自动化数据标注任务

00:01:21.379 --> 00:01:26.034
主动学习模型是指能够从人工初始注释中学习的机器学习模型

00:01:26.034 --> 00:01:32.194
SageMaker 将这两种功能结合到了一起 即让人手动标注数据

00:01:32.194 --> 00:01:35.119
并创建一个用于未来任务的主动学习模型

00:01:35.120 --> 00:01:38.410
然后组合成一个特征 叫做 Ground Truth (参考标准\真相\真实）

00:01:38.409 --> 00:01:44.584
参考标准会尝试将原始数据变成带标签的训练数据

00:01:44.584 --> 00:01:48.379
使你能够让人手动标注数据

00:01:48.379 --> 00:01:51.890
获得这些初始标签后

00:01:51.890 --> 00:01:54.019
它会训练一个机器学习模型

00:01:54.019 --> 00:01:57.274
学习未来自动化这个标注任务

00:01:57.275 --> 00:02:00.440
总体而言 使未来标注相似数据集的

00:02:00.439 --> 00:02:04.679
时间和成本降低了约 70%

