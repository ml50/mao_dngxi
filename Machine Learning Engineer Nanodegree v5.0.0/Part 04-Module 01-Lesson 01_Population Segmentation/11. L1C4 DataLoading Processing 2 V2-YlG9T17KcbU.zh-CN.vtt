WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.455
打开 Pop_Segmentation_Exercise notebook

00:00:04.455 --> 00:00:08.955
首先确保在正确的内核下操作

00:00:08.955 --> 00:00:11.195
转到“Kernel”&gt;“Change kernel”

00:00:11.195 --> 00:00:15.600
可以看到 SageMaker 提供了各种内核

00:00:15.599 --> 00:00:17.160
对于所有这些示例

00:00:17.160 --> 00:00:22.545
我们将使用 conda_mxnet_p36 或 conda_pytorch_p36

00:00:22.545 --> 00:00:26.235
这个表示我们会使用的深度学习框架类型

00:00:26.234 --> 00:00:28.890
mxnet 是 SageMaker 内置的学习框架

00:00:28.890 --> 00:00:32.310
p36 表示我们将使用的 Python 版本

00:00:32.310 --> 00:00:33.740
对于此示例

00:00:33.740 --> 00:00:39.750
我们将使用内置算法 而 mxnet_p36 将是理想的内核

00:00:39.750 --> 00:00:43.810
我可以在 notebook 的右上角查看我使用的是哪个内核

00:00:43.810 --> 00:00:46.490
对于这个分割示例 需要注意的是

00:00:46.490 --> 00:00:49.730
我将详细讲解第一个 notebook

00:00:49.729 --> 00:00:51.709
当我们讲解这些示例时

00:00:51.710 --> 00:00:54.140
越来越多的任务将交给你

00:00:54.140 --> 00:00:56.570
需要你来完成代码

00:00:56.570 --> 00:00:59.064
但是我始终会提供最终解答 notebook

00:00:59.064 --> 00:01:01.609
这部分介绍了美国人口普查数据集

00:01:01.609 --> 00:01:05.344
以及为了分割此数据集我将采取的总体方法

00:01:05.344 --> 00:01:07.909
此 notebook 是一篇 SageMaker 博文中

00:01:07.909 --> 00:01:11.125
代码的修改版本 这是这篇博文的链接

00:01:11.125 --> 00:01:13.174
在此 notebook 中

00:01:13.174 --> 00:01:16.819
你将使用两个非监督式学习算法进行人口细分

00:01:16.819 --> 00:01:20.449
目标是查找人口数据中的自然分组

00:01:20.450 --> 00:01:24.295
并发现美国不同区域的特征级相似性

00:01:24.295 --> 00:01:26.325
为了实施人口细分

00:01:26.325 --> 00:01:28.170
你需要完成几个步骤

00:01:28.170 --> 00:01:30.555
首先 加载和探索数据

00:01:30.555 --> 00:01:32.975
然后清理和预处理数据

00:01:32.974 --> 00:01:34.439
清理数据后

00:01:34.439 --> 00:01:37.810
通过 PCA 降维

00:01:37.810 --> 00:01:40.920
PCA 是主成分分析的缩写

00:01:40.920 --> 00:01:42.650
你将利用这些成分

00:01:42.650 --> 00:01:45.484
创建新的特征并转换原始训练数据

00:01:45.484 --> 00:01:50.155
最后 使用 K 均值聚类算法聚类转换的数据

00:01:50.155 --> 00:01:53.390
我们还将练习可视化每个模型

00:01:53.390 --> 00:01:55.954
PCA 和 K 均值学习的规律

00:01:55.954 --> 00:01:58.129
我们将查看这些模型生成的

00:01:58.129 --> 00:02:00.604
成分和 K 聚类

00:02:00.605 --> 00:02:03.380
这个 notebook 中的每道练习

00:02:03.379 --> 00:02:06.469
旨在帮助你练习机器学习工作流程的每个步骤

00:02:06.469 --> 00:02:09.199
并展示如何使用 SageMaker 工具

00:02:09.199 --> 00:02:13.164
例如通过 S3 管理数据以及使用 SageMaker 的内置算法

00:02:13.164 --> 00:02:17.435
前几个单元格将加载各种库

00:02:17.435 --> 00:02:21.365
有些是可视化库 有些是 SageMaker 库

00:02:21.365 --> 00:02:24.379
包括 boto3 和 SageMaker 库

00:02:24.379 --> 00:02:28.069
SageMaker 安装了很多库 通常你只需指向要使用的资源

00:02:28.069 --> 00:02:31.849
就像在优达学城教室的 workspace 中一样

00:02:31.849 --> 00:02:33.724
下面获取数据

00:02:33.724 --> 00:02:37.759
这个数据集已经位于 Amazon S3 存储桶中

00:02:37.759 --> 00:02:41.840
我可以通过指向这个存储桶加载数据 并通过名称获取数据文件

00:02:41.840 --> 00:02:45.939
首先需要创建一个与 S3 交互的 boto3 客户端

00:02:45.939 --> 00:02:48.680
如果代码输入正确 然后运行此单元格

00:02:48.680 --> 00:02:52.490
应该会看到该存储桶中的对象列表

00:02:52.490 --> 00:02:55.325
我在这里调用该客户端

00:02:55.324 --> 00:02:59.589
要求它列出存储桶中的所有对象 然后输出该存储桶中的内容

00:02:59.590 --> 00:03:03.814
可以看到其中只有一个文件 Census_Data_for_SageMaker

00:03:03.814 --> 00:03:06.935
它是一个 CSV 文件 获取该名称

00:03:06.935 --> 00:03:10.460
我获得了要检索的 CSV 文件的名称

00:03:10.460 --> 00:03:12.650
要获取 S3 对象

00:03:12.650 --> 00:03:15.649
我将再次调用 client 并调用 get_object

00:03:15.649 --> 00:03:16.909
传入该存储桶以及键

00:03:16.909 --> 00:03:20.185
键就是我在这里保存的文件名

00:03:20.185 --> 00:03:23.795
在最后一行 我输出了 data_object 包含的内容

00:03:23.794 --> 00:03:26.854
这个对象包含大量元数据

00:03:26.854 --> 00:03:30.715
例如 content-type 是一个 csv 文件

00:03:30.715 --> 00:03:35.405
在最后有个 Body 标记 这里是 StreamingBody 标记

00:03:35.405 --> 00:03:37.849
我要的就是这个 Streaming 数据

00:03:37.849 --> 00:03:40.204
在下个单元格 我将访问该 Body

00:03:40.205 --> 00:03:42.844
读取它并输出数据类型

00:03:42.844 --> 00:03:48.859
数据类型是 bytes 我可以通过调用 io.BytesIO 读取它

00:03:48.860 --> 00:03:52.040
最终获得一个像读取 csv 文件一样读取的 data_stream

00:03:52.039 --> 00:03:55.775
并创建一个包含郡县信息的 dataframe

00:03:55.775 --> 00:03:59.810
这些就是从 S3 存储桶中读取 data_stream 的步骤

00:03:59.810 --> 00:04:04.504
你可以按照这些步骤从 S3 存储桶中加载任何数据

00:04:04.504 --> 00:04:08.014
稍后 你会发现你可以直接从网络上下载数据

00:04:08.014 --> 00:04:12.219
我加载了数据并快速查看了 csv 文件里的内容

00:04:12.219 --> 00:04:15.409
输出标题和前五行数据

00:04:15.409 --> 00:04:18.439
包括 Censusid state county

00:04:18.439 --> 00:04:21.769
以及很多其他特征 这些特征列出了

00:04:21.769 --> 00:04:25.699
郡县的不同人口特征的人数和百分比

00:04:25.699 --> 00:04:28.729
人口普查记录特征包括总人口

00:04:28.730 --> 00:04:32.210
种族 交通工具和劳动力统计信息

00:04:32.209 --> 00:04:37.074
这些特性随着时间的推移已经改变了 因为人口类别改变了

00:04:37.074 --> 00:04:38.819
与任何人口数据一样

00:04:38.819 --> 00:04:40.879
这些特性简单地描绘了美国人口

00:04:40.879 --> 00:04:44.644
但是实际情况并不是这么简单清晰

00:04:44.644 --> 00:04:48.199
话虽这么说 但是查看区域之间的相似性或不同之处

00:04:48.199 --> 00:04:51.805
可以提供一些很有趣实用的信息

00:04:51.805 --> 00:04:53.384
加载了数据后

00:04:53.384 --> 00:04:54.539
下面清理

00:04:54.540 --> 00:04:56.300
探索和预处理数据

00:04:56.300 --> 00:04:58.370
在首次探索任何数据时

00:04:58.370 --> 00:05:00.050
有必要了解下将使用的数据

00:05:00.050 --> 00:05:02.900
一开始有多少数据点和特征？

00:05:02.899 --> 00:05:06.234
一眼看去可以得出什么样的信息？

00:05:06.235 --> 00:05:08.750
你应该查看数据的形状

00:05:08.750 --> 00:05:11.555
在第一道练习中

00:05:11.555 --> 00:05:13.264
你需要完成简单的数据清理步骤

00:05:13.264 --> 00:05:16.264
即删除任何不完整的数据点

00:05:16.264 --> 00:05:18.649
任何缺少列或列为空的数据

00:05:18.649 --> 00:05:21.889
都不应该包含在最终训练集中

00:05:21.889 --> 00:05:24.240
删除任何不完整的数据后

00:05:24.240 --> 00:05:26.475
请预处理数据

00:05:26.475 --> 00:05:30.020
最终 你需要将这些特征传入机器学习模型中

00:05:30.019 --> 00:05:33.139
机器学习模型需要从数值数据中学习规律

00:05:33.139 --> 00:05:36.680
而不是类别数据 例如 state 和 county 等字符串

00:05:36.680 --> 00:05:40.129
你需要调整这些数据的格式

00:05:40.129 --> 00:05:44.295
使其按照区域“State-County”设定索引

00:05:44.295 --> 00:05:49.609
然后需要删除旧的 state 和 county 列 以及 Censusid 列

00:05:49.608 --> 00:05:53.539
Censusid 只是一个编号 不包含任何人口信息

00:05:53.540 --> 00:05:55.749
现在数据没有行索引

00:05:55.749 --> 00:05:57.530
而是按照 State-County 设定索引

00:05:57.529 --> 00:06:02.029
剩下的特征列保持不变

00:06:02.029 --> 00:06:03.454
编写完代码后

00:06:03.454 --> 00:06:06.444
你应该获得开头如下所示的 dataframe

00:06:06.444 --> 00:06:08.480
这是一个整洁的 dataframe

00:06:08.480 --> 00:06:12.995
没有空列 并且都是可以相互比较的实用数值区域特征

00:06:12.995 --> 00:06:14.629
如果你完成了所有这些代码

00:06:14.629 --> 00:06:18.740
可以继续转到后面的可视化部分

00:06:18.740 --> 00:06:21.290
注意 你应该使用给定的变量名

00:06:21.290 --> 00:06:25.640
因为稍后在此 notebook 中可能会引用这些变量名

00:06:25.639 --> 00:06:29.689
我假定你按顺序执行了所有这些单元格

00:06:29.689 --> 00:06:33.980
例如 clean_counties_df 应该是这样的整洁郡县 dataframe

00:06:33.980 --> 00:06:36.530
稍后将在此 notebook 中引用 clean_counties_df

00:06:36.529 --> 00:06:38.689
如果你在清理或转换格式练习中遇到问题

00:06:38.689 --> 00:06:41.629
或者想检查你的代码

00:06:41.629 --> 00:06:45.029
请观看下个解答视频

