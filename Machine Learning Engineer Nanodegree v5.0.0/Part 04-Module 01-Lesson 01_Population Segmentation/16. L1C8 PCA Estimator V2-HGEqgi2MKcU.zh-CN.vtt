WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.889
需要注意的一点是 每个数据点都有 34 个关联特征

00:00:04.889 --> 00:00:08.699
这个 34 维数据是很高维度的数据

00:00:08.699 --> 00:00:14.564
非监督式算法需要寻找 n 维特征空间里的关系

00:00:14.564 --> 00:00:18.554
对于更高维度 通常会获得噪点更多的聚类

00:00:18.554 --> 00:00:20.640
K 均值等算法

00:00:20.640 --> 00:00:23.789
很难判断要关注哪些维度

00:00:23.789 --> 00:00:27.239
某些维度不如其他维度重要

00:00:27.239 --> 00:00:32.039
例如 如果数据集中的每个郡县总人口都一样

00:00:32.039 --> 00:00:36.034
那么这个特征就不能提供有意义的信息

00:00:36.034 --> 00:00:38.539
不能帮助我们将郡县分成不同的组

00:00:38.539 --> 00:00:42.034
因为它的值在郡县之间没有变化

00:00:42.034 --> 00:00:43.969
这只是一种假设

00:00:43.969 --> 00:00:48.409
我们希望寻找能帮助区分未分组数据的特征

00:00:48.409 --> 00:00:52.804
换句话说 我们希望寻找会导致最大的数据集变化的特征

00:00:52.804 --> 00:00:55.399
在使用 K 均值聚类数据之前

00:00:55.399 --> 00:00:57.229
我还要执行一个步骤

00:00:57.229 --> 00:00:59.375
即降维步骤

00:00:59.375 --> 00:01:01.310
目的是创建一个更小的特征集

00:01:01.310 --> 00:01:04.234
这些特征可以更好地帮助我区分数据

00:01:04.234 --> 00:01:09.400
我们将采用的技巧叫做主成分分析 (PCA)

00:01:09.400 --> 00:01:13.340
如果数据中有大量特征并且你想知道

00:01:13.340 --> 00:01:17.359
哪些特征线性组合最重要 它们可以解释数据集的最大变化

00:01:17.359 --> 00:01:20.510
那么可以使用 PCA

00:01:20.510 --> 00:01:22.094
为了执行 PCA

00:01:22.094 --> 00:01:24.795
我们将使用 SageMaker 的内置 PCA 算法

00:01:24.795 --> 00:01:26.290
为了创建任何模型

00:01:26.290 --> 00:01:30.680
首先需要指定 IAM 角色和 SageMaker 会话

00:01:30.680 --> 00:01:33.890
需要告诉模型使用哪些权限和会话进行训练

00:01:33.890 --> 00:01:39.394
在这个单元格中 我通过调用 sagemaker.Session 存储 SageMaker 会话

00:01:39.394 --> 00:01:42.349
这里是大写的 S 它是会话对象

00:01:42.349 --> 00:01:44.319
将其存储到这个变量中

00:01:44.319 --> 00:01:46.234
然后获取 IAM 角色

00:01:46.234 --> 00:01:47.989
我们之前指定了该角色

00:01:47.989 --> 00:01:51.474
通过导入get_execution_role 并按名称获取该角色

00:01:51.474 --> 00:01:53.944
输出该角色 看看名称是否正确

00:01:53.944 --> 00:01:56.329
我们创建了会话并且这个角色名称

00:01:56.329 --> 00:01:58.769
在之前创建 Notebook 时就设定了

00:01:58.769 --> 00:02:03.229
接着 还需要将训练的模型存储到 S3 存储桶中

00:02:03.230 --> 00:02:06.215
在下个单元格中 我通过调用 .default_bucket

00:02:06.215 --> 00:02:09.270
从 SageMaker 会话中创建默认的存储桶

00:02:09.270 --> 00:02:12.080
并保存该存储桶的名称以供后面引用

00:02:12.080 --> 00:02:14.090
如果你输出这个默认存储桶的名称

00:02:14.090 --> 00:02:15.800
结果应该是类似于这样的名称

00:02:15.800 --> 00:02:18.469
sageMaker 然后是区域

00:02:18.469 --> 00:02:22.405
我的是 us-west-1 最后是一个唯一编号

00:02:22.405 --> 00:02:26.444
然后开始构建 PCA 模型 需要完成几个步骤

00:02:26.444 --> 00:02:28.759
首先 指定要将

00:02:28.759 --> 00:02:29.859
训练过的模型工件

00:02:29.860 --> 00:02:32.300
存储在 S3 存储桶的哪个位置

00:02:32.300 --> 00:02:35.725
我将指定一个 prefix 表示数据的存储目录

00:02:35.724 --> 00:02:38.750
称为 counties 表示美国郡县的数据

00:02:38.750 --> 00:02:43.520
在这里创建整个输出路径 它是一个指向存储桶的字符串

00:02:43.520 --> 00:02:45.085
位于 prefix 目录中

00:02:45.085 --> 00:02:47.810
接下来定义 PCA 模型

00:02:47.810 --> 00:02:52.699
这个模型是一个内置 SageMaker 模型 可以按照名称导入它 输入 import PCA

00:02:52.699 --> 00:02:54.754
然后在下面创建一个模型

00:02:54.754 --> 00:02:58.264
保存为 pca_SM SM 表示 SageMaker

00:02:58.264 --> 00:03:00.739
在这里调用 PCA 构造函数

00:03:00.740 --> 00:03:02.750
括号里有多个参数

00:03:02.750 --> 00:03:06.379
首先 传入在上面定义的 IAM 角色

00:03:06.379 --> 00:03:08.764
然后指定 train_instance_count

00:03:08.764 --> 00:03:10.414
通常为 1

00:03:10.414 --> 00:03:11.810
以及 train_instance_type

00:03:11.810 --> 00:03:14.305
设为 ml_c4.xlarge

00:03:14.305 --> 00:03:18.680
然后将 output_path 指定为上面定义的路径

00:03:18.680 --> 00:03:23.000
这个路径表示生成的模型数据在 S3 中的存储位置

00:03:23.000 --> 00:03:26.830
还要传入刚刚定义的 SageMaker 会话

00:03:26.830 --> 00:03:29.330
最后还要指定一项

00:03:29.330 --> 00:03:32.060
这是 PCA 模型的超参数

00:03:32.060 --> 00:03:36.979
我们需要告诉这个模型我们要创建多少个主成分

00:03:36.979 --> 00:03:41.435
我们希望降低 34 个维度 但是首先需要生成

00:03:41.435 --> 00:03:46.340
足够多的线性独立主成分 以捕获数据中的变化

00:03:46.340 --> 00:03:50.080
稍后 选择将前几个成分并传递给聚类模型

00:03:50.080 --> 00:03:53.015
我将 N_COMPONENTS 设为 33

00:03:53.014 --> 00:03:57.319
它等于现有特征维数 34 减一

00:03:57.319 --> 00:04:01.084
这是开始 PCA 分析的一项经验法则

00:04:01.085 --> 00:04:05.240
我将创建 33 个主成分

00:04:05.240 --> 00:04:10.195
之后近选择前几个成分并用在最终的聚类算法中

00:04:10.194 --> 00:04:13.909
这个全大写 因为它是全局变量

00:04:13.909 --> 00:04:15.469
所以在定义该变量之后

00:04:15.469 --> 00:04:18.379
我将能够在 Notebook 中的任何后续单元格中访问该变量

00:04:18.379 --> 00:04:21.370
总结下我是如何创建这个 estimator 的

00:04:21.370 --> 00:04:24.590
首先从 SageMaker 导入该内置模型

00:04:24.589 --> 00:04:27.889
然后在这里传入几个构造函数参数

00:04:27.889 --> 00:04:32.735
包括角色和在上面的单元格中定义的 SageMaker 会话

00:04:32.735 --> 00:04:35.470
它们是可以从 Notebook 访问的默认参数

00:04:35.470 --> 00:04:39.380
session 和 role 是始终可以从 Notebook 实例中获得的变量.

00:04:39.379 --> 00:04:41.870
我还指定了一个输出路径

00:04:41.870 --> 00:04:44.990
表示模型训练后将在 S3 存储桶中存储的位置

00:04:44.990 --> 00:04:48.650
接着指定实例数量和训练类型

00:04:48.649 --> 00:04:51.919
最后指定 PCA 模型的超参数

00:04:51.920 --> 00:04:53.254
将我们要生成的成分数量

00:04:53.254 --> 00:04:55.529
设为 33

00:04:55.529 --> 00:04:57.359
Ok运行该单元格

00:04:57.360 --> 00:04:59.620
定义了该模型后

00:04:59.620 --> 00:05:03.965
我需要创建一个训练作业 并在 counties 数据上进行训练

00:05:03.964 --> 00:05:05.574
所有的

00:05:05.574 --> 00:05:10.214
SageMaker 内置模型都要求传入的训练数据是记录集

00:05:10.214 --> 00:05:14.539
这样的话 与 Scikit-learn 等模型相比

00:05:14.540 --> 00:05:18.379
在 SageMaker 中训练模型速度非常快 尤其是对于大型数据集来说

00:05:18.379 --> 00:05:21.214
为了变成记录集格式

00:05:21.214 --> 00:05:23.779
首先通过调用 values.astype(‘float32’)

00:05:23.779 --> 00:05:27.769
将缩放范围的 dataframe 变成一个 NumPy 数组

00:05:27.769 --> 00:05:30.685
将这个 NumPy 数组保存为 train_data_np

00:05:30.685 --> 00:05:34.889
然后调用模型的 .record_set

00:05:34.889 --> 00:05:39.425
并传入这个 NumPy 数组以创建记录集格式的训练数据

00:05:39.425 --> 00:05:41.595
从 NumPy 转换成记录集

00:05:41.595 --> 00:05:43.110
我获得了特定格式的训练数据

00:05:43.110 --> 00:05:44.370
最后 为了训练模型

00:05:44.370 --> 00:05:48.980
调用 pca_SM.fit 并传入 formatted_train_data

00:05:48.980 --> 00:05:50.180
如果运行此单元格

00:05:50.180 --> 00:05:54.715
将启动训练作业并在这里看到训练作业的名称

00:05:54.714 --> 00:05:56.959
这个作业需要运行一段时间

00:05:56.959 --> 00:05:59.104
在运行期间 我再演示一些其他功能

00:05:59.105 --> 00:06:02.405
转到 Amazon SageMaker 控制台

00:06:02.404 --> 00:06:04.234
在左侧有很多按钮

00:06:04.235 --> 00:06:06.275
这里有个“Training jobs”

00:06:06.274 --> 00:06:09.949
点击该按钮可以看到刚刚启动的 PCA 作业

00:06:09.949 --> 00:06:14.779
它处于 InProgress 状态可以看到我之前运行过的这些作业列表

00:06:14.779 --> 00:06:17.959
我们来看看正在运行的最近这个作业

00:06:17.959 --> 00:06:22.310
在此页面可以看到作业名称以及关联的 IAM 角色

00:06:22.310 --> 00:06:27.290
可以看出它正在运行 看看这个训练作业的详细信息

00:06:27.290 --> 00:06:29.450
一直向下滚动到“Monitor”部分

00:06:29.449 --> 00:06:31.740
我们可以点击日志

00:06:31.740 --> 00:06:33.860
日志对于调试训练作业来说非常重要

00:06:33.860 --> 00:06:36.185
例如如果运行失败了

00:06:36.185 --> 00:06:39.415
日志中会记录任何错误和跟踪记录

00:06:39.415 --> 00:06:42.700
在我的开发经历中 我遇到了几次作业失败的情况

00:06:42.699 --> 00:06:45.259
解决方法就是阅读日志并调试

00:06:45.259 --> 00:06:47.704
就像任何其他步骤一样 调试也是编程的一个步骤

00:06:47.704 --> 00:06:50.000
我刚刚演示了如何查看

00:06:50.000 --> 00:06:52.779
关于唯一训练作业的更多信息

00:06:52.779 --> 00:06:54.949
回到 Notebook 我们还可以

00:06:54.949 --> 00:06:57.529
在 Notebook 本身中监控训练作业

00:06:57.529 --> 00:07:01.969
可以看到输出语句和时间戳 表示实例何时启动的

00:07:01.970 --> 00:07:03.650
导入数据何时下载的

00:07:03.649 --> 00:07:06.234
以及关于训练作业的进度信息

00:07:06.235 --> 00:07:08.449
因为我计时了 所以最后可以向下滚动

00:07:08.449 --> 00:07:12.409
看看整个流程花费多长时间 有几分钟时间

00:07:12.410 --> 00:07:14.270
训练作业已经运行完毕

00:07:14.269 --> 00:07:15.740
我已经获得了训练过的模型

00:07:15.740 --> 00:07:20.300
接下来 我将查看模型生成的主成分

00:07:20.300 --> 00:07:25.280
我要看看组成每个成分的线性组合是什么

00:07:25.279 --> 00:07:27.919
并判断在创建新的降维训练数据时

00:07:27.920 --> 00:07:31.710
要包含多少个前几个成分

