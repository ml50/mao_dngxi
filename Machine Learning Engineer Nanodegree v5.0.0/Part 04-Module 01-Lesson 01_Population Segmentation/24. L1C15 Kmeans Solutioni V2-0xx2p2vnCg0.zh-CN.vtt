WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.485
在上个视频中

00:00:01.485 --> 00:00:06.120
我们训练了 PCA 模型并将其应用到原始归一化训练数据上

00:00:06.120 --> 00:00:11.339
使数据的维度从 34 维降到 7 个成分

00:00:11.339 --> 00:00:12.855
我们现在可以

00:00:12.855 --> 00:00:15.525
利用这个转换后的数据实现 K 均值聚类了

00:00:15.525 --> 00:00:20.130
创建 K 均值 estimator 并部署它的步骤与之前的很相似

00:00:20.129 --> 00:00:21.929
我将快速过一遍

00:00:21.929 --> 00:00:23.714
模型创建 训练和部署步骤

00:00:23.714 --> 00:00:26.295
第一步是定义 K 均值模型

00:00:26.295 --> 00:00:28.455
打开 K 均值的参考文档

00:00:28.454 --> 00:00:30.719
看看这个函数需要哪些参数

00:00:30.719 --> 00:00:34.274
可以看出 我需要导入 KMeans estimator

00:00:34.274 --> 00:00:38.009
传入角色并设定训练实例的数量以及类型

00:00:38.009 --> 00:00:40.019
这里还有个超参数

00:00:40.020 --> 00:00:43.070
k往下浏览文档

00:00:43.070 --> 00:00:46.850
这个 k 表示我希望算法生成的聚类数量

00:00:46.850 --> 00:00:49.579
在 notebook 中 我提供了关于如何选择合适的 k 值的

00:00:49.579 --> 00:00:52.504
建议这些建议是根据经验数据提出的

00:00:52.505 --> 00:00:55.640
我介绍了对于不同的 k 值

00:00:55.640 --> 00:00:58.789
如何查看数据点与每个聚类中心的距离

00:00:58.789 --> 00:01:02.420
一种糟糕的 k 值是

00:01:02.420 --> 00:01:06.575
K 值太高了 只有 1、2 个数据点非常接近聚类中心

00:01:06.575 --> 00:01:09.409
另一种糟糕的 k 值是 k 值太小

00:01:09.409 --> 00:01:12.409
数据点距离聚类中心太远

00:01:12.409 --> 00:01:15.229
我还介绍了“肘部”选择方法

00:01:15.230 --> 00:01:17.780
即选择这样一种肘部距离

00:01:17.780 --> 00:01:21.260
使我们能够足够区分

00:01:21.260 --> 00:01:23.525
每个聚类中的数据点

00:01:23.525 --> 00:01:27.560
但是还要包含足够多的聚类 使每个数据点距离每个聚类的距离都不是太远

00:01:27.560 --> 00:01:30.590
肘部方法接受一个 k 值

00:01:30.590 --> 00:01:34.564
然后查看每个数据点距离聚类中心的平均距离

00:01:34.564 --> 00:01:38.855
看看当 k 增大时 这个值是如何减小的

00:01:38.855 --> 00:01:41.570
如果看到像胳膊肘一样的形状或位置

00:01:41.569 --> 00:01:44.419
此时这个值不再显著下降

00:01:44.420 --> 00:01:48.905
那么就应该选择这个 k 值我尝试了各种 k 值的代码

00:01:48.905 --> 00:01:52.460
发现对我们来说 8 是比较合适的聚类数量

00:01:52.459 --> 00:01:56.479
可以看到 在此点之前 平均距离一直在下降

00:01:56.480 --> 00:02:00.825
Ok在定义 k 均值 estimator 时 我传入了角色

00:02:00.825 --> 00:02:02.560
指定了实例类型

00:02:02.560 --> 00:02:05.750
以及输出路径 与之前 PCA 模型使用的路径一样

00:02:05.750 --> 00:02:10.370
然后将聚类数量设为 8

00:02:10.370 --> 00:02:11.795
创建此模型后

00:02:11.794 --> 00:02:13.389
我称为 kmeans

00:02:13.389 --> 00:02:17.494
下面使用特殊格式的训练数据训练该模型

00:02:17.495 --> 00:02:20.450
这些步骤与训练 PCA 模型的一样

00:02:20.449 --> 00:02:23.464
传入 counties_transformed dataframe

00:02:23.465 --> 00:02:26.659
将其转换为浮点值 NumPy 数组

00:02:26.659 --> 00:02:29.074
然后调用 kmeans.record_set

00:02:29.074 --> 00:02:30.979
传入这个 NumPy 数据

00:02:30.979 --> 00:02:34.259
返回记录集格式的数据

00:02:34.259 --> 00:02:35.719
然后调用 fit()

00:02:35.719 --> 00:02:39.289
传入这个格式化数据并创建一个训练作业 作业名称是这个

00:02:39.289 --> 00:02:41.509
之后 如果你想查看模型属性

00:02:41.509 --> 00:02:44.030
可以引用这个名称

00:02:44.030 --> 00:02:45.985
训练作业运行完毕后

00:02:45.985 --> 00:02:49.400
然后部署此模型并创建 k 均值预测器

00:02:49.400 --> 00:02:52.969
使用的参数与 PCA 模型的一样

00:02:52.969 --> 00:02:56.965
可以看到 在这里创建了 k 均值模型和端点

00:02:56.965 --> 00:03:01.444
然后使用此预测器为所有数据点生成聚类标签

00:03:01.444 --> 00:03:04.009
在这里通过名称获取该预测器并调用 predict()

00:03:04.009 --> 00:03:07.909
然后将格式化的 NumPy 数据传入预测器中

00:03:07.909 --> 00:03:11.539
这个预测器将接受成分训练数据

00:03:11.539 --> 00:03:14.014
并返回关于聚类的信息

00:03:14.014 --> 00:03:15.919
在下个单元格中

00:03:15.919 --> 00:03:19.039
输出第一个数据点（列表中的第一个郡县）的

00:03:19.039 --> 00:03:20.614
聚类信息

00:03:20.615 --> 00:03:22.860
对于 Alabama-Autauga 县

00:03:22.860 --> 00:03:26.370
它最靠近聚类 3

00:03:26.370 --> 00:03:29.480
并且可以查看它与该聚类的欧几里得距离

00:03:29.479 --> 00:03:33.519
每个数据点都是一个 7 维成分空间

00:03:33.520 --> 00:03:35.795
我们所说的到聚类的距离

00:03:35.794 --> 00:03:38.659
是指在 7 维空间里

00:03:38.659 --> 00:03:42.365
数据点与它最靠近的聚类的中心之间的距离

00:03:42.365 --> 00:03:44.120
在下面的几个单元格中

00:03:44.120 --> 00:03:48.980
我将可视化数据并查看每个聚类有多少个数据点

00:03:48.979 --> 00:03:51.739
在这里查看标签 closest_cluster

00:03:51.740 --> 00:03:54.170
预计值为 3

00:03:54.169 --> 00:03:56.419
我将获取 cluster_info 中每个数据点的聚类标签

00:03:56.419 --> 00:03:59.244
并存储为 cluster_labels

00:03:59.245 --> 00:04:03.330
然后看看有多少数据点落入每个聚类中

00:04:03.330 --> 00:04:04.969
并输出这些计数

00:04:04.969 --> 00:04:08.009
这些值按照落入的数据点最多到最少排序

00:04:08.009 --> 00:04:11.664
大部分数据都落入了聚类 1 里

00:04:11.664 --> 00:04:14.729
注意 它们从 0 开始设定索引

00:04:14.729 --> 00:04:17.329
所以从聚类 0 到聚类 7

00:04:17.329 --> 00:04:19.925
这是另一种可视化这些计数的方式

00:04:19.925 --> 00:04:22.240
即显示为直方图

00:04:22.240 --> 00:04:26.180
如果数据聚类很不均匀

00:04:26.180 --> 00:04:30.709
那么表明所选的 k 值可能不适合区分数据

00:04:30.709 --> 00:04:34.310
但是这个图看起来分布比较均匀

00:04:34.310 --> 00:04:36.625
我存储了所有的聚类标签

00:04:36.625 --> 00:04:39.485
并且模型端点使用完毕了

00:04:39.485 --> 00:04:41.120
最后一步

00:04:41.120 --> 00:04:43.925
删除 k 均值预测器端点

00:04:43.925 --> 00:04:46.939
接下来 请你提取训练过的模型的属性

00:04:46.939 --> 00:04:50.314
从而查看数据和聚类形心

00:04:50.314 --> 00:04:52.774
我还提供了一些可视化代码

00:04:52.774 --> 00:04:55.519
最重要的是真正地了解这些数据

00:04:55.519 --> 00:04:58.954
看看郡县是如何自然分组的

00:04:58.954 --> 00:05:01.144
请自己完成这个任务

00:05:01.144 --> 00:05:04.409
遇到问题也可以参考我的答案

