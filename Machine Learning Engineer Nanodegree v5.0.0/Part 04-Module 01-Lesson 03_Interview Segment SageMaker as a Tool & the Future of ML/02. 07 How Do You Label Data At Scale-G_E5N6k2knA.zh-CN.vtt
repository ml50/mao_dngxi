WEBVTT
Kind: captions
Language: zh-CN

00:00:02.419 --> 00:00:07.035
如果我们将数据发送给人工标注者

00:00:07.035 --> 00:00:15.689
有没有什么方面可以加快 Ground Truth 功能？

00:00:15.689 --> 00:00:18.254
你想到了什么你觉得需要什么帮助？

00:00:18.254 --> 00:00:21.829
嗯我认为 理想情况下 这个流程应该自动化

00:00:21.829 --> 00:00:27.570
可以有人工介入 但是希望有个机器学习算法

00:00:28.570 --> 00:00:33.500
是的这正是我们的想法

00:00:33.500 --> 00:00:39.009
假设需要识别图像中的某些对象

00:00:39.009 --> 00:00:40.570
例如狗

00:00:40.570 --> 00:00:43.204
猫或马

00:00:43.204 --> 00:00:45.824
如果有 1,000 个图像

00:00:45.825 --> 00:00:50.650
并且有很好的随机重排机制

00:00:50.649 --> 00:00:54.799
那么前 100 个图像就可能

00:00:54.799 --> 00:00:59.509
包含你要识别的所有动物类别

00:00:59.509 --> 00:01:06.944
所以最好能从前 100 个图像中识别这些动物

00:01:06.944 --> 00:01:12.859
让机器学习模型能学习以后如何识别它们

00:01:12.859 --> 00:01:17.359
并将剩下的 900 个图像先放到机器学习模型里

00:01:17.359 --> 00:01:20.974
看看模型能否代替你识别这些动物

00:01:20.974 --> 00:01:22.964
因为是机器学习模型

00:01:22.965 --> 00:01:24.560
所以是自动化的 速度很快

00:01:24.560 --> 00:01:26.090
不需要再人工干预

00:01:26.090 --> 00:01:28.325
如果能够识别

00:01:28.325 --> 00:01:32.255
则将数据直接放到训练集中

00:01:32.254 --> 00:01:34.489
如果不能识别

00:01:34.489 --> 00:01:40.174
或者识别的置信水平不高

00:01:40.174 --> 00:01:43.685
则再发给人工注释者

00:01:43.685 --> 00:01:47.299
这正是 Amazon SageMaker Ground Truth 的功能

00:01:47.299 --> 00:01:51.259
除了能够将数据发送给

00:01:51.260 --> 00:01:55.109
最终手动标记数据的人员之外

00:01:55.109 --> 00:01:59.750
还可以创建主动学习模型

00:01:59.750 --> 00:02:04.655
在学习第一批数据后先尝试标记数据

00:02:04.655 --> 00:02:10.789
如果对未来标记数据很有信心

00:02:10.789 --> 00:02:14.164
则将数据直接放入训练集中

00:02:14.164 --> 00:02:16.324
如果没有信心 则发给人工标注者

00:02:16.324 --> 00:02:18.530
客户可以借助该功能

00:02:18.530 --> 00:02:23.090
节省 70% 的成本

00:02:23.090 --> 00:02:27.979
Autodesk 就是使用 SageMaker Ground Truth

00:02:27.979 --> 00:02:30.049
标记数据集的示例客户

00:02:30.050 --> 00:02:31.965
通过 Machine Learning Ground Truth 的自动化流程

00:02:31.965 --> 00:02:34.240
他们能够节省 70% 的成本和时间

00:02:34.240 --> 00:02:36.920
嗯你提到的置信水平很有意思

00:02:36.919 --> 00:02:40.099
对于医学影像来说

00:02:40.099 --> 00:02:42.859
影像一般需要发送给人类标注者

00:02:42.860 --> 00:02:47.390
这属于最复杂、奇怪的示例

00:02:47.389 --> 00:02:53.344
还包括有趣的图像或其他数据点

00:02:53.344 --> 00:02:59.240
该工具对学术之外的研究也很有用 太棒了

