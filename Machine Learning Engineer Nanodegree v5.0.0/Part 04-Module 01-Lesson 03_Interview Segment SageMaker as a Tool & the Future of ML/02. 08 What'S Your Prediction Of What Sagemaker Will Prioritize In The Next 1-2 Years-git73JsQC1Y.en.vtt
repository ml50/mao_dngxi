WEBVTT
Kind: captions
Language: en

00:00:01.040 --> 00:00:07.275
If you could say a prediction for something like SageMaker in the next year or two,

00:00:07.275 --> 00:00:09.509
where do you think some of your energy's will go?

00:00:09.509 --> 00:00:13.410
Will it be more data security or other kinds

00:00:13.410 --> 00:00:16.530
of features do you think you'll see more of in future?

00:00:16.530 --> 00:00:18.480
Yeah. That's a very good question.

00:00:18.480 --> 00:00:21.600
So to get back to how we build.

00:00:21.600 --> 00:00:24.795
So we do have two ways of looking at it.

00:00:24.795 --> 00:00:29.540
One is that we know a thing or two by working with a lot of customers,

00:00:29.539 --> 00:00:31.829
and then we hear a lot of needs.

00:00:31.829 --> 00:00:33.884
For example, needs four more automation,

00:00:33.884 --> 00:00:36.479
needs for more integration.

00:00:36.479 --> 00:00:40.529
If you think about operationalizing an end-to-end machine learning workflow,

00:00:40.530 --> 00:00:42.480
now you can have tools for building,

00:00:42.479 --> 00:00:43.759
you can have tools for training,

00:00:43.759 --> 00:00:45.454
you can have tools for deploying.

00:00:45.454 --> 00:00:47.449
But if you have to do that every day,

00:00:47.450 --> 00:00:51.350
then you probably want to have tools for lifecycle management, integration,

00:00:51.350 --> 00:00:54.170
experiment management, workflows, and all these other things

00:00:54.170 --> 00:00:57.315
that really automate the whole thing.

00:00:57.314 --> 00:00:59.780
So towards the end of last year,

00:00:59.780 --> 00:01:04.629
we announced a lot of peripheral features around SageMaker.

00:01:04.629 --> 00:01:07.814
Features for serverless integration, for example.

00:01:07.814 --> 00:01:11.284
Features for GitHub integration to enable collaboration.

00:01:11.284 --> 00:01:14.209
Features for experiment management to be able to

00:01:14.209 --> 00:01:17.959
compare the results that you have from two different machine learning models,

00:01:17.959 --> 00:01:22.689
and then look at them side-by-side and see which ones satisfy your metrics.

00:01:22.689 --> 00:01:30.109
So we are heavily investing into really connecting the dots in an end-to-end lifecycle.

00:01:30.109 --> 00:01:34.739
This is other thing that is happening where once you have a machine learning model,

00:01:34.739 --> 00:01:38.644
there's really three ways you can employ the model.

00:01:38.644 --> 00:01:40.894
One is that you can have that behind

00:01:40.894 --> 00:01:47.524
a real time endpoint web application that can serve real traffic.

00:01:47.525 --> 00:01:51.740
The second thing is that you can use that for batch processing.

00:01:51.739 --> 00:01:55.879
For example, you want to crunch the sales of the last month or year,

00:01:55.879 --> 00:01:58.909
and then you can pass the data through batch scoring exercise.

00:01:58.909 --> 00:02:02.929
The third one that is becoming more and more popular nowadays is that you really

00:02:02.930 --> 00:02:07.495
want to get a machine learning models closest to the users as possible.

00:02:07.495 --> 00:02:11.390
So, for example, you want to be able to put a machine learning model in the device

00:02:11.389 --> 00:02:15.169
like the Echo device closer to the user,

00:02:15.169 --> 00:02:16.733
or in a mobile application,

00:02:16.734 --> 00:02:18.930
or in an IoT device,

00:02:18.930 --> 00:02:21.564
or predictive agriculture, or something like that,

00:02:21.564 --> 00:02:24.680
or in an Internet disconnected area.

00:02:24.680 --> 00:02:29.480
So you can put the machine learning model and a small tool that you can use

00:02:29.479 --> 00:02:32.239
to look at a crop and then see if that crop

00:02:32.240 --> 00:02:35.455
is healthy in an area that is not connected to the Internet.

00:02:35.455 --> 00:02:39.710
Then these ecosystems come with their own challenges because you have

00:02:39.710 --> 00:02:44.045
to get the model to be tiny enough to fit into those little devices.

00:02:44.044 --> 00:02:47.244
So we put a lot of energy around that to make sure that

00:02:47.245 --> 00:02:50.930
after you train a machine learning model on the Cloud with a lot of GPUs,

00:02:50.930 --> 00:02:52.474
you can compile that,

00:02:52.474 --> 00:02:57.715
get it smaller, but maintain the same amount of accuracy that you can maintain,

00:02:57.715 --> 00:03:01.759
and increase the performance because the model is a lot smaller but high performance.

00:03:01.759 --> 00:03:04.579
Then put that in those devices and really bring

00:03:04.580 --> 00:03:08.300
machine learning models closest to the users in a data as possible.

00:03:08.300 --> 00:03:10.625
So you should expect us to put

00:03:10.625 --> 00:03:14.750
more energy around these kinds of challenges that we're seeing in a field,

00:03:14.750 --> 00:03:17.479
like where do machine learning models reading it to be,

00:03:17.479 --> 00:03:20.405
and find ways to build technology around that.

00:03:20.405 --> 00:03:23.930
What is the lifecycle of automating machine learning models and

00:03:23.930 --> 00:03:27.980
operationalizing that and in building technology to connect these dots.

00:03:27.979 --> 00:03:29.224
Of course, like I say,

00:03:29.224 --> 00:03:32.090
90 to 95 percent of the time we just talked to customers and trying

00:03:32.090 --> 00:03:35.134
to find out what they want and we built that.

00:03:35.134 --> 00:03:37.399
So, yes, we're building according to what we know,

00:03:37.400 --> 00:03:41.125
but we're also building according to the needs that are there, existing out there.

00:03:41.125 --> 00:03:44.000
I'm curious to know a bit more about your background.

00:03:44.000 --> 00:03:48.335
How did you become interested in machine learning and make your way to Amazon?

00:03:48.335 --> 00:03:52.564
Sure. I did study physics and computer science,

00:03:52.564 --> 00:03:53.990
so that's my background.

00:03:53.990 --> 00:03:57.050
I did work as a deployment engineer in the past,

00:03:57.050 --> 00:04:01.350
and I did work as an on-site engineer in payment systems,

00:04:01.349 --> 00:04:06.069
and eventually into big data and Hadoop type of technologies.

00:04:06.069 --> 00:04:10.984
So I've always been around science, and engineering,

00:04:10.985 --> 00:04:14.000
and building systems, and deploying systems,

00:04:14.000 --> 00:04:17.014
and trying to integrate them at scale.

00:04:17.014 --> 00:04:21.430
So when I got into Amazon about five-and-a-half years ago,

00:04:21.430 --> 00:04:25.125
I got in as a Hadoop Engineering Manager,

00:04:25.125 --> 00:04:29.569
where I built a team of Hadoop and big data engineers.

00:04:29.569 --> 00:04:34.920
What we were doing there back then really was to play with the Hadoop tools,

00:04:34.920 --> 00:04:38.515
Spark, when it came out and the other tools in the ecosystem.

00:04:38.514 --> 00:04:45.964
Essentially, it was a time when big data was growing big as a field.

00:04:45.964 --> 00:04:48.875
It was still [inaudible] it but it was growing a little bit.

00:04:48.875 --> 00:04:53.165
The small analogy that I draw with the times today is,

00:04:53.165 --> 00:04:57.995
machine learning is today a little bit what big data was five or six years ago,

00:04:57.995 --> 00:05:00.800
where a lot of people who are getting into the field,

00:05:00.800 --> 00:05:07.625
but the technology wasn't really there yet to help people adopt big data.

00:05:07.625 --> 00:05:08.540
It's playing catch up.

00:05:08.540 --> 00:05:09.700
Yeah. It's playing catch up.

00:05:09.699 --> 00:05:14.060
So it was very useful from our perspective, from my perspective,

00:05:14.060 --> 00:05:16.579
to observe the investments that

00:05:16.579 --> 00:05:20.029
AWS put into building Amazon Elastic MapReduce, for example,

00:05:20.029 --> 00:05:21.738
that made Hadoop accessible,

00:05:21.738 --> 00:05:26.029
and then the other tools on top of the Hadoop ecosystem and make that accessible.

00:05:26.029 --> 00:05:28.594
So I spent some time in that ecosystem,

00:05:28.595 --> 00:05:32.975
and then when we started investing into building machine learning platforms,

00:05:32.975 --> 00:05:36.485
it was basically a repeat of what we've done with big data,

00:05:36.485 --> 00:05:39.300
and that's how I got into machine learning.

00:05:39.300 --> 00:05:44.014
But to get myself ready before actually doing machine learning full-time,

00:05:44.014 --> 00:05:45.905
I was taking courses online.

00:05:45.904 --> 00:05:50.994
I took the Coursera course by the famous Andrew Ing, what?

00:05:50.995 --> 00:05:54.855
Six, seven years ago now, 2012, 2011.

00:05:54.855 --> 00:05:59.629
So there's this continuous and perpetual learning aspect

00:05:59.629 --> 00:06:04.603
that has always been part of my process where I want to learn new languages,

00:06:04.603 --> 00:06:07.069
I want to learn new tools,

00:06:07.069 --> 00:06:08.659
I want to learn new technology,

00:06:08.660 --> 00:06:12.605
and machine learning was naturally fitting in that mindset.

00:06:12.605 --> 00:06:14.700
That's really how I got into it.

