WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.135
原始 XGBoost 模型已部署

00:00:03.135 --> 00:00:06.720
可以帮助设置我们要解决的情形

00:00:06.720 --> 00:00:10.590
我们有理由认为

00:00:10.590 --> 00:00:14.775
我们要解决的问题性质发生了变化

00:00:14.775 --> 00:00:17.940
这种变化体现在

00:00:17.940 --> 00:00:21.260
模型的效果不如当初

00:00:21.260 --> 00:00:24.720
我们想知道发生了什么

00:00:24.720 --> 00:00:31.770
为何新数据的分类效果不如原始数据？

00:00:31.770 --> 00:00:33.610
下面开始研究发生的情况

00:00:33.610 --> 00:00:41.110
我们将查看分类错误的影评示例

00:00:41.110 --> 00:00:44.825
看看发生了什么

00:00:44.825 --> 00:00:50.825
顺便提下 我将此方法创建成了生成器,

00:00:50.825 --> 00:00:55.760
如果你之前没有使用过 Python 生成器

00:00:55.760 --> 00:00:57.810
建议了解一下

00:00:57.810 --> 00:01:00.470
简单来说

00:01:00.470 --> 00:01:04.700
你只需将 return 语句换成 yield 语句

00:01:04.700 --> 00:01:10.405
一旦有一个可用的返回值

00:01:10.405 --> 00:01:12.770
它将返回该值

00:01:12.770 --> 00:01:15.460
然后当你第二次对生成的生成器调用 next() 时

00:01:15.460 --> 00:01:18.835
它将从上次停下的地方继续

00:01:18.835 --> 00:01:21.200
在这个 for 循环里

00:01:21.200 --> 00:01:25.730
我遍历了新数据集中的每行

00:01:25.730 --> 00:01:30.590
发现第一个分类错误的影评示例后

00:01:30.590 --> 00:01:34.015
它将返回结果 停止循环

00:01:34.015 --> 00:01:35.875
但是从某种程度上来说

00:01:35.875 --> 00:01:38.810
并没有完全停止循环

00:01:38.810 --> 00:01:42.260
稍后可以继续寻找下个示例

00:01:42.260 --> 00:01:47.360
通过这种方式可以浏览大量数据

00:01:47.360 --> 00:01:49.910
并找到反例 因为我们不需要

00:01:49.910 --> 00:01:52.640
处理整个新数据集

00:01:52.640 --> 00:01:54.080
原理是

00:01:54.080 --> 00:01:57.890
首先创建一个包含 yield 关键字的方法

00:01:57.890 --> 00:02:01.955
我们使用该方法创建一个生成器

00:02:01.955 --> 00:02:05.030
然后 每当我对生成器调用 next() 时

00:02:05.030 --> 00:02:07.730
它将为我找到下个反例

00:02:07.730 --> 00:02:09.475
这是第一个反例

00:02:09.475 --> 00:02:15.650
这就属于 XGBoost 模型分类错误的影评示例

00:02:15.650 --> 00:02:17.930
如果再次执行该单元格

00:02:17.930 --> 00:02:19.280
将获得另一个示例

00:02:19.280 --> 00:02:20.855
如果再执行一次

00:02:20.855 --> 00:02:22.555
又获得另一个示例

00:02:22.555 --> 00:02:28.280
我们可以通过种方法看看一些分类错误的影评

00:02:28.280 --> 00:02:30.935
假设查看了这些分类错误的影评后

00:02:30.935 --> 00:02:34.940
你认为问题之一是原始数据集与新数据集

00:02:34.940 --> 00:02:39.440
对字词的使用不一样了

00:02:39.440 --> 00:02:44.630
查看这种不一致性的一种方式是

00:02:44.630 --> 00:02:50.065
查看两个数据集中词频排名前 5000 的字词

00:02:50.065 --> 00:02:52.620
5,000 并不是随机选择的数字

00:02:52.620 --> 00:02:54.410
它是词汇表的大小

00:02:54.410 --> 00:02:58.250
还可以理解成

00:02:58.250 --> 00:03:02.765
我将比较一开始创建模型时使用的词汇表

00:03:02.765 --> 00:03:08.480
以及使用新数据训练模型时会用到的词汇表

00:03:08.480 --> 00:03:09.920
下面

00:03:09.920 --> 00:03:14.215
我们创建一个 CountVectorizer 并用它拟合新数据

00:03:14.215 --> 00:03:17.735
看看生成的词汇表如何

00:03:17.735 --> 00:03:21.965
CountVectorizer 拟合新数据后

00:03:21.965 --> 00:03:25.670
创建一个包含原始词汇表中字词的集合

00:03:25.670 --> 00:03:30.375
以及一个包含新词汇表中字词的集合

00:03:30.375 --> 00:03:32.600
看看二者的区别

00:03:32.600 --> 00:03:33.830
这行代码

00:03:33.830 --> 00:03:37.460
将获取原始词汇表中的所有字词

00:03:37.460 --> 00:03:41.615
并删除同时出现在新词汇表中的字词

00:03:41.615 --> 00:03:43.585
然后显示剩下的字词

00:03:43.585 --> 00:03:47.630
同理 这行将获取新词汇表中的所有字词

00:03:47.630 --> 00:03:53.134
并删除同时出现在原始词汇表中的字词

00:03:53.134 --> 00:03:54.955
剩下这些字词

00:03:54.955 --> 00:03:57.710
我并不打算立即说出答案

00:03:57.710 --> 00:04:00.680
希望保持开放式答案

00:04:00.680 --> 00:04:03.155
但是在下一步

00:04:03.155 --> 00:04:05.810
建议看看这些字词

00:04:05.810 --> 00:04:09.415
出现在各自训练集中的次数

00:04:09.415 --> 00:04:14.315
例如 spill 出现在原始训练集中的次数是多少？

00:04:14.315 --> 00:04:18.740
masterson 出现在新数据集中的次数是多少？

00:04:18.740 --> 00:04:21.200
你可能认为这些字词

00:04:21.200 --> 00:04:24.245
在各自数据集中的出现次数并不多

00:04:24.245 --> 00:04:26.685
但是如果次数很多

00:04:26.685 --> 00:04:29.270
那么表示可能存在问题

