WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.100
现在我们有理由认为

00:00:02.100 --> 00:00:05.160
数据的底层分布发生了变化

00:00:05.160 --> 00:00:07.860
建议的解决方案是

00:00:07.860 --> 00:00:12.345
用新数据训练新的模型并替换旧模型

00:00:12.345 --> 00:00:15.900
首先 我们需要创建有效的训练集

00:00:15.900 --> 00:00:22.320
之前 我们使用新影评创建了新的词汇表

00:00:22.320 --> 00:00:25.140
现在需要使用新词汇表

00:00:25.140 --> 00:00:28.465
创建表示新数据的词袋

00:00:28.465 --> 00:00:30.470
操作完毕后 快速检查下

00:00:30.470 --> 00:00:35.040
看看用新词袋编码的数据集的大小

00:00:35.040 --> 00:00:39.970
是否等于要使用的词汇表的长度

00:00:39.970 --> 00:00:42.885
我们的词汇表长度为 5,000

00:00:42.885 --> 00:00:47.195
所以每行的长度应该为 5,000 的确是

00:00:47.195 --> 00:00:51.830
检查完毕后 我们需要将新数据拆分成训练集和验证集

00:00:51.830 --> 00:00:55.145
并将新数据以及新训练集和验证集

00:00:55.145 --> 00:00:59.000
保存到本地实例中

00:00:59.000 --> 00:01:04.360
然后 使用 upload_data 方法将所有数据上传到 S3

00:01:04.360 --> 00:01:08.060
从而创建和训练新的 XGBoost 模型

00:01:08.060 --> 00:01:10.235
首先设置一个 estimator 对象

00:01:10.235 --> 00:01:11.660
这里使用的超参数

00:01:11.660 --> 00:01:15.320
与原始 XGBoost 模型的超参数一样

00:01:15.320 --> 00:01:17.335
创建 estimator 对象后

00:01:17.335 --> 00:01:24.470
调用 fit() 方法并用新的 XGBoost 模型拟合新数据集

00:01:24.470 --> 00:01:26.030
下面看看新模型

00:01:26.030 --> 00:01:29.570
是否能达到预期行为

00:01:29.570 --> 00:01:32.555
一般 我们首先会

00:01:32.555 --> 00:01:36.185
用训练模型的数据测试新模型

00:01:36.185 --> 00:01:39.425
实际上这种做法不可取

00:01:39.425 --> 00:01:42.875
因为我们使用了新数据训练模型

00:01:42.875 --> 00:01:47.465
使用相同的数据测试模型属于典型的数据泄露问题

00:01:47.465 --> 00:01:50.735
在实际操作中千万不要犯这种错误

00:01:50.735 --> 00:01:53.030
我们这么测试只是为了

00:01:53.030 --> 00:01:55.555
有一个数值基准可以进行比较

00:01:55.555 --> 00:01:57.725
为了测试新模型

00:01:57.725 --> 00:02:00.395
我们将创建新的 transformer 对象

00:02:00.395 --> 00:02:05.255
并用该对象创建一个转换作业用在新数据上

00:02:05.255 --> 00:02:07.625
转换作业运行完毕后

00:02:07.625 --> 00:02:11.855
将结果复制到本地实例上 并看看模型的表现

00:02:11.855 --> 00:02:15.895
看来新模型在新数据上的表现很好

00:02:15.895 --> 00:02:20.020
肯定很好 因为新模型是用相同的数据训练的

00:02:20.020 --> 00:02:22.910
还要检查的是

00:02:22.910 --> 00:02:26.640
模型在旧数据上是否也相对不错

00:02:26.640 --> 00:02:30.395
我们不希望数据分布已经明显改变

00:02:30.395 --> 00:02:34.910
导致新模型在旧数据上的表现很糟糕

00:02:34.910 --> 00:02:40.300
首先读取原始测试集 然后转换它

00:02:40.300 --> 00:02:45.920
因为新模型使用的是新词汇表

00:02:45.920 --> 00:02:48.690
所以在用词袋

00:02:48.690 --> 00:02:51.745
编码原始测试集时

00:02:51.745 --> 00:02:54.215
我们将使用新词汇表

00:02:54.215 --> 00:02:57.005
使用之前创建的 new_vectorizer

00:02:57.005 --> 00:03:01.595
将原始测试集转换成词袋版本

00:03:01.595 --> 00:03:05.125
然后 将结果写入本地实例中

00:03:05.125 --> 00:03:07.075
并将文件上传到 S3 上

00:03:07.075 --> 00:03:09.995
然后使用新模型转换它

00:03:09.995 --> 00:03:12.350
看看模型的效果如何

00:03:12.350 --> 00:03:14.690
似乎并不糟糕

00:03:14.690 --> 00:03:17.520
看来新的 XGBoost 模型

00:03:17.520 --> 00:03:21.070
行为完全符合我们的预期

00:03:21.070 --> 00:03:25.480
它在新数据和旧数据上的表现都不错

00:03:25.480 --> 00:03:27.470
似乎可以将现有端点

00:03:27.470 --> 00:03:30.455
切换为使用新的模型

00:03:30.455 --> 00:03:33.140
因为我们假设有一个

00:03:33.140 --> 00:03:36.665
使用原始模型的应用正在运行

00:03:36.665 --> 00:03:39.995
所以需要使用 SageMaker 的更新功能

00:03:39.995 --> 00:03:42.530
这样的话 端点就不会关闭

00:03:42.530 --> 00:03:45.690
为了更新端点

00:03:45.690 --> 00:03:48.300
我们需要创建新的端点配置

00:03:48.300 --> 00:03:50.850
为了创建端点配置

00:03:50.850 --> 00:03:54.440
我们需要知道要向其发送数据的模型的名称

00:03:54.440 --> 00:03:59.165
我们可以从之前创建的 transformer 对象中获取该名称

00:03:59.165 --> 00:04:01.005
获得模型名称后

00:04:01.005 --> 00:04:03.855
我们可以创建一个新的端点配置

00:04:03.855 --> 00:04:05.100
我们创建的端点配置

00:04:05.100 --> 00:04:08.525
只有一个生产变体

00:04:08.525 --> 00:04:11.015
即新的 XGBoost 模型

00:04:11.015 --> 00:04:13.945
创建了端点配置后

00:04:13.945 --> 00:04:17.490
我们可以要求 SageMaker 更新现有端点

00:04:17.490 --> 00:04:22.225
使其新配置使用新的 XGBoost 模型

00:04:22.225 --> 00:04:24.055
在现实中

00:04:24.055 --> 00:04:25.740
这项工作已经完成的很好

00:04:25.740 --> 00:04:27.495
我们诊断出问题

00:04:27.495 --> 00:04:29.190
创建了问题解决方案

00:04:29.190 --> 00:04:36.200
然后更新了端点 并且最终用户不会体验到服务中断现象

00:04:36.200 --> 00:04:38.975
因为我们不再需要这个部署端点

00:04:38.975 --> 00:04:40.520
所以应该删除该端点

00:04:40.520 --> 00:04:43.820
最后 我还要指出几个其他问题

00:04:43.820 --> 00:04:45.919
这些问题并没有什么标准答案

00:04:45.919 --> 00:04:49.490
例如 如果我们要尝试创建情感分析模型

00:04:49.490 --> 00:04:53.475
底层分布还会有哪些改变

00:04:53.475 --> 00:04:56.020
这个问题在应用中的用处更大

00:04:56.020 --> 00:04:59.290
而不仅仅是判断影评是正面的还是负面的

00:04:59.290 --> 00:05:01.180
例如 在某些情形下

00:05:01.180 --> 00:05:04.090
企业会根据股东的

00:05:04.090 --> 00:05:06.460
情感分析报告

00:05:06.460 --> 00:05:09.250
判断某支股票表现不错还是表现很差

00:05:09.250 --> 00:05:11.980
还有一个问题 因为我们不希望新模型

00:05:11.980 --> 00:05:14.530
与原始模型的差别很大

00:05:14.530 --> 00:05:18.165
那么仅使用新数据训练模型合适吗？

00:05:18.165 --> 00:05:21.025
应该以某种方式混合数据吗？

00:05:21.025 --> 00:05:24.430
如果应该混合 混合比例是多少？

00:05:24.430 --> 00:05:26.725
最后 在本示例中

00:05:26.725 --> 00:05:29.390
我们收到了大量新数据

00:05:29.390 --> 00:05:31.115
足以用来训练模型

00:05:31.115 --> 00:05:33.575
但是如果样本量少多了呢？

00:05:33.575 --> 00:05:37.745
假设新数据集只有 500 个样本

00:05:37.745 --> 00:05:39.860
不足以创建新的模型

00:05:39.860 --> 00:05:42.785
但是足以知道旧模型表现不佳

00:05:42.785 --> 00:05:45.090
如何解决该问题？正如我刚刚提到的

00:05:45.090 --> 00:05:46.910
这些是开放式问题

00:05:46.910 --> 00:05:49.020
没有什么标准答案

00:05:49.020 --> 00:05:51.350
只是让你感受在现实中

00:05:51.350 --> 00:05:54.530
可能需要思考的问题

