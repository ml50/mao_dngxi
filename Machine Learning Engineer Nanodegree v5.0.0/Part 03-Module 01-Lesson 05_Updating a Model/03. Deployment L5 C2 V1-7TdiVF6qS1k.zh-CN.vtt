WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.150
我们创建了一个 XGBoost 模型

00:00:03.150 --> 00:00:06.285
并将模型部署到了应用中

00:00:06.285 --> 00:00:08.985
但是因为某种原因

00:00:08.985 --> 00:00:12.115
该 XGBoost 模型太复杂

00:00:12.115 --> 00:00:16.789
也许在推理时占用太多资源

00:00:16.789 --> 00:00:19.040
或者我们需要多次使用它

00:00:19.040 --> 00:00:21.550
或者我们无法很好地解释它的运行原理

00:00:21.550 --> 00:00:23.210
所以我们非常希望

00:00:23.210 --> 00:00:26.095
有一个能解释的更简单模型

00:00:26.095 --> 00:00:31.280
无论是何种情况 都假设现在我们想创建一个线性模型

00:00:31.280 --> 00:00:35.650
创建线性模型的方式与创建 XGBoost 模型的很相似

00:00:35.650 --> 00:00:40.050
先通过高阶方法创建模型工件

00:00:40.050 --> 00:00:43.205
首先创建一个 estimator 对象

00:00:43.205 --> 00:00:47.300
确保在训练过程中使用的容器是

00:00:47.300 --> 00:00:51.895
linear-learner 容器 和 XGBoost 模型一样

00:00:51.895 --> 00:00:55.790
我们需要设定特定于此算法的超参数

00:00:55.790 --> 00:00:59.120
数据有 13 个特征

00:00:59.120 --> 00:01:02.690
所以需要将特征维数设为 13

00:01:02.690 --> 00:01:06.500
我们将使用回归 因为要预测实数

00:01:06.500 --> 00:01:11.555
linear-learner 算法

00:01:11.555 --> 00:01:13.775
在创建线性模型时

00:01:13.775 --> 00:01:16.640
将采用迷你批次

00:01:16.640 --> 00:01:22.175
它会使用梯度下降法拟合模型

00:01:22.175 --> 00:01:27.454
我们可以在这里设定每个迷你批次的行数

00:01:27.454 --> 00:01:29.160
设置了超参数后

00:01:29.160 --> 00:01:32.990
调用 fit() 方法

00:01:32.990 --> 00:01:37.625
SageMaker 将为线性模型创建模型工件

00:01:37.625 --> 00:01:40.040
拟合了线性模型后

00:01:40.040 --> 00:01:42.140
我们将部署模型

00:01:42.140 --> 00:01:44.810
方式与部署 XGBoost 模型的几乎一样

00:01:44.810 --> 00:01:50.480
首先在 SageMaker 中创建一个模型对象

00:01:50.480 --> 00:01:53.435
指定模型工件的存储位置

00:01:53.435 --> 00:01:56.510
以及推理用到的容器

00:01:56.510 --> 00:01:59.315
然后创建端点配置

00:01:59.315 --> 00:02:01.475
与 XGBoost 示例一样,

00:02:01.475 --> 00:02:04.280
我们只有一个生产变体

00:02:04.280 --> 00:02:07.105
称之为 Linear-Model

00:02:07.105 --> 00:02:11.000
创建了使用新训练的模型的端点配置后

00:02:11.000 --> 00:02:15.185
我们可以要求 SageMaker 使用这些属性创建一个端点

00:02:15.185 --> 00:02:17.195
设置好端点后

00:02:17.195 --> 00:02:19.700
我们可以测试模型

00:02:19.700 --> 00:02:22.475
看看一切是否都按预期运行

00:02:22.475 --> 00:02:25.280
与 XGBoost 端点一样

00:02:25.280 --> 00:02:27.320
我们将发送第一行测试数据

00:02:27.320 --> 00:02:30.200
首先序列化数据 然后发送给端点

00:02:30.200 --> 00:02:33.140
与 XGBoost 示例一样

00:02:33.140 --> 00:02:36.050
获得的响应是 JSON 对象

00:02:36.050 --> 00:02:39.905
告诉我们返回类型是 JSON 数据

00:02:39.905 --> 00:02:44.590
使用的变体是 Linear-Model

00:02:44.590 --> 00:02:46.640
当然 使用的变体肯定是 Linear-Model

00:02:46.640 --> 00:02:49.640
因为我们仅列出了一个生产变体

00:02:49.640 --> 00:02:54.620
下面读取 body 对象并转换成字符串

00:02:54.620 --> 00:03:00.875
正如 response 变量所描述的 我们获得的返回内容是 JSON 数据

00:03:00.875 --> 00:03:03.280
是一个 JSON 对象

00:03:03.280 --> 00:03:06.575
其中包含分数 35.8

00:03:06.575 --> 00:03:09.320
将这个分数与真实值进行比较

00:03:09.320 --> 00:03:11.120
可以看到 对于这个分数来说

00:03:11.120 --> 00:03:14.840
线性模型比 XGBoost 模型的效果稍微好些

00:03:14.840 --> 00:03:17.360
当然 只查看一个数据点

00:03:17.360 --> 00:03:20.600
并不能很好地判断模型的行为效果

00:03:20.600 --> 00:03:23.580
但是至少也是一项数据

00:03:23.580 --> 00:03:26.765
接下来 因为我们并不单独使用线性模型

00:03:26.765 --> 00:03:29.040
所以将关闭端点

