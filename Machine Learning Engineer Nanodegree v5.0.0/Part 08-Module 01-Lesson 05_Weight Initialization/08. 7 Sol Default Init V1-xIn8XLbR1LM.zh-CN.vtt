WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.065
下面说说我的实现方法

00:00:02.065 --> 00:00:04.920
我创建了一个函数 它会使用

00:00:04.920 --> 00:00:08.020
从正态分布里取样的值初始化模型的权重

00:00:08.020 --> 00:00:11.690
它是另一个可以应用到模块权重上的函数

00:00:11.690 --> 00:00:14.220
在这里定义一个分布

00:00:14.220 --> 00:00:17.935
均值为 0 标准差为 1/√n￣

00:00:17.935 --> 00:00:20.970
n 表示给定层级的输入数量

00:00:20.970 --> 00:00:23.625
因此这些权重所在的范围

00:00:23.625 --> 00:00:26.450
应该根据线性层级的输入数量变化

00:00:26.450 --> 00:00:28.700
像往常一样 偏差的权重设为 0

00:00:28.700 --> 00:00:31.365
然后创建两个模型加以比较

00:00:31.365 --> 00:00:33.400
首先是 model_uniform_rule

00:00:33.400 --> 00:00:37.965
使用上面的函数 weights_init_uniform_rule 初始化权重

00:00:37.965 --> 00:00:41.000
然后创建另一个模型

00:00:41.000 --> 00:00:44.465
它使用在这里定义的函数 权重来自正态分布

00:00:44.465 --> 00:00:48.040
对我来说 先创建新的模型 然后再比较模型 这样最简单

00:00:48.040 --> 00:00:50.210
因为这样我就能避免

00:00:50.210 --> 00:00:52.705
两个模型的训练轮数不一致的情况

00:00:52.705 --> 00:00:54.740
初始化两个模型后

00:00:54.740 --> 00:00:59.735
通过创建模型列表并使用 compare_init_weights 函数比较这两个模型

00:00:59.735 --> 00:01:02.210
此图显示了分别用正态分布和均匀分布

00:01:02.210 --> 00:01:07.160
两个初始化权重的模型行为比较相似

00:01:07.160 --> 00:01:10.360
注意 这里的起始损失值很低

00:01:10.360 --> 00:01:14.050
两个模型相似的行为可能是因为网络很小

00:01:14.050 --> 00:01:18.425
大型网络将从这两个分布中选择更多权重值

00:01:18.425 --> 00:01:21.910
两种初始化方式的效果就会有更明显的区分

00:01:21.910 --> 00:01:25.400
如果正态分布表明有很小的改善

00:01:25.400 --> 00:01:28.835
那么可以想象对大型模型的改善会放大

00:01:28.835 --> 00:01:32.015
我还要指出 我们取得了很大的成果

00:01:32.015 --> 00:01:35.090
上拉页面 看看常量权重值

00:01:35.090 --> 00:01:37.505
可以看出模型改善了很多

00:01:37.505 --> 00:01:40.445
最初是效果很差的常量权重

00:01:40.445 --> 00:01:43.645
然后 我们使用均匀分布引入随机性

00:01:43.645 --> 00:01:48.660
使模型能犯更有启发性的错误

00:01:48.660 --> 00:01:52.670
最后我们了解了选择权重范围的一般法则

00:01:52.670 --> 00:01:55.720
该范围取决于层级看到的输入数量

00:01:55.720 --> 00:01:58.865
现在可以看出 在训练过程中

00:01:58.865 --> 00:02:04.155
从均匀分布或正态分布中选择权重有助于模型快速达到较高的准确率

00:02:04.155 --> 00:02:06.965
现在再测试一种模型

00:02:06.965 --> 00:02:10.195
这种模型没有明确的初始化方法

00:02:10.195 --> 00:02:13.430
在这里直接实例化一个模型

00:02:13.430 --> 00:02:17.025
不传入任何参数并且不应用任何初始权重

00:02:17.025 --> 00:02:21.965
将此模型和名称传入比较函数中

00:02:21.965 --> 00:02:26.110
可以看到默认行为效果很不错

00:02:26.110 --> 00:02:28.600
看起来和根据均匀分布

00:02:28.600 --> 00:02:31.540
初始化权重的模型行为很像

00:02:31.540 --> 00:02:34.840
这是因为每种 PyTorch 层级

00:02:34.840 --> 00:02:38.245
在后台都有一种默认的权重初始化方式

00:02:38.245 --> 00:02:43.600
我们可以通过查看模块源代码了解这种默认初始化方式

00:02:43.600 --> 00:02:47.615
这是 PyTorch 中线性层级的源代码

00:02:47.615 --> 00:02:50.080
在这个 reset_parameters 函数中可以看出

00:02:50.080 --> 00:02:52.300
每个线性层级的初始权重

00:02:52.300 --> 00:02:56.285
都来自均匀分布

00:02:56.285 --> 00:02:59.895
甚至偏差都具有随机范围

00:02:59.895 --> 00:03:03.930
但是要注意这种默认初始化方式

00:03:03.930 --> 00:03:07.025
通常根据正态分布初始化权重

00:03:07.025 --> 00:03:10.730
能够获得更好的结果

00:03:10.730 --> 00:03:14.150
因此正态分布依然很有用

00:03:14.150 --> 00:03:16.460
尤其当你尝试训练最佳模型

00:03:16.460 --> 00:03:19.125
并根据你定义的规则初始化模型权重的时候

00:03:19.125 --> 00:03:21.670
学习之路并不是到此就结束了

00:03:21.670 --> 00:03:23.780
建议你查看各种不同类型的

00:03:23.780 --> 00:03:26.985
初始化分布文档

00:03:26.985 --> 00:03:29.065
当你继续在此课堂里学习教程时

00:03:29.065 --> 00:03:33.730
我们会提供更多关于学习和练习权重初始化的资源

