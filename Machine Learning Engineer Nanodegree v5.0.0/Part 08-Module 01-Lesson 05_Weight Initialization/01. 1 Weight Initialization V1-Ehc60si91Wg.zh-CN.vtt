WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.845
你已经学了很多 CNN 知识

00:00:02.845 --> 00:00:06.240
在这节课 我将详细介绍

00:00:06.240 --> 00:00:09.879
在 PyTorch 中构建和训练神经网络时在后台发生的情况

00:00:09.879 --> 00:00:11.970
也就是权重初始化

00:00:11.970 --> 00:00:15.330
权重初始化发生在模型创建时

00:00:15.330 --> 00:00:17.315
并发生在模型看到任何训练数据之前

00:00:17.315 --> 00:00:21.000
通常只在模型第一次创建时初始化

00:00:21.000 --> 00:00:25.730
模型初始化是指实例化 CNN 等模型的方式

00:00:25.730 --> 00:00:27.910
能使模型权重（参数）针对给定任务

00:00:27.910 --> 00:00:31.830
设成最佳初始值

00:00:31.830 --> 00:00:33.360
可以这么理解

00:00:33.360 --> 00:00:36.765
模型中的任何神经元都具有权重和偏差

00:00:36.765 --> 00:00:40.590
这些权重和偏差会对输入值执行运算并转换为期望的输出

00:00:40.590 --> 00:00:44.640
这是将输入图像转换为类别分数的方式

00:00:44.640 --> 00:00:48.490
模型将尝试学习将输入映射到输出的最佳权重

00:00:48.490 --> 00:00:51.280
即最准确地分类给定图像

00:00:51.280 --> 00:00:52.715
在进行迁移学习时

00:00:52.715 --> 00:00:56.270
我们已知某些权重对图像分类来说是最佳值

00:00:56.270 --> 00:00:59.570
然后 我们会使用这些最佳预训练权重来初始化网络

00:00:59.570 --> 00:01:01.620
但是对于非预训练网络来说

00:01:01.620 --> 00:01:03.640
该如何初始化权重？

00:01:03.640 --> 00:01:07.340
我们可以首先将权重都初始化为 0

00:01:07.340 --> 00:01:10.100
然后训练权重并上下调整它们

00:01:10.100 --> 00:01:12.270
或者可以初始化为很大的权重值

00:01:12.270 --> 00:01:13.815
甚至使用随机值

00:01:13.815 --> 00:01:15.155
看看会发生什么

00:01:15.155 --> 00:01:18.270
我们将在这个 notebook 中探讨这些问题

00:01:18.270 --> 00:01:20.300
现在我将在此 notebook 中演示

00:01:20.300 --> 00:01:23.089
不同权重初始化策略的效果

00:01:23.089 --> 00:01:25.505
我们将讨论如何决定初始权重

00:01:25.505 --> 00:01:28.470
以及在训练过程中 什么样的初始行为是好的行为

00:01:28.470 --> 00:01:32.300
像往常一样 我们将在 GitHub 代码库中公开提供这些代码

00:01:32.300 --> 00:01:34.935
因此你也可以自己修改代码

00:01:34.935 --> 00:01:36.255
看看结果如何

00:01:36.255 --> 00:01:39.415
我们想要定义一种模型 一个简单的 MLP

00:01:39.415 --> 00:01:42.590
我们将用不同的值初始化模型的权重

00:01:42.590 --> 00:01:47.335
并比较在 1-2 个训练周期之后训练损失的降低情况

00:01:47.335 --> 00:01:50.105
即 用不同的权重初始化相同模型

00:01:50.105 --> 00:01:53.030
我们在此图中绘制出了

00:01:53.030 --> 00:01:56.275
两个不同初始化方法在 100 批数据上的训练损失

00:01:56.275 --> 00:01:57.730
这只是两个例子

00:01:57.730 --> 00:02:00.020
某些初始化策略

00:02:00.020 --> 00:02:02.625
可能对降低损失改进很大

00:02:02.625 --> 00:02:04.475
其他策略可能对损失改进不大

00:02:04.475 --> 00:02:06.885
例如在此图中 很难判断区别

00:02:06.885 --> 00:02:10.224
但是无论影响大还是小 我们都能从这些差别中汲取经验

00:02:10.224 --> 00:02:13.040
因此我们将定义一个简单的 MLP

00:02:13.040 --> 00:02:15.965
用于分类 Fashion-MNIST 数据集中的图像

00:02:15.965 --> 00:02:20.470
在前几个单元格中 我将加载数据 批次大小为 100

00:02:20.470 --> 00:02:24.495
Fashion-MNIST 数据集中的图像分成 10 个类别

00:02:24.495 --> 00:02:25.880
包括 T恤 衬衫

00:02:25.880 --> 00:02:28.420
运动鞋 包 短靴等

00:02:28.420 --> 00:02:32.200
这是其中一些图像样本以及相应的标签

00:02:32.200 --> 00:02:33.950
你可能之前已经见过此数据集

00:02:33.950 --> 00:02:36.795
它只是一个服饰类型灰阶图像数据集

00:02:36.795 --> 00:02:38.640
与 MNIST 数据集很相似

00:02:38.640 --> 00:02:43.315
但是这个分类任务比分类数字图像要难些

00:02:43.315 --> 00:02:48.005
像这样的简单数据集经常用于测试网络性能

00:02:48.005 --> 00:02:50.060
因为这样的数据集使用便捷

00:02:50.060 --> 00:02:52.765
而且训练行为易于理解

00:02:52.765 --> 00:02:57.324
例如 我们能肯定训练损失会稳步降低

00:02:57.324 --> 00:03:01.894
照常加载和查看数据 然后定义模型

00:03:01.894 --> 00:03:05.500
这是我打算构建的 MLP 的结构图

00:03:05.500 --> 00:03:07.330
这个 MLP 有一个输入层

00:03:07.330 --> 00:03:09.865
两个隐藏层 大小已指定

00:03:09.865 --> 00:03:11.330
以及一个最后输出层

00:03:11.330 --> 00:03:14.590
输出是 10 个类别分数 对应 10 种服饰类型

00:03:14.590 --> 00:03:19.530
隐藏层将分别有 256 和 128 个节点

00:03:19.530 --> 00:03:21.500
我们不想做得太复杂

00:03:21.500 --> 00:03:22.880
因为侧重点是了解

00:03:22.880 --> 00:03:26.370
权重初始化对此类模型性能的影响

00:03:26.370 --> 00:03:30.255
下拉 就能看见我在这里是如何定义该模型的

00:03:30.255 --> 00:03:33.950
我拉平了输入 x 并传入全连接层

00:03:33.950 --> 00:03:37.415
向每个隐藏层应用 ReLu 激活函数

00:03:37.415 --> 00:03:38.925
在中间添加丢弃层

00:03:38.925 --> 00:03:40.975
这是最终的全连接层

00:03:40.975 --> 00:03:43.420
它会生成 10 个类别分数

00:03:43.420 --> 00:03:45.420
然后实际训练该模型

00:03:45.420 --> 00:03:47.850
我将代码放入了 helpers.py 文件中

00:03:47.850 --> 00:03:50.650
你可以通过点击这个 Jupyter 图标找到该文件

00:03:50.650 --> 00:03:53.480
此 notebook 的目的

00:03:53.480 --> 00:03:56.300
不是训练模型让它在分类任务上表现不错

00:03:56.300 --> 00:04:00.560
而是看看如果给定不同的初始权重 模型效果如何

00:04:00.560 --> 00:04:03.365
我们打开 helpers.py 文件看看

00:04:03.365 --> 00:04:06.370
这是主辅助函数 get_loss_acc

00:04:06.370 --> 00:04:07.720
它的输入参数是 model

00:04:07.720 --> 00:04:09.785
train_loader 和 validation_loader

00:04:09.785 --> 00:04:13.920
在这里定义模型的训练时间 设为两个周期

00:04:13.920 --> 00:04:17.810
并且在这里定义了损失和优化函数

00:04:17.810 --> 00:04:20.740
使用交叉熵损失和 Adam 优化器

00:04:20.740 --> 00:04:21.855
这是我的做法

00:04:21.855 --> 00:04:26.060
你也可以改成随机梯度下降法 看看效果如何

00:04:26.060 --> 00:04:29.510
然后在此函数里训练模型两轮

00:04:29.510 --> 00:04:31.880
并记录训练损失

00:04:31.880 --> 00:04:35.435
我将在 loss_batch 列表中记录损失

00:04:35.435 --> 00:04:38.030
模型训练两轮后

00:04:38.030 --> 00:04:41.090
看看它在验证集上的效果

00:04:41.090 --> 00:04:43.240
比较预测类别和正确类别

00:04:43.240 --> 00:04:44.910
看看哪些类别匹配

00:04:44.910 --> 00:04:49.915
最后返回训练损失列表和验证准确率

00:04:49.915 --> 00:04:53.120
这是另一个辅助函数 叫做 compare_init_weights

00:04:53.120 --> 00:04:55.320
它的输入是模型列表

00:04:55.320 --> 00:04:57.110
对于列表中的每个模型

00:04:57.110 --> 00:05:01.205
它将记录两轮的训练损失和验证准确率

00:05:01.205 --> 00:05:05.315
然后是可视化损失并至少比较两个模型的代码

00:05:05.315 --> 00:05:06.920
你可以查看辅助函数代码

00:05:06.920 --> 00:05:09.560
并理解所有代码的工作原理

00:05:09.560 --> 00:05:13.135
但是没必要更改我介绍的这些代码

00:05:13.135 --> 00:05:16.730
我已经介绍了这些资源和此 notebook

00:05:16.730 --> 00:05:17.810
在下面的几个视频中

00:05:17.810 --> 00:05:22.200
我将演示如何正确地设置权重并比较它们的行为

