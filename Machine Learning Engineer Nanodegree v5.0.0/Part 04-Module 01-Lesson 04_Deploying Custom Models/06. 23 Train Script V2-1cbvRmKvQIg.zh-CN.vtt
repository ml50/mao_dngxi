WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.879
在 model.py 中定义了神经网络后

00:00:02.879 --> 00:00:05.279
下面实例化并训练该模型

00:00:05.280 --> 00:00:07.740
我们将在训练脚本中完成操作

00:00:07.740 --> 00:00:10.859
该文件位于 source 目录的 train.py 下

00:00:10.859 --> 00:00:14.114
训练脚本是训练自定义模型的关键

00:00:14.115 --> 00:00:18.359
当我们对自定义 estimator 调用 .fit 时 该脚本将执行

00:00:18.359 --> 00:00:21.629
下面我将演示一个 PyTorch 示例 但是你也可以

00:00:21.629 --> 00:00:24.945
以非常相似的方式训练和部署自定义 scikit-learn 模型

00:00:24.945 --> 00:00:29.039
实际上更简单 因为只需导入模型 而不用定义自定义模型

00:00:29.039 --> 00:00:33.269
很多 Sklearn 模型都有内置的预测函数

00:00:33.270 --> 00:00:36.359
唯一需要完成的是 train.py 文件

00:00:36.359 --> 00:00:40.019
典型的训练脚本会完成多项操作

00:00:40.020 --> 00:00:44.000
首先 它会加载训练数据

00:00:44.000 --> 00:00:48.140
并解析传入 estimator 构造函数的所有训练和模型超参数

00:00:48.140 --> 00:00:51.725
然后它将根据指定的超参数实例化模型

00:00:51.725 --> 00:00:53.899
我们的参数包括 input_dim

00:00:53.899 --> 00:00:57.019
Hidden_dim 和 output_dim 然后训练该模型

00:00:57.020 --> 00:00:59.120
最后 它还负责

00:00:59.119 --> 00:01:02.149
保存训练过的模型 以便稍后部署模型

00:01:02.149 --> 00:01:04.640
我们看看 train.py 文件

00:01:04.640 --> 00:01:06.695
首先是 import 语句

00:01:06.694 --> 00:01:11.444
导入我需要的库并导入刚刚创建的模型 SimpleNet

00:01:11.444 --> 00:01:13.774
然后是提供的几个函数

00:01:13.775 --> 00:01:16.969
这个函数会加载之前训练过的模型

00:01:16.969 --> 00:01:21.694
如果你想根据之前保存的模型参数创建 SimpleNet 那么这个函数很有用

00:01:21.694 --> 00:01:24.574
然后是函数 _get_train_loader

00:01:24.575 --> 00:01:28.385
它的参数包括批次大小和训练数据的保存位置

00:01:28.385 --> 00:01:32.120
这个函数将读取训练 csv 文件

00:01:32.120 --> 00:01:36.350
它认为叫做 train.csv 并将其划分为标签和特征

00:01:36.349 --> 00:01:40.539
在这里从第一列获取标签并从剩余列中获取特征

00:01:40.540 --> 00:01:42.800
然后将特征和标签放入 TensorDataset 中

00:01:42.799 --> 00:01:46.325
便于 DataLoader 批处理这些特征和标签

00:01:46.325 --> 00:01:49.265
接下来是 train 函数

00:01:49.265 --> 00:01:52.099
它的参数包括模型 train_loader 以及训练参数

00:01:52.099 --> 00:01:54.799
这个循环负责遍历所有的训练数据

00:01:54.799 --> 00:01:59.435
并根据优化参数更新模型

00:01:59.435 --> 00:02:00.590
例如在这里

00:02:00.590 --> 00:02:03.740
查看模型对一批数据的响应效果

00:02:03.739 --> 00:02:06.979
并查看输出与某个目标的接近程度

00:02:06.980 --> 00:02:10.550
然后执行反向传播和优化步骤 改进模型

00:02:10.550 --> 00:02:13.400
这行代码将输出训练信息

00:02:13.400 --> 00:02:15.995
收起这部分 这样看起来更整洁

00:02:15.995 --> 00:02:17.990
但仅在所有训练周期之后

00:02:17.990 --> 00:02:21.050
将训练过的模型保存到模型目录下

00:02:21.050 --> 00:02:23.180
这里提供了一些保存函数

00:02:23.180 --> 00:02:27.200
保存训练过的模型的状态字典以及仅保存模型参数

00:02:27.199 --> 00:02:31.354
这个主 if 语句中包含了所有的详细信息

00:02:31.354 --> 00:02:33.379
包括如何定义和训练模型

00:02:33.379 --> 00:02:36.625
要训练多少个周期 等等

00:02:36.625 --> 00:02:38.460
if _name_ == ‘_main_’

00:02:38.460 --> 00:02:41.090
当你调用 .fit 来训练自定义 estimator 时

00:02:41.090 --> 00:02:43.670
所有这些代码将执行

00:02:43.669 --> 00:02:45.259
我将在此 if 语句中

00:02:45.259 --> 00:02:49.179
定义所有的模型和训练超参数

00:02:49.180 --> 00:02:52.099
这些参数包括 batch-size

00:02:52.099 --> 00:02:55.204
当我们创建 estimator 时 这些参数将传入构造函数中

00:02:55.205 --> 00:02:57.800
我将在这里获取 train_loader

00:02:57.800 --> 00:03:00.860
并用指定的参数实例化模型

00:03:00.860 --> 00:03:04.010
我需要定义优化器和损失函数

00:03:04.009 --> 00:03:07.669
并将它们传递给上面的 train 函数 最终保存训练过的模型

00:03:07.669 --> 00:03:09.759
你需要完成几个 TODO 任务

00:03:09.759 --> 00:03:12.769
第一个任务是在这里定义模型和训练超参数

00:03:12.770 --> 00:03:16.265
并将它们添加到 args 里

00:03:16.264 --> 00:03:18.694
你可以使用 ArgumentParser

00:03:18.694 --> 00:03:23.989
借助 ArgumentParser 你可以将参数添加到 estimator 构造函数中

00:03:23.990 --> 00:03:25.969
我们可以添加 batch-size 等

00:03:25.969 --> 00:03:29.615
当我们实际构造自定义 estimator 时可以指定这些参数

00:03:29.615 --> 00:03:30.935
为了添加参数

00:03:30.935 --> 00:03:34.039
我们只需调用 parser.add_argument

00:03:34.039 --> 00:03:38.299
并传入双短线和变量的名称以及其他几项内容

00:03:38.300 --> 00:03:42.140
每个参数都有一个类型 例如 int 或 string

00:03:42.139 --> 00:03:46.084
一个默认值 在构造函数中没有指定值时就采用默认值

00:03:46.085 --> 00:03:50.330
一个 metavar 它是一个描述性字符串 通常是一两个字母

00:03:50.330 --> 00:03:54.875
例如 n 表示数字 s 表示 seed 它们可以用在用法消息中

00:03:54.875 --> 00:03:59.210
最后是 help 它是描述参数的一句话

00:03:59.210 --> 00:04:01.205
第一批参数

00:04:01.205 --> 00:04:03.305
都是 SageMaker 参数

00:04:03.305 --> 00:04:06.469
例如模型目录和数据目录

00:04:06.469 --> 00:04:09.995
分别表示训练数据的存储位置以及训练模型输出的存储位置

00:04:09.995 --> 00:04:13.340
无论是什么 estimator 这些参数都会自动设置

00:04:13.340 --> 00:04:16.814
然后是一些训练参数 例如 batch-size

00:04:16.814 --> 00:04:19.564
训练周期数和学习速率

00:04:19.564 --> 00:04:23.870
你的任务是添加定义 SimpleNet 所需的新参数

00:04:23.870 --> 00:04:26.780
例如传入 k，表示 k 均值模型

00:04:26.779 --> 00:04:30.589
以及训练 LinearLearner 的预测器类型

00:04:30.589 --> 00:04:33.879
我们有三个模型参数

00:04:33.879 --> 00:04:35.798
分别定义了输入 隐藏和输出维度

00:04:35.798 --> 00:04:38.329
你应该在这里添加三个新的参数

00:04:38.329 --> 00:04:42.069
建议根据 SimpleNet 中的参数名称命名

00:04:42.069 --> 00:04:44.909
所以分别为 input_dim hidden_dim 和 output_dim

00:04:44.910 --> 00:04:47.150
下个 TODO 任务是实例化该模型

00:04:47.149 --> 00:04:49.774
并传入这些输入参数

00:04:49.774 --> 00:04:52.370
可以调用 SimpleNet 并传入参数

00:04:52.370 --> 00:04:55.490
例如 args.input_dim 以获得相应的维度

00:04:55.490 --> 00:04:59.615
最后定义训练优化器和损失函数

00:04:59.615 --> 00:05:02.449
所有这些都放入 train 函数里

00:05:02.449 --> 00:05:05.074
它将负责训练和保存模型

00:05:05.074 --> 00:05:09.214
接下来请根据代码中的 TODO 标记完成此训练脚本

00:05:09.214 --> 00:05:12.929
然后我将介绍我的一种解决方案

