WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.585
现在你将有机会使用 SageMaker 构建模型

00:00:03.585 --> 00:00:05.220
首先

00:00:05.220 --> 00:00:09.870
打开 sagemaker-deployment 目录并找到 Mini-Projects 目录

00:00:09.870 --> 00:00:11.895
我们将使用的 notebook 是

00:00:11.895 --> 00:00:15.600
IMDB Sentiment Analysis-XGBoost (batch transform)

00:00:15.600 --> 00:00:20.250
在此 notebook 中 你将使用 SageMaker 创建一个 XGBoost 模型

00:00:20.250 --> 00:00:24.120
我们将使用该模型判断

00:00:24.120 --> 00:00:28.350
发布在 IMDB 数据库中的影评是正面的还是负面的

00:00:28.350 --> 00:00:33.000
首先看看各个单元格 包括下载数据

00:00:33.000 --> 00:00:36.150
准备数据和处理数据

00:00:36.150 --> 00:00:39.530
没有什么要执行的操作 只需执行这些单元格

00:00:39.530 --> 00:00:41.435
注意

00:00:41.435 --> 00:00:44.510
数据处理流程可能要花费一段时间

00:00:44.510 --> 00:00:46.550
我几乎花了整整一小时

00:00:46.550 --> 00:00:49.970
建议先运行所有单元格

00:00:49.970 --> 00:00:53.420
然后看看每一步的作用

00:00:53.420 --> 00:00:56.515
第 4 步就需要你来操作了

00:00:56.515 --> 00:01:01.925
首先 你需要将训练集拆分成验证集和训练集

00:01:01.925 --> 00:01:07.095
然后将测试集 训练集和验证集保存到文件中

00:01:07.095 --> 00:01:09.785
并将这些文件上传到 S3

00:01:09.785 --> 00:01:13.460
就像在 Boston Housing notebook 中操作的那样

00:01:13.460 --> 00:01:19.100
然后创建一个 XGBoost 模型 拟合该模型

00:01:19.100 --> 00:01:24.360
最后创建一个批转换作业 测试模型

00:01:24.360 --> 00:01:27.640
看看预测结果有多准确

00:01:27.640 --> 00:01:31.400
最后一步 你可以选择删除

00:01:31.400 --> 00:01:34.910
/data 目录和 /cache 目录下的所有文件

00:01:34.910 --> 00:01:37.535
这样的话

00:01:37.535 --> 00:01:41.120
notebook 实例不会很快就磁盘空间不足

00:01:41.120 --> 00:01:45.320
建议看看 Boston Housing notebook

00:01:45.320 --> 00:01:47.750
因为在此 notebook 中的很多操作

00:01:47.750 --> 00:01:52.340
都与本 notebook 中的任务很相似

00:01:52.340 --> 00:01:54.020
但是 如果你遇到问题的话

00:01:54.020 --> 00:01:55.850
别担心 在下个视频中

00:01:55.850 --> 00:01:58.600
我会详细讲解我的操作流程的

