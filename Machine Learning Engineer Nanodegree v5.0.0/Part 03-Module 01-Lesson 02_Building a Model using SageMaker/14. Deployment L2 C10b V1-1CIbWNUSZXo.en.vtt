WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.794
Now that we've uploaded our training and validation data to S3,

00:00:03.794 --> 00:00:05.655
it's time to construct our model.

00:00:05.655 --> 00:00:07.485
When we use the word model,

00:00:07.485 --> 00:00:10.005
we should be very careful about what we mean.

00:00:10.005 --> 00:00:13.980
For now, we mean model as understood by SageMaker,

00:00:13.980 --> 00:00:18.870
which is a collection of information including any model artifacts created during

00:00:18.870 --> 00:00:24.630
training and additional information describing how the model artifacts should be used.

00:00:24.629 --> 00:00:28.994
This will make a little more sense as we go through creating our model.

00:00:28.995 --> 00:00:32.579
To remind ourselves how this works in the high-level case,

00:00:32.579 --> 00:00:34.979
let's take a look at the high level notebook.

00:00:34.979 --> 00:00:36.750
This is the high level notebook,

00:00:36.750 --> 00:00:41.865
and if we scroll down to training and creating the XGBoost model,

00:00:41.865 --> 00:00:48.195
what we did was first get the URI to the XGBoost docker container.

00:00:48.195 --> 00:00:51.075
We then created an estimator object,

00:00:51.075 --> 00:00:57.265
which included which algorithm to use by means of a link to a container.

00:00:57.265 --> 00:00:59.884
Some information about the type

00:00:59.884 --> 00:01:03.679
of virtual machine that should be used to run the algorithm,

00:01:03.679 --> 00:01:05.719
where to store the output,

00:01:05.719 --> 00:01:10.549
and then some other information like what role the virtual machine should have,

00:01:10.549 --> 00:01:13.108
and some additional session information.

00:01:13.108 --> 00:01:17.515
Next, we set algorithms specific hyperparameters.

00:01:17.515 --> 00:01:20.375
Lastly, we called the fit method

00:01:20.375 --> 00:01:24.409
providing a link to the training and validation data sets.

00:01:24.409 --> 00:01:31.129
The ultimate goal of these three steps was to create a training job training.

00:01:31.129 --> 00:01:33.640
A job essentially does what it sounds like it does.

00:01:33.640 --> 00:01:37.489
It runs an algorithm on supervised data to fit

00:01:37.489 --> 00:01:42.199
a model and then saves the resulting fit model to a file somewhere.

00:01:42.200 --> 00:01:44.960
We will be setting up the training job ourselves in

00:01:44.959 --> 00:01:49.484
the low-level notebook switching back to the low-level notebook.

00:01:49.484 --> 00:01:52.000
In order to create the training job,

00:01:52.000 --> 00:01:58.375
we need to specify all of the bits of information in a single large dictionary object.

00:01:58.375 --> 00:02:01.790
We're gonna call our dictionary object Training params.

00:02:01.790 --> 00:02:05.180
Of course, we're going to need the URI to

00:02:05.180 --> 00:02:08.740
the docker container containing the extra boost algorithm.

00:02:08.740 --> 00:02:12.020
Next, we make sure to specify what role

00:02:12.020 --> 00:02:15.320
the virtual machine that we will eventually create should have.

00:02:15.319 --> 00:02:18.539
Next, we need to specify the algorithm we wish to run,

00:02:18.539 --> 00:02:21.775
we do that by specifying a link to the container.

00:02:21.775 --> 00:02:26.795
Next, we need to specify where the resulting model should be saved.

00:02:26.794 --> 00:02:31.819
This output of our algorithm is what is called the modal artifacts.

00:02:31.819 --> 00:02:33.739
Next, we need to describe

00:02:33.739 --> 00:02:39.064
what properties the virtual machine we are going to run our algorithm on should have.

00:02:39.064 --> 00:02:43.389
In our case, we are going to use a single virtual machine which is

00:02:43.389 --> 00:02:49.253
relatively medium powered and does not require too much in the way of storage.

00:02:49.253 --> 00:02:53.125
This parameter sets a timeout condition.

00:02:53.125 --> 00:02:55.900
Essentially if the training algorithm gets stuck

00:02:55.900 --> 00:02:58.780
in some sort of infinite or very long loop,

00:02:58.780 --> 00:03:02.305
this makes sure that our Virtual Machine doesn't run forever.

00:03:02.305 --> 00:03:05.530
Those are the parameters that make up the algorithm specification.

00:03:05.530 --> 00:03:10.120
Now we need to set the parameters that are specific to the algorithm we've chosen,

00:03:10.120 --> 00:03:12.370
in our case X D boost,

00:03:12.370 --> 00:03:14.170
we can do that here.

00:03:14.169 --> 00:03:17.469
As you may notice, the hyperparameters that we've chosen

00:03:17.469 --> 00:03:21.159
here are the same as the ones that appear in the high-level notebook.

00:03:21.159 --> 00:03:25.375
Next, we need to tell SageMaker where to pull the data from.

00:03:25.375 --> 00:03:29.710
In particular, we need to tell it where the training data is,

00:03:29.710 --> 00:03:32.174
in this case it is in S3,

00:03:32.174 --> 00:03:35.020
and it is CSV data,

00:03:35.020 --> 00:03:37.110
and the validation data,

00:03:37.110 --> 00:03:40.940
which is also on S3 and is also CSV data.

00:03:40.939 --> 00:03:44.750
So, now we have specified which hour them to use,

00:03:44.750 --> 00:03:47.705
parameters specific to that algorithm,

00:03:47.705 --> 00:03:50.315
and the data that is sent to the algorithm.

00:03:50.314 --> 00:03:53.359
All that is left is to ask SageMaker to

00:03:53.360 --> 00:03:57.090
construct the training job with the parameters that we have chosen.

00:03:57.090 --> 00:04:00.890
One additional parameter that must be included is a name.

00:04:00.889 --> 00:04:03.739
Every training job must have a name and that name

00:04:03.740 --> 00:04:06.920
must be unique The way that we make sure that

00:04:06.919 --> 00:04:13.084
our training job has a unique name is by including a timestamp at the end of the name.

00:04:13.085 --> 00:04:14.629
Once we've done that,

00:04:14.629 --> 00:04:19.060
we asked SageMaker to create the training job and away it goes.

00:04:19.060 --> 00:04:22.334
Just like when doing the batch transform,

00:04:22.334 --> 00:04:24.560
the training job is being created in

00:04:24.560 --> 00:04:28.420
the background and once it has been created it will be executed.

00:04:28.420 --> 00:04:32.000
If we want to have some sort of visual representation of what is

00:04:32.000 --> 00:04:35.750
going on and to alert us when that training job has completed,

00:04:35.750 --> 00:04:42.829
we need to use this logs for job method and include the wait equals true parameter.

00:04:42.829 --> 00:04:45.400
Now we just need to wait for our training job to complete.

