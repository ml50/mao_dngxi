WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.970
请打开 Boston Housing - XGBoost (Hyperparameter Tuning) - High Level notebook

00:00:05.970 --> 00:00:07.320
我已经打开了

00:00:07.320 --> 00:00:09.930
并执行了前几个单元格

00:00:09.930 --> 00:00:12.810
向下滚动到训练 XGBoost 模型部分

00:00:12.810 --> 00:00:15.210
首先 我按照训练单个模型时的步骤

00:00:15.210 --> 00:00:18.675
构建了一个 estimator 对象

00:00:18.675 --> 00:00:23.700
SageMaker 将以该对象为基准模型

00:00:23.700 --> 00:00:28.680
进行更改调整 以测试各种超参数

00:00:28.680 --> 00:00:31.770
接着设置一些超参数

00:00:31.770 --> 00:00:37.095
这是基准模型 SageMaker 将以其为基础加以更改

00:00:37.095 --> 00:00:40.289
例如 默认地我们将 eta 设为 0.2

00:00:40.289 --> 00:00:44.630
但是稍后允许 SageMaker 更改它

00:00:44.630 --> 00:00:47.300
设置好 estimator 对象后

00:00:47.300 --> 00:00:49.940
我们将创建一个新的对象

00:00:49.940 --> 00:00:52.970
称为 HyperparameterTuner 对象

00:00:52.970 --> 00:00:57.760
首先 将基准模型设为 estimator 对象

00:00:57.760 --> 00:01:02.255
指定如何区分两个不同的已训练模型

00:01:02.255 --> 00:01:07.430
我们将使用 RMSE 指标

00:01:07.430 --> 00:01:11.330
我们关心的是应用到验证集的指标

00:01:11.330 --> 00:01:12.860
而不是训练集的指标

00:01:12.860 --> 00:01:18.425
接着 寻找最小化验证 RMSE 的模型

00:01:18.425 --> 00:01:24.470
max_jobs 表示我们总共希望 SageMaker 训练多少个模型

00:01:24.470 --> 00:01:28.040
max_parallel_jobs 表示我们希望

00:01:28.040 --> 00:01:31.780
SageMaker 并行训练多少个模型

00:01:31.780 --> 00:01:40.015
最后 指定特定超参数的范围

00:01:40.015 --> 00:01:42.835
例如 指定超参数 eta

00:01:42.835 --> 00:01:49.525
应该是连续超参数 范围是 0.05 到 0.5

00:01:49.525 --> 00:01:52.695
创建了 HyperparameterTuner 对象后

00:01:52.695 --> 00:01:54.560
与 estimator 对象一样

00:01:54.560 --> 00:01:59.345
对该对象调用 fit() 方法

00:01:59.345 --> 00:02:04.310
就像我们之前创建的大部分其他训练作业一样

00:02:04.310 --> 00:02:07.235
SageMaker 将在后台执行操作

00:02:07.235 --> 00:02:10.775
如果要直观地查看进度

00:02:10.775 --> 00:02:12.815
需要使用 wait() 方法

00:02:12.815 --> 00:02:15.875
下面等待超参数优化作业运行完毕

00:02:15.875 --> 00:02:19.490
现在 SageMaker 已经训练完一批模型

00:02:19.490 --> 00:02:24.125
我们看看训练的最佳模型是哪个

00:02:24.125 --> 00:02:28.000
它存储在 best_training_job 方法中

00:02:28.000 --> 00:02:31.050
这是最佳训练作业的名称

00:02:31.050 --> 00:02:33.740
之前 当我们想要创建 transformer 对象

00:02:33.740 --> 00:02:39.470
以便创建批转换作业来测试模型时

00:02:39.470 --> 00:02:41.875
我们使用了 estimator 对象

00:02:41.875 --> 00:02:45.515
但是我们没有已经训练过的 estimator 对象

00:02:45.515 --> 00:02:49.250
我们之前创建了一个 estimator 对象

00:02:49.250 --> 00:02:53.300
以便创建 HyperparameterTuner 对象

00:02:53.300 --> 00:02:58.489
但是原始 estimator 对象没有训练

00:02:58.489 --> 00:03:04.835
我们可以创建一个新的 estimator 对象

00:03:04.835 --> 00:03:09.355
然后使用 attach 方法将此 estimator 对象附加到训练作业上

00:03:09.355 --> 00:03:14.245
这样将会创建一个训练过的 estimator 对象

00:03:14.245 --> 00:03:17.960
实际上 它与作为参数传入的训练作业

00:03:17.960 --> 00:03:21.740
创建的模型工件相关联

00:03:21.740 --> 00:03:24.950
我们在这里传入最佳训练作业的名称

00:03:24.950 --> 00:03:29.300
xgb-attached 现在是与超参数优化作业生成的

00:03:29.300 --> 00:03:34.460
最佳训练作业相关联的已训练 estimator 对象

00:03:34.460 --> 00:03:38.960
然后我们可以执行与测试模型时一样的步骤

00:03:38.960 --> 00:03:42.795
创建一个 transformer 然后开始转换作业

00:03:42.795 --> 00:03:44.625
等待结果

00:03:44.625 --> 00:03:47.090
批量转换运行完毕后

00:03:47.090 --> 00:03:52.580
将生成的输出复制到本地 notebook 实例中

00:03:52.580 --> 00:03:56.130
然后绘制图形 看看效果如何

