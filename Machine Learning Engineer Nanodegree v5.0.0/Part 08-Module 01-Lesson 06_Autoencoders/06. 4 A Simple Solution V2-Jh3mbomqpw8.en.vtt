WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.440
All right. So, you've been given a chance to define and train an autoencoder of your own,

00:00:04.440 --> 00:00:07.470
and I want to show you what training looks like for my simple model.

00:00:07.469 --> 00:00:09.794
I decided to train for around 20 epics.

00:00:09.794 --> 00:00:11.580
I looked at the trends in training loss,

00:00:11.580 --> 00:00:14.519
and saw that the biggest decreases happened at the start of training,

00:00:14.519 --> 00:00:17.324
and then minor decreases around epic 14 or so.

00:00:17.324 --> 00:00:19.504
So, if I train for longer than 20 epics,

00:00:19.504 --> 00:00:21.644
I'm not sure I would have seen much of an improvement,

00:00:21.644 --> 00:00:25.204
but this loss is only one way to check how well your model is doing.

00:00:25.204 --> 00:00:27.239
For classification model recall,

00:00:27.239 --> 00:00:29.794
we would often look at classification accuracy,

00:00:29.795 --> 00:00:31.880
but here the task is a little different,

00:00:31.879 --> 00:00:35.969
this whole time we're comparing original input images to the reconstructions.

00:00:35.969 --> 00:00:38.009
So, a better way to see how your encoder is

00:00:38.009 --> 00:00:40.769
doing is to look directly at those reconstructions.

00:00:40.770 --> 00:00:45.290
Here, I'm loading in a batch of test data and I care only about the images.

00:00:45.289 --> 00:00:47.269
I then flattened those test images and pass

00:00:47.270 --> 00:00:49.645
them to our model to get some reconstructions.

00:00:49.645 --> 00:00:51.665
Finally, I resize this output,

00:00:51.664 --> 00:00:54.744
so that is reshaped into a 28 by 28 image,

00:00:54.744 --> 00:00:59.534
and this code displays 10 original images and their 10 reconstructions underneath them,

00:00:59.534 --> 00:01:01.294
and you can check out the result.

00:01:01.295 --> 00:01:03.859
For the most part, these reconstructions look pretty good,

00:01:03.859 --> 00:01:06.879
almost identical to the original images in some cases,

00:01:06.879 --> 00:01:09.259
but there do seem to be some weird blurry artifacts

00:01:09.260 --> 00:01:11.910
around the edges and curves of some digits.

00:01:11.909 --> 00:01:14.854
You can experiment with adding more linear layers to this model.

00:01:14.855 --> 00:01:16.310
But next, since we know that

00:01:16.310 --> 00:01:19.820
most image analysis tasks are better done by convolutional layers,

00:01:19.819 --> 00:01:23.269
let's see how we might create a good convolutional autoencoder.

