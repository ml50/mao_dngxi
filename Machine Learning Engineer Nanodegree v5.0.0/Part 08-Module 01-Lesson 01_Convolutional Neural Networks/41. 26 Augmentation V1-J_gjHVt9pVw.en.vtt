WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.819
To perform image augmentation in PyTorch,

00:00:02.819 --> 00:00:06.424
you can use the help of a built-in image transformation library.

00:00:06.424 --> 00:00:07.844
Here you can scroll through

00:00:07.844 --> 00:00:11.105
all the common transforms available in the transforms library.

00:00:11.105 --> 00:00:13.740
You can see transforms that shift around the image from

00:00:13.740 --> 00:00:16.865
left to right or that crop the image randomly.

00:00:16.864 --> 00:00:21.554
In our case, we want our dataset to be a little more rotation and scale invariant

00:00:21.554 --> 00:00:23.699
and so we can choose random transforms that

00:00:23.699 --> 00:00:26.535
change the scale and how much an image is rotated.

00:00:26.535 --> 00:00:29.219
I'm going to briefly show you how to do this in code and

00:00:29.219 --> 00:00:31.890
then you can choose whether or not to use it in your own work.

00:00:31.890 --> 00:00:35.759
I'm going to augment our data in the same step that I'm loading it in.

00:00:35.759 --> 00:00:38.640
Basically, I want to add to our composite transform.

00:00:38.640 --> 00:00:41.310
Where you've previously just seen conversion to tensors and

00:00:41.310 --> 00:00:44.740
normalization you can put other types of transforms as well.

00:00:44.740 --> 00:00:47.660
This transformation randomly flips an image along

00:00:47.659 --> 00:00:52.469
its horizontal axis and this code randomly rotates an image by 10 degrees.

00:00:52.469 --> 00:00:56.890
I apply this transform as usual when I form my training and test data.

00:00:56.890 --> 00:01:01.340
And that's all you need to do to give your images some geometric variation.

00:01:01.340 --> 00:01:02.930
After transforming my data,

00:01:02.929 --> 00:01:05.689
I've gone through the same visualization steps

00:01:05.689 --> 00:01:08.060
and we can see by looking at the borders of

00:01:08.060 --> 00:01:10.430
some of these images that some of our images have been

00:01:10.430 --> 00:01:13.675
rotated slightly right or left within 10 degrees.

00:01:13.674 --> 00:01:17.299
Then to see if data augmentation actually improve the performance of

00:01:17.299 --> 00:01:21.810
our model I use the same convolutional neural network and loop that I did before.

00:01:21.810 --> 00:01:26.060
I trained the model over 30 epics using our augmented training data.

00:01:26.060 --> 00:01:29.510
In this case it seemed that the training and validation mass took a little

00:01:29.510 --> 00:01:32.995
longer to decrease but may have reached a smaller minimum.

00:01:32.995 --> 00:01:36.290
I saved this augmented model and when I tested it,

00:01:36.290 --> 00:01:39.020
I got one percent more accuracy in general.

00:01:39.019 --> 00:01:43.729
This is a minor increase in test accuracy but the small performance improvements can

00:01:43.730 --> 00:01:45.829
add up and there's something worthwhile if you're

00:01:45.829 --> 00:01:48.530
really trying to find the best model for a task.

00:01:48.530 --> 00:01:50.299
Generally in this course,

00:01:50.299 --> 00:01:52.954
your job will be to design a model so that it can reach

00:01:52.954 --> 00:01:55.730
a high accuracy but in addition to that,

00:01:55.730 --> 00:01:58.564
choices about data augmentation and loss and

00:01:58.564 --> 00:02:01.579
optimization functions can take that even further.

00:02:01.579 --> 00:02:03.799
So this is a useful skill to have.

