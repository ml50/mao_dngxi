<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Convolutional Layers in PyTorch
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Convolutional Neural Networks
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Introducing Alexis.html">
       01. Introducing Alexis
      </a>
     </li>
     <li class="">
      <a href="02. Applications of CNNs.html">
       02. Applications of CNNs
      </a>
     </li>
     <li class="">
      <a href="03. Lesson Outline.html">
       03. Lesson Outline
      </a>
     </li>
     <li class="">
      <a href="04. MNIST Dataset.html">
       04. MNIST Dataset
      </a>
     </li>
     <li class="">
      <a href="05. How Computers Interpret Images.html">
       05. How Computers Interpret Images
      </a>
     </li>
     <li class="">
      <a href="06. MLP Structure &amp; Class Scores.html">
       06. MLP Structure &amp; Class Scores
      </a>
     </li>
     <li class="">
      <a href="07. Do Your Research.html">
       07. Do Your Research
      </a>
     </li>
     <li class="">
      <a href="08. Loss &amp; Optimization.html">
       08. Loss &amp; Optimization
      </a>
     </li>
     <li class="">
      <a href="09. Defining a Network in PyTorch.html">
       09. Defining a Network in PyTorch
      </a>
     </li>
     <li class="">
      <a href="10. Training the Network.html">
       10. Training the Network
      </a>
     </li>
     <li class="">
      <a href="11. Pre-Notebook MLP Classification, Exercise.html">
       11. Pre-Notebook: MLP Classification, Exercise
      </a>
     </li>
     <li class="">
      <a href="12. Notebook MLP Classification, MNIST.html">
       12. Notebook: MLP Classification, MNIST
      </a>
     </li>
     <li class="">
      <a href="13. One Solution.html">
       13. One Solution
      </a>
     </li>
     <li class="">
      <a href="14. Model Validation.html">
       14. Model Validation
      </a>
     </li>
     <li class="">
      <a href="15. Validation Loss.html">
       15. Validation Loss
      </a>
     </li>
     <li class="">
      <a href="16. Image Classification Steps.html">
       16. Image Classification Steps
      </a>
     </li>
     <li class="">
      <a href="17. MLPs vs CNNs.html">
       17. MLPs vs CNNs
      </a>
     </li>
     <li class="">
      <a href="18. Local Connectivity.html">
       18. Local Connectivity
      </a>
     </li>
     <li class="">
      <a href="19. Filters and the Convolutional Layer.html">
       19. Filters and the Convolutional Layer
      </a>
     </li>
     <li class="">
      <a href="20. Filters &amp; Edges.html">
       20. Filters &amp; Edges
      </a>
     </li>
     <li class="">
      <a href="21. Frequency in Images.html">
       21. Frequency in Images
      </a>
     </li>
     <li class="">
      <a href="22. High-pass Filters.html">
       22. High-pass Filters
      </a>
     </li>
     <li class="">
      <a href="23. Quiz Kernels.html">
       23. Quiz: Kernels
      </a>
     </li>
     <li class="">
      <a href="24. OpenCV &amp; Creating Custom Filters.html">
       24. OpenCV &amp; Creating Custom Filters
      </a>
     </li>
     <li class="">
      <a href="25. Notebook Finding Edges.html">
       25. Notebook: Finding Edges
      </a>
     </li>
     <li class="">
      <a href="26. Convolutional Layer.html">
       26. Convolutional Layer
      </a>
     </li>
     <li class="">
      <a href="27. Convolutional Layers (Part 2).html">
       27. Convolutional Layers (Part 2)
      </a>
     </li>
     <li class="">
      <a href="28. Stride and Padding.html">
       28. Stride and Padding
      </a>
     </li>
     <li class="">
      <a href="29. Pooling Layers.html">
       29. Pooling Layers
      </a>
     </li>
     <li class="">
      <a href="30. Notebook Layer Visualization.html">
       30. Notebook: Layer Visualization
      </a>
     </li>
     <li class="">
      <a href="31. Capsule Networks.html">
       31. Capsule Networks
      </a>
     </li>
     <li class="">
      <a href="32. Increasing Depth.html">
       32. Increasing Depth
      </a>
     </li>
     <li class="">
      <a href="33. CNNs for Image Classification.html">
       33. CNNs for Image Classification
      </a>
     </li>
     <li class="">
      <a href="34. Convolutional Layers in PyTorch.html">
       34. Convolutional Layers in PyTorch
      </a>
     </li>
     <li class="">
      <a href="35. Feature Vector.html">
       35. Feature Vector
      </a>
     </li>
     <li class="">
      <a href="36. Pre-Notebook CNN Classification.html">
       36. Pre-Notebook: CNN Classification
      </a>
     </li>
     <li class="">
      <a href="37. Notebook CNNs for CIFAR Image Classification.html">
       37. Notebook: CNNs for CIFAR Image Classification
      </a>
     </li>
     <li class="">
      <a href="38. CIFAR Classification Example.html">
       38. CIFAR Classification Example
      </a>
     </li>
     <li class="">
      <a href="39. CNNs in PyTorch.html">
       39. CNNs in PyTorch
      </a>
     </li>
     <li class="">
      <a href="40. Image Augmentation.html">
       40. Image Augmentation
      </a>
     </li>
     <li class="">
      <a href="41. Augmentation Using Transformations.html">
       41. Augmentation Using Transformations
      </a>
     </li>
     <li class="">
      <a href="42. Groundbreaking CNN Architectures.html">
       42. Groundbreaking CNN Architectures
      </a>
     </li>
     <li class="">
      <a href="43. Visualizing CNNs (Part 1).html">
       43. Visualizing CNNs (Part 1)
      </a>
     </li>
     <li class="">
      <a href="44. Visualizing CNNs (Part 2).html">
       44. Visualizing CNNs (Part 2)
      </a>
     </li>
     <li class="">
      <a href="45. Summary of CNNs.html">
       45. Summary of CNNs
      </a>
     </li>
     <li class="">
      <a href="46. Introduction to GPU Workspaces.html">
       46. Introduction to GPU Workspaces
      </a>
     </li>
     <li class="">
      <a href="47. Workspace Playground.html">
       47. Workspace Playground
      </a>
     </li>
     <li class="">
      <a href="48. GPU Workspace Playground.html">
       48. GPU Workspace Playground
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          34. Convolutional Layers in PyTorch
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h2 id="convolutional-layers-in-pytorch">
          Convolutional Layers in PyTorch
         </h2>
         <p>
          To create a convolutional layer in PyTorch, you must first import the necessary module:
         </p>
         <pre><code class="python language-python">import torch.nn as nn</code></pre>
         <p>
          Then, there is a two part process to defining a convolutional layer and defining the feedforward behavior of a model (how an input moves through the layers of a network). First, you must define a Model class and fill in two functions.
         </p>
         <p>
          <strong>
           <strong>
            init
           </strong>
          </strong>
         </p>
         <p>
          You can define a convolutional layer in the
          <code>
           __init__
          </code>
          function of  by using the following format:
         </p>
         <pre><code class="python language-python">self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)</code></pre>
         <p>
          <strong>
           forward
          </strong>
         </p>
         <p>
          Then, you refer to that layer in the forward function! Here, I am passing in an input image
          <code>
           x
          </code>
          and applying a ReLU function to the output of this layer.
         </p>
         <pre><code>x = F.relu(self.conv1(x))</code></pre>
         <h3 id="arguments">
          Arguments
         </h3>
         <p>
          You must pass the following arguments:
         </p>
         <ul>
          <li>
           <code>
            in_channels
           </code>
           - The number of inputs (in depth), 3 for an RGB image, for example.
          </li>
          <li>
           <code>
            out_channels
           </code>
           - The number of output channels, i.e. the number of filtered "images" a convolutional layer is made of or the number of unique, convolutional kernels that will be applied to an input.
          </li>
          <li>
           <code>
            kernel_size
           </code>
           - Number specifying both the height and width of the (square) convolutional kernel.
          </li>
         </ul>
         <p>
          There are some additional, optional arguments that you might like to tune:
         </p>
         <ul>
          <li>
           <code>
            stride
           </code>
           - The stride of the convolution.  If you don't specify anything,
           <code>
            stride
           </code>
           is set to
           <code>
            1
           </code>
           .
          </li>
          <li>
           <code>
            padding
           </code>
           - The border of 0's around an input array.  If you don't specify anything,
           <code>
            padding
           </code>
           is set to
           <code>
            0
           </code>
           .
          </li>
         </ul>
         <p>
          <strong>
           NOTE
          </strong>
          : It is possible to represent both
          <code>
           kernel_size
          </code>
          and
          <code>
           stride
          </code>
          as either a number or a tuple.
         </p>
         <p>
          There are many other tunable arguments that you can set to change the behavior of your convolutional layers.  To read more about these, we recommend perusing the official
          <a href="https://pytorch.org/docs/stable/nn.html#conv2d" rel="noopener noreferrer" target="_blank">
           documentation
          </a>
          .
         </p>
         <h2 id="pooling-layers">
          Pooling Layers
         </h2>
         <p>
          Pooling layers take in a kernel_size and a stride. Typically the same value as is the down-sampling factor. For example, the following code will down-sample an input's x-y dimensions, by a factor of 2:
         </p>
         <pre><code class="python language-python">self.pool = nn.MaxPool2d(2,2)</code></pre>
         <p>
          <strong>
           forward
          </strong>
         </p>
         <p>
          Here, we see that poling layer being applied in the forward function.
         </p>
         <pre><code>x = F.relu(self.conv1(x))
x = self.pool(x)</code></pre>
         <hr/>
         <h3 id="convolutional-example-1">
          Convolutional Example #1
         </h3>
         <p>
          Say I'm constructing a CNN, and my input layer accepts grayscale images that are 200 by 200 pixels (corresponding to a 3D array with height 200, width 200, and depth 1).  Then, say I'd like the next layer to be a convolutional layer with 16 filters, each filter having a width and height of 2.  When performing the convolution, I'd like the filter to jump two pixels at a time.  I also don't want the filter to extend outside of the image boundaries; in other words, I don't want to pad the image with zeros.  Then, to construct this convolutional layer, I would use the following line of code:
         </p>
         <pre><code class="python language-python">self.conv1 = nn.Conv2d(1, 16, 2, stride=2)</code></pre>
         <h3 id="convolutional-example-2">
          Convolutional Example #2
         </h3>
         <p>
          Say I'd like the next layer in my CNN to be a convolutional layer that takes the layer constructed in Example 1 as input.  Say I'd like my new layer to have 32 filters, each with a height and width of 3.  When performing the convolution, I'd like the filter to jump 1 pixel at a time.  I want this layer to have the same width and height as the input layer, and so I will pad accordingly.  Then, to construct this convolutional layer, I would use the following line of code:
         </p>
         <pre><code class="python language-python">self.conv2 = nn.Conv2d(16, 32, 3, padding=1)</code></pre>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="__Convolution with 3x3 window and stride 1__

Image source: http://iamaaditya.github.io/2016/03/one-by-one-convolution/" class="img img-fluid" src="img/full-padding-no-strides-transposed.gif"/>
          <figcaption class="figure-caption">
           <p>
            <strong>
             Convolution with 3x3 window and stride 1
            </strong>
           </p>
           <p>
            Image source:
            <a href="http://iamaaditya.github.io/2016/03/one-by-one-convolution/" rel="noopener noreferrer" target="_blank">
             http://iamaaditya.github.io/2016/03/one-by-one-convolution/
            </a>
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="sequential-models">
          Sequential Models
         </h1>
         <p>
          We can also create a CNN in PyTorch by using a
          <code>
           Sequential
          </code>
          wrapper in the
          <code>
           __init__
          </code>
          function. Sequential allows us to stack different types of layers, specifying activation functions in between!
         </p>
         <pre><code>def __init__(self):
        super(ModelName, self).__init__()
        self.features = nn.Sequential(
              nn.Conv2d(1, 16, 2, stride=2),
              nn.MaxPool2d(2, 2),
              nn.ReLU(True),

              nn.Conv2d(16, 32, 3, padding=1),
              nn.MaxPool2d(2, 2),
              nn.ReLU(True) 
         )</code></pre>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <hr/>
         <h3 id="formula-number-of-parameters-in-a-convolutional-layer">
          Formula: Number of Parameters in a Convolutional Layer
         </h3>
         <p>
          The number of parameters in a convolutional layer depends on the supplied values of
          <code>
           filters/out_channels
          </code>
          ,
          <code>
           kernel_size
          </code>
          , and
          <code>
           input_shape
          </code>
          .  Let's define a few variables:
         </p>
         <ul>
          <li>
           <code>
            K
           </code>
           - the number of filters in the convolutional layer
          </li>
          <li>
           <code>
            F
           </code>
           - the height and width of the convolutional filters
          </li>
          <li>
           <code>
            D_in
           </code>
           - the depth of the previous layer
          </li>
         </ul>
         <p>
          Notice that
          <code>
           K
          </code>
          =
          <code>
           out_channels
          </code>
          , and
          <code>
           F
          </code>
          =
          <code>
           kernel_size
          </code>
          .  Likewise,
          <code>
           D_in
          </code>
          is the last value in the
          <code>
           input_shape
          </code>
          tuple, typically 1 or 3 (RGB and grayscale, respectively).
         </p>
         <p>
          Since there are
          <code>
           F*F*D_in
          </code>
          weights per filter, and the convolutional layer is composed of
          <code>
           K
          </code>
          filters, the total number of weights in the convolutional layer is
          <code>
           K*F*F*D_in
          </code>
          .  Since there is one bias term per filter, the convolutional layer has
          <code>
           K
          </code>
          biases.  Thus, the
          <em>
           _ number of parameters_
          </em>
          in the convolutional layer is given by
          <code>
           K*F*F*D_in + K
          </code>
          .
         </p>
         <h3 id="formula-shape-of-a-convolutional-layer">
          Formula: Shape of a Convolutional Layer
         </h3>
         <p>
          The shape of a convolutional layer depends on the supplied values of
          <code>
           kernel_size
          </code>
          ,
          <code>
           input_shape
          </code>
          ,
          <code>
           padding
          </code>
          , and
          <code>
           stride
          </code>
          .  Let's define a few variables:
         </p>
         <ul>
          <li>
           <code>
            K
           </code>
           - the number of filters in the convolutional layer
          </li>
          <li>
           <code>
            F
           </code>
           - the height and width of the convolutional filters
          </li>
          <li>
           <code>
            S
           </code>
           - the stride of the convolution
          </li>
          <li>
           <code>
            P
           </code>
           - the padding
          </li>
          <li>
           <code>
            W_in
           </code>
           - the width/height (square) of the previous layer
          </li>
         </ul>
         <p>
          Notice that
          <code>
           K
          </code>
          =
          <code>
           out_channels
          </code>
          ,
          <code>
           F
          </code>
          =
          <code>
           kernel_size
          </code>
          , and
          <code>
           S
          </code>
          =
          <code>
           stride
          </code>
          .  Likewise,
          <code>
           W_in
          </code>
          is the first and second value of the
          <code>
           input_shape
          </code>
          tuple.
         </p>
         <p>
          The
          <strong>
           depth
          </strong>
          of the convolutional layer will always equal the number of filters
          <code>
           K
          </code>
          .
         </p>
         <p>
          The spatial dimensions of a convolutional layer can be calculated as:
          <br/>
          <code>
           (W_in−F+2P)/S+1
          </code>
         </p>
         <hr/>
         <h2 id="flattening">
          Flattening
         </h2>
         <p>
          Part of completing a CNN architecture, is to
          <em>
           flatten
          </em>
          the eventual output of a series of convolutional and pooling layers, so that
          <strong>
           all
          </strong>
          parameters can be seen (as a vector) by a linear classification layer. At this step, it is imperative that you know exactly how many parameters are output by a layer.
         </p>
         <p>
          For the following quiz questions, consider an input image that is
          <code>
           130x130 (x, y) and 3
          </code>
          in depth (RGB). Say, this image goes through the following layers in order:
         </p>
         <pre><code>nn.Conv2d(3, 10, 3)
nn.MaxPool2d(4, 4)
nn.Conv2d(10, 20, 5, padding=2)
nn.MaxPool2d(2, 2)</code></pre>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <form>
          <fieldset>
           <legend>
            <p>
             After going through all four of these layers in sequence, what is the depth of the final output?
            </p>
           </legend>
          </fieldset>
          <div>
           <input id="a1537841436220" name="727963" type="radio" value="a1537841436220"/>
           <label for="a1537841436220">
            <p>
             1
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841774841" name="727963" type="radio" value="a1537841774841"/>
           <label for="a1537841774841">
            <p>
             3
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841776435" name="727963" type="radio" value="a1537841776435"/>
           <label for="a1537841776435">
            <p>
             10
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841781624" name="727963" type="radio" value="a1537841781624"/>
           <label for="a1537841781624">
            <p>
             20
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841786686" name="727963" type="radio" value="a1537841786686"/>
           <label for="a1537841786686">
            <p>
             40
            </p>
           </label>
          </div>
         </form>
         <details>
          <summary>
           <strong>
            SOLUTION:
           </strong>
          </summary>
          20
         </details>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <form>
          <fieldset>
           <legend>
            <p>
             What is the x-y size of the output of the final maxpooling layer? Careful to look at how the 130x130 image passes through (and shrinks) as it moved through each convolutional and pooling layer.
            </p>
           </legend>
          </fieldset>
          <div>
           <input id="a1537841834281" name="727964" type="radio" value="a1537841834281"/>
           <label for="a1537841834281">
            <p>
             8
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841886804" name="727964" type="radio" value="a1537841886804"/>
           <label for="a1537841886804">
            <p>
             15
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841891344" name="727964" type="radio" value="a1537841891344"/>
           <label for="a1537841891344">
            <p>
             16
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841900812" name="727964" type="radio" value="a1537841900812"/>
           <label for="a1537841900812">
            <p>
             30
            </p>
           </label>
          </div>
          <div>
           <input id="a1537841915391" name="727964" type="radio" value="a1537841915391"/>
           <label for="a1537841915391">
            <p>
             32
            </p>
           </label>
          </div>
         </form>
         <details>
          <summary>
           <strong>
            SOLUTION:
           </strong>
          </summary>
          16
         </details>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <form>
          <fieldset>
           <legend>
            <p>
             How many parameters, total, will be left after an image passes through all four of the above layers in sequence?
            </p>
           </legend>
          </fieldset>
          <div>
           <input id="a1537841974179" name="727965" type="radio" value="a1537841974179"/>
           <label for="a1537841974179">
            <p>
             <code>
              4*4*20
             </code>
            </p>
           </label>
          </div>
          <div>
           <input id="a1537842003415" name="727965" type="radio" value="a1537842003415"/>
           <label for="a1537842003415">
            <p>
             <code>
              128*20
             </code>
            </p>
           </label>
          </div>
          <div>
           <input id="a1537842007522" name="727965" type="radio" value="a1537842007522"/>
           <label for="a1537842007522">
            <p>
             <code>
              16*16*20
             </code>
            </p>
           </label>
          </div>
          <div>
           <input id="a1537842032728" name="727965" type="radio" value="a1537842032728"/>
           <label for="a1537842032728">
            <p>
             <code>
              32*32*20
             </code>
            </p>
           </label>
          </div>
         </form>
         <details>
          <summary>
           <strong>
            SOLUTION:
           </strong>
          </summary>
          `16*16*20`
         </details>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="35. Feature Vector.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('34. Convolutional Layers in PyTorch')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
