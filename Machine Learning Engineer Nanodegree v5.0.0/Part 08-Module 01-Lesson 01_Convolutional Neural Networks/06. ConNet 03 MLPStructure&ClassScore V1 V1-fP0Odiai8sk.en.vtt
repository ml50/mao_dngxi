WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.919
After looking at and normalizing our image data,

00:00:02.919 --> 00:00:07.094
we'll then create a neural network for discovering the patterns in our training data.

00:00:07.094 --> 00:00:09.570
After training, our network should be able to look at

00:00:09.570 --> 00:00:12.150
totally new images that it hasn't trained on,

00:00:12.150 --> 00:00:14.929
and classify the digits contained in those images.

00:00:14.929 --> 00:00:18.890
This previously unseen data is often called test data.

00:00:18.890 --> 00:00:24.030
At this point, our images have been converted into vectors with 784 entries.

00:00:24.030 --> 00:00:28.630
So, the first input layer in our MLP should have 784 nodes.

00:00:28.629 --> 00:00:31.410
We also know that we want the output layer to distinguish

00:00:31.410 --> 00:00:34.590
between 10 different digit types, zero through nine.

00:00:34.590 --> 00:00:37.385
So, we'll want the last layer to have 10 nodes.

00:00:37.384 --> 00:00:41.689
So, our model will take in a flattened image and produce 10 output values,

00:00:41.689 --> 00:00:44.539
one for each possible class, zero through nine.

00:00:44.539 --> 00:00:47.500
These output values are often called class scores.

00:00:47.500 --> 00:00:50.570
A high class score indicates that a network is very

00:00:50.570 --> 00:00:53.929
certain that a given input image falls into a certain class.

00:00:53.929 --> 00:00:57.759
You can imagine that the class score for a 103, for example,

00:00:57.759 --> 00:01:02.019
will have a high score for the class three and a low score for the classes zero,

00:01:02.020 --> 00:01:03.679
one, and so on.

00:01:03.679 --> 00:01:06.140
But it may also have a small score for

00:01:06.140 --> 00:01:10.204
an eight or any other class that looks kind of similar in shape to a three.

00:01:10.204 --> 00:01:13.625
The class scores are often represented as a vector of values

00:01:13.625 --> 00:01:17.635
or even as a bar graph indicating the relative strengths of the scores.

00:01:17.635 --> 00:01:20.840
Now, the part of this MLP architecture that's up to you to

00:01:20.840 --> 00:01:24.424
define is really in between the input and output layers.

00:01:24.424 --> 00:01:28.829
How many hidden layers do you want to include and how many nodes should be in each one?

00:01:28.829 --> 00:01:31.549
This is a question you'll come across a lot as you define

00:01:31.549 --> 00:01:34.349
neural networks to approach a variety of tasks.

00:01:34.349 --> 00:01:36.859
I usually start by looking at any papers or

00:01:36.859 --> 00:01:39.754
related work I can find that may act as a good guide.

00:01:39.754 --> 00:01:43.259
In this case, I would search for MLP for MNIST,

00:01:43.260 --> 00:01:44.359
or even more generally,

00:01:44.359 --> 00:01:47.215
MLP for classifying small greyscale images.

00:01:47.215 --> 00:01:49.670
Next, I'm going to ask you to perform a search like

00:01:49.670 --> 00:01:51.799
this and see if you can find a good place to

00:01:51.799 --> 00:01:56.439
start when it comes to defining the hidden layers of an MLP for image classification.

