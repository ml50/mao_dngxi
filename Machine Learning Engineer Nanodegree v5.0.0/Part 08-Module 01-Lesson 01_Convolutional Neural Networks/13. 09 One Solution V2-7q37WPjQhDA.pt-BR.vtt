WEBVTT
Kind: captions
Language: pt-BR

00:00:00.186 --> 00:00:04.113
Mostrarei rapidamente como
definir e treinar a MLP

00:00:04.146 --> 00:00:05.614
de classificação de imagem.

00:00:05.647 --> 00:00:09.588
Primeiro eu carreguei e observei
os dados de imagem,

00:00:09.621 --> 00:00:12.511
depois defini
o modelo de classificação.

00:00:12.544 --> 00:00:15.303
Comecei com a camada
completamente conectada, fc1,

00:00:15.336 --> 00:00:18.271
que observa o vetor
com tamanho igual a 784,

00:00:18.304 --> 00:00:20.790
que representa
uma imagem achatada como input.

00:00:20.823 --> 00:00:23.336
Depois, segui a partir do recurso
que encontrei,

00:00:23.369 --> 00:00:27.255
que tinha duas camadas ocultas
com 512 inputs e outputs.

00:00:27.288 --> 00:00:30.136
Eu armazenei os valores aqui
como duas variáveis,

00:00:30.169 --> 00:00:31.855
hidden_1 e hidden_2.

00:00:31.888 --> 00:00:35.310
Este é um passo extra, mas facilita
na hora de alterar os valores

00:00:35.343 --> 00:00:37.495
para testar
ou coisa do gênero.

00:00:37.528 --> 00:00:39.925
Para completar
a primeira camada conectada,

00:00:39.958 --> 00:00:43.324
coloquei hidden_1 como
a quantidade de outputs desejada.

00:00:43.357 --> 00:00:46.529
Depois criei uma segunda
camada completamente conectada, fc2,

00:00:46.562 --> 00:00:51.183
que pega os outputs
e produz 512 outputs novamente.

00:00:51.216 --> 00:00:54.069
Também quero que os outputs
de uma camada

00:00:54.102 --> 00:00:56.320
sejam os inputs da próxima.

00:00:56.353 --> 00:00:59.524
Depois defini a última
camada completamente conectada, fc3,

00:00:59.557 --> 00:01:03.724
para que ela veja os 512 inputs
e produza 10 outputs.

00:01:03.757 --> 00:01:07.101
Os 10 outputs correspondem
à quantidade de classes,

00:01:07.134 --> 00:01:08.581
de 0 a 9.

00:01:08.614 --> 00:01:11.309
Essa camada produzirá
as pontuações de classe.

00:01:11.342 --> 00:01:15.052
Por fim, ainda na função init,
defini uma camada dropout,

00:01:15.085 --> 00:01:18.804
com a probabilidade dropout
de 0,2 ou de 20%.

00:01:18.837 --> 00:01:21.140
Agora que defini as camadas
necessárias

00:01:21.173 --> 00:01:23.241
para criar a MLP
de classificação,

00:01:23.274 --> 00:01:26.852
preciso definir o comportamento
feedforward da rede.

00:01:26.885 --> 00:01:29.325
Com a função forward,
quero responder

00:01:29.358 --> 00:01:32.355
como um vetor de entrada
procederá pelas camadas.

00:01:32.388 --> 00:01:36.549
O input X começa
como um tensor de imagem de 28x28.

00:01:36.582 --> 00:01:40.517
O primeiro passo é achatar
em um vetor de 784.

00:01:40.550 --> 00:01:45.093
Depois disso, passarei na primeira
camada completamente conectada, fc1,

00:01:45.126 --> 00:01:47.549
aplicando
a função de ativação.

00:01:47.582 --> 00:01:49.604
A seguir, farei
exatamente o mesmo

00:01:49.637 --> 00:01:52.365
com a segunda camada
completamente conectada, fc2.

00:01:52.398 --> 00:01:55.461
Entre as duas camadas,
adiciono uma camada dropout,

00:01:55.494 --> 00:01:57.837
que evita o sobreajuste.

00:01:57.870 --> 00:02:00.061
Após X passar
na segunda camada oculta,

00:02:00.094 --> 00:02:01.925
adicionamos
mais uma camada dropout

00:02:01.958 --> 00:02:04.356
à última camada
completamente conectada.

00:02:04.389 --> 00:02:07.029
Perceba que não apliquei
uma função de ativação

00:02:07.062 --> 00:02:08.284
à camada final,

00:02:08.317 --> 00:02:12.387
isso porque ela terá
uma função de ativação softmax,

00:02:12.420 --> 00:02:14.524
então eu deixarei como está,

00:02:14.557 --> 00:02:17.660
retornando o X transformado.

00:02:17.693 --> 00:02:20.180
Como fc3 produz 10 outputs,

00:02:20.213 --> 00:02:23.212
o X deve representar
as pontuações de 10 classes.

00:02:23.245 --> 00:02:26.654
Depois instancio
e imprimo a rede

00:02:26.687 --> 00:02:28.755
para que ela tenha
a camadas desejadas.

00:02:28.788 --> 00:02:31.709
Vemos as três camadas
lineares e a de dropout.

00:02:31.742 --> 00:02:35.315
O próximo passo é definir as funções
de perda e de otimização.

00:02:35.348 --> 00:02:38.795
Aqui defini o critério de perda
como CrossEntropyLoss.

00:02:38.828 --> 00:02:42.310
Esta é uma perda padrão
para a tarefa de classificação.

00:02:42.343 --> 00:02:45.412
Usarei o gradiente descendente
estocástico, SGD,

00:02:45.445 --> 00:02:47.580
da biblioteca
de otimização Torch.

00:02:47.613 --> 00:02:50.829
Isso usa os parâmetros do modelo
e uma taxa de aprendizado.

00:02:50.862 --> 00:02:53.282
Configurei a taxa como 0.01.

00:02:53.315 --> 00:02:56.707
Se a perda estiver diminuindo
devagar demais ou esporadicamente,

00:02:56.740 --> 00:02:58.179
mudamos este valor.

00:02:58.212 --> 00:03:02.115
Eu treinei este modelo
por 50 epochs.

00:03:02.148 --> 00:03:04.976
Isso levou um tempo,
pois só estou usando a CPU,

00:03:05.009 --> 00:03:08.311
mas mostrarei depois como usar
a GPU para treinar mais rápido.

00:03:08.344 --> 00:03:11.089
Ao fim de cada epoch,
imprimi a perda de treinamento

00:03:11.122 --> 00:03:13.811
para ver como ela diminuiu
com o passar do tempo.

00:03:13.844 --> 00:03:16.200
Houve uma rápida diminuição
no início,

00:03:16.233 --> 00:03:21.617
mas fica mais devagar,
especialmente perto da epoch 40.

00:03:21.650 --> 00:03:24.861
Isso continua diminuindo
até a epoch 50.

00:03:24.894 --> 00:03:28.828
Para ver como meu modelo
generaliza para os novos dados,

00:03:28.861 --> 00:03:32.276
eu testo com os dados de teste
que carregamos no início.

00:03:32.309 --> 00:03:35.205
Iterei os dados
do test_loader,

00:03:35.238 --> 00:03:38.412
apliquei o modelo
e gravei a perda de teste.

00:03:38.445 --> 00:03:42.164
Um modelo retorna
uma lista de pontuações de classe.

00:03:42.197 --> 00:03:46.692
Até eu prever a classe,
usarei o valor máximo das pontuações

00:03:46.725 --> 00:03:48.472
e retornarei uma previsão.

00:03:48.505 --> 00:03:51.884
Depois comparo a previsão
com o rótulo que queremos.

00:03:51.917 --> 00:03:55.339
Isso cria uma lista dizendo
se a previsão está correta ou não.

00:03:55.372 --> 00:04:01.148
Separei isto entre as 10 classes
e imprimi a precisão de cada uma.

00:04:01.181 --> 00:04:04.331
Tenho a perda geral do teste
e a precisão geral,

00:04:04.364 --> 00:04:06.179
que é de 97%.

00:04:06.212 --> 00:04:09.074
Isso é bom. Vemos que,
entre as classes,

00:04:09.107 --> 00:04:10.925
o valor é bem consistente.

00:04:10.958 --> 00:04:14.626
O modelo se saiu pior em imagens
com o número 7 ou 8,

00:04:14.659 --> 00:04:18.004
mas a distribuição demonstra
que o modelo foi bem treinado

00:04:18.037 --> 00:04:19.721
em cada tipo de dado.

00:04:19.754 --> 00:04:23.103
Também incluí uma célula na qual
podemos exibir imagens de teste

00:04:23.136 --> 00:04:25.674
e os rótulos previstos,
um do lado do outro.

00:04:25.707 --> 00:04:29.362
Assim fica fácil de ver
quando obtemos uma imagem errada.

00:04:29.395 --> 00:04:32.060
Observando
a precisão do teste,

00:04:32.093 --> 00:04:34.430
me pergunto se ele pode se sair
ainda melhor,

00:04:34.463 --> 00:04:37.262
se eu posso melhorar o modelo
adicionando outra camada

00:04:37.295 --> 00:04:39.209
que defina mais padrões
nos dados

00:04:39.242 --> 00:04:42.661
ou se eu escolhi o momento certo
de parar o treinamento?

00:04:42.694 --> 00:04:45.973
Na verdade, perceba que eu parei
o treinamento na epoch 50,

00:04:46.006 --> 00:04:49.357
a partir da minha expectativa
da diminuição da perda,

00:04:49.390 --> 00:04:51.837
mas é mais uma arte
do que uma ciência.

00:04:51.870 --> 00:04:54.441
A seguir, veremos
um método concreto

00:04:54.474 --> 00:04:56.271
para saber
quando parar de treinar,

00:04:56.304 --> 00:04:58.636
uma técnica chamada
de "validação de modelo".

