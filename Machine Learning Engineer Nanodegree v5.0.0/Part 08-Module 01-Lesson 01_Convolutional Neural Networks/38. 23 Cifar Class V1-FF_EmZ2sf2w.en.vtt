WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.634
CIFAR-10 is a popular dataset of 60,000 tiny images,

00:00:04.634 --> 00:00:07.824
each depicting an object from one of 10 classes.

00:00:07.825 --> 00:00:10.275
You can see that each image is truly tiny.

00:00:10.275 --> 00:00:12.705
Only 32 pixels high and wide.

00:00:12.705 --> 00:00:15.689
These are color images so they're interpreted by the computer as

00:00:15.689 --> 00:00:18.905
arrays with a depth of three for RGB color channels.

00:00:18.905 --> 00:00:21.820
Because these are color images and there are a lot of them,

00:00:21.820 --> 00:00:25.469
the first thing I'm going to show you is an option to use a GPU for training.

00:00:25.469 --> 00:00:28.469
A GPU is essentially something that allows you to do

00:00:28.469 --> 00:00:33.149
data processing in parallel and so it may prove useful to speed up your training time.

00:00:33.149 --> 00:00:36.350
Here, you can see I'm loading in my usual libraries and then

00:00:36.350 --> 00:00:40.115
PyTorch gives us a way to check if a GPU device is available.

00:00:40.115 --> 00:00:43.280
Torch.cuda is available will return a Boolean

00:00:43.280 --> 00:00:46.984
variable true or false whether or not a GPU is available.

00:00:46.984 --> 00:00:50.630
We'll store this and then later if we do have a GPU available will be

00:00:50.630 --> 00:00:54.290
able to move our data and our model to that device for faster training.

00:00:54.289 --> 00:00:58.189
For now, I'm just going to visualize some data and present this problem and so I'm using

00:00:58.189 --> 00:01:02.699
my laptop and when I run this cell you can see that I'm training on CPU.

00:01:02.700 --> 00:01:06.140
Later, when I do try to develop a solution and train a model,

00:01:06.140 --> 00:01:10.894
I'll switch to GPU and in general this is a good thing to know how to use.

00:01:10.894 --> 00:01:13.670
Next, I'm going to load in my data as usual.

00:01:13.670 --> 00:01:18.390
CIFAR, much like is Amnest is available in the torchvision datasets library.

00:01:18.390 --> 00:01:22.625
I'm going to define my training and my test data by calling datasets.CIFAR10.

00:01:22.625 --> 00:01:27.040
I'll also transform this data into a tensor datatype and normalize

00:01:27.040 --> 00:01:31.565
the RGB values so that the pixel values are in a range from about zero to one.

00:01:31.564 --> 00:01:37.060
Finally, I can load in my transform data in batches using PyTorch's data loader class.

00:01:37.060 --> 00:01:39.340
These lines of code should look very similar to

00:01:39.340 --> 00:01:41.704
the Amnest code in which we loaded in data,

00:01:41.704 --> 00:01:43.655
transformed it into a tensor datatype,

00:01:43.655 --> 00:01:45.599
and separated the data into training,

00:01:45.599 --> 00:01:47.679
validation, and test sets.

00:01:47.680 --> 00:01:51.975
Also down here, I'm specifying the 10 image classes that I'm reading in.

00:01:51.974 --> 00:01:55.489
All CIFAR-10 images will fall into one of these categories.

00:01:55.489 --> 00:01:57.849
The data may take a moment to load in but once

00:01:57.849 --> 00:02:00.394
you load it in you can visualize a batch of that data.

00:02:00.394 --> 00:02:04.789
Here, I've defined a helper function which will basically unnormalize the images

00:02:04.790 --> 00:02:09.504
and convert them from a tensor image type to a non-py image type for visualization,

00:02:09.504 --> 00:02:12.109
then I'm just going to load in and display a batch of

00:02:12.110 --> 00:02:16.715
images and here we can verify that these images look pretty much how you would expect.

00:02:16.715 --> 00:02:18.170
We have images of cats,

00:02:18.169 --> 00:02:21.289
frogs, deer, and automobiles.

00:02:21.289 --> 00:02:24.984
We can even choose to view an image in more detail.

00:02:24.985 --> 00:02:27.170
Here, I'm displaying the red, green,

00:02:27.169 --> 00:02:32.030
and blue color channels as grayscale values for one single image and we should again

00:02:32.030 --> 00:02:34.159
see that the brightest pixel values are close to

00:02:34.159 --> 00:02:37.305
the value one and darker ones closer to zero.

00:02:37.305 --> 00:02:41.745
Next, you'll want to define and train a CNN to classify these images.

00:02:41.745 --> 00:02:44.250
You're also welcome to try out an MLP approach,

00:02:44.250 --> 00:02:46.435
see how both work, and compare the results.

00:02:46.435 --> 00:02:50.449
I'll be assuming that you want to define a CNN architecture so I provided

00:02:50.449 --> 00:02:54.799
links to the documentation for convolutional and maxpooling layers in PyTorch.

00:02:54.800 --> 00:02:56.630
Here's also a simple diagram showing how

00:02:56.629 --> 00:02:59.414
an input image might pass through a couple of these layers.

00:02:59.414 --> 00:03:00.849
Then if you scroll down,

00:03:00.849 --> 00:03:04.340
you can see that I've defined one example convolutional layer for you.

00:03:04.340 --> 00:03:06.995
I've defined it in the init function of our network.

00:03:06.995 --> 00:03:09.020
To define a convolutional layer,

00:03:09.020 --> 00:03:12.895
I use nn.Conv2d and I pass in some parameters.

00:03:12.895 --> 00:03:14.525
For our first convolutional layer,

00:03:14.525 --> 00:03:18.289
this will be the number of inputs seen as the depth of the input image.

00:03:18.289 --> 00:03:24.414
Recall that our inputs are 32 by 32 images with a depth of three for RGB color channels.

00:03:24.414 --> 00:03:27.500
So, I've defined the input and I've specified that this

00:03:27.500 --> 00:03:30.800
should output a convolutional layer with a depth of 16.

00:03:30.800 --> 00:03:35.930
That means this layer should take in our image and produce 16 filtered images as output.

00:03:35.930 --> 00:03:39.310
I've also specified that I'm using filters that are 3 by 3 in

00:03:39.310 --> 00:03:44.050
size and to keep my output layer the same x y size as my input image,

00:03:44.050 --> 00:03:46.650
I'll add one pixel of padding on the border.

00:03:46.650 --> 00:03:49.980
I've also defined one maxpooling layer named pool.

00:03:49.979 --> 00:03:53.989
This has a kernel size and stride size of two which means that any input it's

00:03:53.990 --> 00:03:58.510
applied to it will downsample it x y dimensions by a factor of two.

00:03:58.509 --> 00:03:59.639
Then in the forward function,

00:03:59.639 --> 00:04:02.000
we can see how all of these things fit together.

00:04:02.000 --> 00:04:03.884
For an input image x,

00:04:03.884 --> 00:04:05.079
I first pass it into

00:04:05.080 --> 00:04:09.300
our first convolutional layer and I apply a relu activation function.

00:04:09.300 --> 00:04:12.710
This output will be passed to a final pooling layer resulting in

00:04:12.710 --> 00:04:15.900
a downsampled transformed x which I'll return.

00:04:15.900 --> 00:04:16.930
To complete this model,

00:04:16.930 --> 00:04:21.019
it will be up to you to add multiple convolutional and pooling layers and finally

00:04:21.019 --> 00:04:23.389
flatten and apply a fully-connected layer for

00:04:23.389 --> 00:04:26.284
producing the desired number of class score outputs.

00:04:26.285 --> 00:04:28.265
After defining a complete CNN,

00:04:28.264 --> 00:04:31.839
you can instantiate it and even move it to GPU if it's available.

00:04:31.839 --> 00:04:35.089
Next, it'll be up to you to specify an appropriate loss and

00:04:35.089 --> 00:04:38.439
optimization function for this training task and finally,

00:04:38.439 --> 00:04:40.350
I've provided a training loop for you.

00:04:40.350 --> 00:04:44.135
You may want to increase the number of epochs you train your final model for.

00:04:44.134 --> 00:04:47.949
But this loop will keep track of the training and validation loss as you go.

00:04:47.949 --> 00:04:50.659
If you're validation loss decreases over an epoch,

00:04:50.660 --> 00:04:52.100
your model will be saved.

00:04:52.100 --> 00:04:54.650
Then you'll be able to test your train network and see

00:04:54.649 --> 00:04:57.469
how it performs on each type of test image.

00:04:57.470 --> 00:05:02.030
The biggest challenge will be defining a complete CNN and as always I encourage you

00:05:02.029 --> 00:05:03.649
to do your research before you define

00:05:03.649 --> 00:05:06.694
your model so that you can make an informed decision as you go.

00:05:06.694 --> 00:05:09.709
Try to solve this challenge on your own and if you want to check

00:05:09.709 --> 00:05:12.799
your work next I'll go over one possible solution.

