WEBVTT
Kind: captions
Language: pt-BR

00:00:00.563 --> 00:00:02.945
Se quisermos classificar
uma imagem de input,

00:00:02.978 --> 00:00:04.738
há várias formas de fazer isso

00:00:04.771 --> 00:00:06.921
com uma arquitetura
de aprendizado profundo.

00:00:06.954 --> 00:00:10.879
Aqui a camada de input é seguida
por várias camadas convolucionais.

00:00:10.912 --> 00:00:14.861
Esta pilha descobrirá hierarquias
de padrões espaciais na imagem.

00:00:14.894 --> 00:00:18.173
A 1ª camada de filtros procura
padrões na imagem de input,

00:00:18.206 --> 00:00:21.116
a 2ª procura na camada
convolucional anterior

00:00:21.149 --> 00:00:22.407
e assim por diante.

00:00:22.440 --> 00:00:25.377
Cada camada convolucional
requer que especifiquemos

00:00:25.410 --> 00:00:27.710
um número de hiperparâmetros.

00:00:27.743 --> 00:00:30.608
O 1º e o 2º inputs que definem
uma camada convolucional

00:00:30.641 --> 00:00:34.543
são a profundidade do input
e a profundidade desejada do output.

00:00:34.576 --> 00:00:37.668
Aqui a profundidade do input
de uma imagem colorida será 3

00:00:37.701 --> 00:00:39.374
para os canais RGB.

00:00:39.407 --> 00:00:42.458
E vamos produzir
16 imagens filtradas diferentes

00:00:42.491 --> 00:00:43.944
nesta camada convolucional.

00:00:44.422 --> 00:00:46.299
Depois definimos
o tamanho dos filtros

00:00:46.332 --> 00:00:48.263
que definem
a camada convolucional.

00:00:48.296 --> 00:00:52.216
O formato costuma ser quadrado,
e o tamanho varia de 2x2, no mínimo,

00:00:52.249 --> 00:00:55.608
até 7x7,
para imagens bem grandes.

00:00:55.641 --> 00:00:58.609
Aqui optei por usar
filtros 3x3.

00:00:58.642 --> 00:01:00.443
O stride costuma ser definido
como 1,

00:01:00.476 --> 00:01:03.298
e miniframeworks usarão esse valor
como padrão.

00:01:03.331 --> 00:01:05.734
Então talvez não seja preciso
inserir esse valor.

00:01:05.767 --> 00:01:07.660
O padding produz
resultados melhores

00:01:07.693 --> 00:01:10.358
se for definido
de modo que a camada convolucional

00:01:10.391 --> 00:01:14.208
tenha a mesma largura e altura
do input da camada anterior.

00:01:14.241 --> 00:01:15.952
No caso de um filtro 3x3,

00:01:15.985 --> 00:01:19.059
que consegue se centralizar
quase perfeitamente com a imagem,

00:01:19.092 --> 00:01:21.262
mas fica 1 pixel desalinhado
na borda,

00:01:21.295 --> 00:01:23.295
o padding será igual a 1.

00:01:23.328 --> 00:01:26.321
Você pode ler mais sobre casos
de extrapolação de padding.

00:01:26.534 --> 00:01:28.920
Ao definir a profundidade,
ou número de filtros,

00:01:28.953 --> 00:01:30.410
de uma camada convolucional,

00:01:30.443 --> 00:01:33.642
escolhemos números
que aumentem em sequência.

00:01:33.675 --> 00:01:36.904
Se a 1ª camada convolucional
tiver 16 filtros,

00:01:36.937 --> 00:01:38.930
a 2ª verá essa profundidade
como input

00:01:38.963 --> 00:01:41.567
e produzirá uma camada
com uma profundidade de 32,

00:01:41.600 --> 00:01:44.519
a 3ª terá uma profundidade de 64
e assim por diante.

00:01:45.033 --> 00:01:46.651
Após cada camada
convolucional,

00:01:46.684 --> 00:01:49.048
aplicaremos
uma função de ativação ReLU.

00:01:49.509 --> 00:01:50.961
Se seguirmos esse processo,

00:01:50.994 --> 00:01:52.905
há um método
para aumentar gradualmente

00:01:52.938 --> 00:01:56.920
a profundidade do array,
sem alterar a altura e a largura.

00:01:56.953 --> 00:01:59.335
O input, como todas
as camadas desta sequência,

00:01:59.368 --> 00:02:01.604
tem altura e largura
iguais a 32.

00:02:01.637 --> 00:02:04.726
Mas a profundidade da camada
aumenta de 3

00:02:04.759 --> 00:02:07.625
para 16, 32 e 64.

00:02:07.658 --> 00:02:10.380
Então queremos, sim,
aumentar a profundidade,

00:02:10.413 --> 00:02:12.983
mas também queremos reduzir
a altura e a largura

00:02:13.016 --> 00:02:15.422
e descartar
algumas informações espaciais.

00:02:15.455 --> 00:02:17.953
É aí que entram
as camadas max pooling.

00:02:17.986 --> 00:02:22.383
Elas costumam seguir uma ou duas
camadas convolucionais da sequência.

00:02:22.416 --> 00:02:23.624
Este é um exemplo

00:02:23.657 --> 00:02:27.221
onde há uma camada max pooling
após cada camada convolucional.

00:02:27.254 --> 00:02:28.711
Para a camada max pooling,

00:02:28.744 --> 00:02:31.794
você só precisa definir
o tamanho do filtro e o stride.

00:02:31.827 --> 00:02:34.537
Nas configurações mais comuns,
o tamanho do filtro é 2,

00:02:34.570 --> 00:02:35.990
e o stride é 2.

00:02:36.023 --> 00:02:38.480
Isso reduz as dimensões X e Y

00:02:38.513 --> 00:02:41.231
pela metade
em relação à camada anterior.

00:02:41.264 --> 00:02:44.732
Assim, a combinação das camadas
convolucionais com as max pooling

00:02:44.765 --> 00:02:47.131
cumpre o nosso objetivo
de gerar um array

00:02:47.164 --> 00:02:50.425
que é bem profundo,
mas pequeno nas dimensões X e Y.

00:02:50.916 --> 00:02:53.604
A seguir falaremos
sobre como conectar o output

00:02:53.637 --> 00:02:55.266
a uma camada
totalmente conectada

00:02:55.299 --> 00:02:57.930
e ver o que acontece
com o input

00:02:57.963 --> 00:02:59.832
quando ele se move
por essas camadas.

