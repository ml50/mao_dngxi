WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.635
CIFAR-10 是一个很热门的数据集 其中包含 60,000 张小图

00:00:04.635 --> 00:00:07.825
共分成 10 个类别 每张图都描绘了一个对象

00:00:07.825 --> 00:00:10.275
可以看出每张图都很小

00:00:10.275 --> 00:00:12.705
宽和高只有 32 个像素

00:00:12.705 --> 00:00:15.690
它们是彩色图像 所以计算机将它们解析为

00:00:15.690 --> 00:00:18.905
深度为 3 的数组 3 表示 RGB 颜色通道

00:00:18.905 --> 00:00:21.820
因为它们是彩色图像并且有很多

00:00:21.820 --> 00:00:25.470
所以首先我将演示如何使用 GPU 训练模型

00:00:25.470 --> 00:00:28.470
GPU 使你能够并行地处理数据

00:00:28.470 --> 00:00:33.150
所以也许能够缩短训练时间

00:00:33.150 --> 00:00:36.350
我在这里照常加载库

00:00:36.350 --> 00:00:40.115
PyTorch 提供了一种检测是否有可用 GPU 设备的方式

00:00:40.115 --> 00:00:43.280
torch.cuda.is_available 将返回布尔值true 或 false

00:00:43.280 --> 00:00:46.985
表示 GPU 设备是否可用

00:00:46.985 --> 00:00:50.630
我们将存储该变量 之后当 GPU 可用时

00:00:50.630 --> 00:00:54.290
我们能够将数据和模型移到该设备上并加快训练

00:00:54.290 --> 00:00:58.190
暂时我将可视化数据并演示该问题 所以我将使用笔记本电脑

00:00:58.190 --> 00:01:02.700
当我运行此单元格时 可以看出我是在 CPU 上训练

00:01:02.700 --> 00:01:06.140
稍后 当我尝试开发解决方案并训练模型时

00:01:06.140 --> 00:01:10.895
我将切换到 GPU 这是通常的做法

00:01:10.895 --> 00:01:13.670
接下来我将照常加载数据

00:01:13.670 --> 00:01:18.390
和 MNIST 很像   CIFAR 也位于 torchvision datasets 库中

00:01:18.390 --> 00:01:22.625
我将通过调用 datasets.CIFAR10 定义训练和测试数据

00:01:22.625 --> 00:01:27.040
此外 将此数据转换为张量数据类型并标准化 RGB 值

00:01:27.040 --> 00:01:31.565
以便像素值的范围是在 0 到 1 之间

00:01:31.565 --> 00:01:37.060
最后 使用 PyTorch 的 DataLoader 类按批次加载转换的数据

00:01:37.060 --> 00:01:39.340
这几行代码应该看起来和 MNIST 代码很像

00:01:39.340 --> 00:01:41.705
我们加载了数据

00:01:41.705 --> 00:01:43.655
转换为张量数据类型

00:01:43.655 --> 00:01:45.600
将数据划分为训练集

00:01:45.600 --> 00:01:47.680
验证集和测试集

00:01:47.680 --> 00:01:51.975
然后在下面指定要读取的 10 个图像类别

00:01:51.975 --> 00:01:55.490
所有 CIFAR-10 图像都将属于其中一个类别

00:01:55.490 --> 00:01:57.850
数据加载可能需要一段时间

00:01:57.850 --> 00:02:00.395
加载之后 你可以可视化一批数据

00:02:00.395 --> 00:02:04.790
我在这里定义了一个辅助函数 它会取消标准化图像

00:02:04.790 --> 00:02:09.505
并将它们从张量图像类型转换为 NumPy 图像类型以进行可视化

00:02:09.505 --> 00:02:12.110
然后加载并显示一批数据

00:02:12.110 --> 00:02:16.715
从这里可以看出图像看起来和我们预期的一样

00:02:16.715 --> 00:02:18.170
这些图像包括猫

00:02:18.170 --> 00:02:21.290
青蛙 小鹿和汽车

00:02:21.290 --> 00:02:24.985
甚至可以更详细地查看图像

00:02:24.985 --> 00:02:27.170
我将一个图像的红绿蓝颜色通道

00:02:27.170 --> 00:02:32.030
显示为灰阶值

00:02:32.030 --> 00:02:34.160
应该会看到最亮的像素值接近 1

00:02:34.160 --> 00:02:37.305
更暗的像素值接近 0

00:02:37.305 --> 00:02:41.745
接下来 你需要定义并训练 CNN 分类这些图像

00:02:41.745 --> 00:02:44.250
你也可以尝试 MLP 方法

00:02:44.250 --> 00:02:46.435
看看二者的效果并加以比较

00:02:46.435 --> 00:02:50.450
假定你想定义 CNN 架构

00:02:50.450 --> 00:02:54.800
我们提供了 PyTorch 卷积层和最大池化层的文档链接

00:02:54.800 --> 00:02:56.630
这个示例图表显示了

00:02:56.630 --> 00:02:59.415
输入图像如何经过这几个层级

00:02:59.415 --> 00:03:00.850
向下滚动

00:03:00.850 --> 00:03:04.340
你会发现我为你定义了一个示例卷积层

00:03:04.340 --> 00:03:06.995
我在网络的 init 函数中定义了该卷积层

00:03:06.995 --> 00:03:09.020
要定义卷积层

00:03:09.020 --> 00:03:12.895
我调用了 nn.Conv2d 并传入一些参数

00:03:12.895 --> 00:03:14.525
对于第一个卷积层

00:03:14.525 --> 00:03:18.290
这个参数将是输入图像的深度

00:03:18.290 --> 00:03:24.415
输入是 32x32 图像 深度是 3 表示 RGB 颜色通道

00:03:24.415 --> 00:03:27.500
所以将该输入设为 3

00:03:27.500 --> 00:03:30.800
并指定输出卷积层的深度应该为 16

00:03:30.800 --> 00:03:35.930
表示该层应该接受输入图像并生成 16 个过滤图像

00:03:35.930 --> 00:03:39.310
同时指定过滤器大小是 3x2

00:03:39.310 --> 00:03:44.050
为了让输出层的 x,y 大小和输入图像的一样

00:03:44.050 --> 00:03:46.650
我将边界填充设为一个像素

00:03:46.650 --> 00:03:49.980
我还定义了一个最大池化层 称为 pool

00:03:49.980 --> 00:03:53.990
核大小和步长为 2

00:03:53.990 --> 00:03:58.510
表示会将任何输入的 x,y 维度下采样到一半大小

00:03:58.510 --> 00:03:59.640
然后在 forward 函数中

00:03:59.640 --> 00:04:02.000
将所有这一切组合到一起

00:04:02.000 --> 00:04:03.885
对于输入图像 x

00:04:03.885 --> 00:04:05.080
首先将其传入第一个卷积层

00:04:05.080 --> 00:04:09.300
并应用 ReLu 激活函数

00:04:09.300 --> 00:04:12.710
将这个输出传入最后的池化层

00:04:12.710 --> 00:04:15.900
生成并返回被下采样的转换后 x

00:04:15.900 --> 00:04:16.930
要完成此模型

00:04:16.930 --> 00:04:21.020
你需要添加多个卷积层和池化层

00:04:21.020 --> 00:04:23.390
最后扁平化并应用一个全连接层

00:04:23.390 --> 00:04:26.285
从而生成所需数量的类别分数

00:04:26.285 --> 00:04:28.265
定义完整的 CNN 后

00:04:28.265 --> 00:04:31.840
你可以实例化该模型 如果有 GPU 的话 甚至可以移到 GPU 上

00:04:31.840 --> 00:04:35.090
接下来你需要为此训练任务

00:04:35.090 --> 00:04:38.440
定义合适的损失和优化函数

00:04:38.440 --> 00:04:40.350
最后我为你提供了训练循环

00:04:40.350 --> 00:04:44.135
你可能需要增加最终模型的训练周期数

00:04:44.135 --> 00:04:47.950
但是这个循环会跟踪训练和验证损失

00:04:47.950 --> 00:04:50.660
如果验证损失在某个周期后降低了

00:04:50.660 --> 00:04:52.100
模型将保存

00:04:52.100 --> 00:04:54.650
然后你将能够测试训练过的模型

00:04:54.650 --> 00:04:57.470
看看它在每种测试图像上表现如何

00:04:57.470 --> 00:05:02.030
最大的挑战是定义完整的 CNN

00:05:02.030 --> 00:05:03.650
像往常一样 我建议你在定义模型之前先查阅资料

00:05:03.650 --> 00:05:06.695
再做出正确的决策

00:05:06.695 --> 00:05:09.710
请尝试自己完成这道练习

00:05:09.710 --> 00:05:12.800
接下来我将介绍一种可能的解决方案供你参考

