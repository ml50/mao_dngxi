WEBVTT
Kind: captions
Language: pt-BR

00:00:00.167 --> 00:00:03.967
Quando construímos um algoritmo
para classificar objetos em imagens,

00:00:04.004 --> 00:00:08.067
há muitas informações
irrelevantes.

00:00:08.100 --> 00:00:10.767
Nós queremos
que o algoritmo determine

00:00:10.800 --> 00:00:13.934
se um objeto está presente
na imagem ou não.

00:00:13.967 --> 00:00:16.434
O tamanho do objeto
não importa,

00:00:16.467 --> 00:00:17.867
nem o ângulo,

00:00:17.900 --> 00:00:21.100
nem se eu o mover
para a direita da imagem.

00:00:21.134 --> 00:00:24.067
Isso continuará sendo
uma imagem com um abacate.

00:00:24.100 --> 00:00:27.734
Nós queremos
que o algoritmo aprenda

00:00:27.767 --> 00:00:31.600
uma representação invariante
da imagem.

00:00:31.634 --> 00:00:34.400
Nós não queremos que o modelo
altere a previsão

00:00:34.434 --> 00:00:36.800
baseado no tamanho do objeto.

00:00:36.834 --> 00:00:39.667
Isso é chamado
de "invariância de escala".

00:00:39.700 --> 00:00:43.530
Também não queremos que o ângulo
do objeto seja relevante.

00:00:43.767 --> 00:00:46.600
Isso é chamado
de "invariância de rotação".

00:00:46.634 --> 00:00:48.967
Se eu mover a imagem
para a esquerda

00:00:49.000 --> 00:00:50.500
ou para a direita,

00:00:50.534 --> 00:00:53.234
ela continuará sendo
a imagem de um abacate.

00:00:53.267 --> 00:00:56.634
Isso é chamado
de "invariância de tradução".

00:00:56.667 --> 00:00:59.600
As CNNs já possuem algumas

00:00:59.634 --> 00:01:02.434
invariâncias de tradução.

00:01:02.467 --> 00:01:05.667
Para ver isso, precisaremos
nos lembrar de como calculamos

00:01:05.700 --> 00:01:07.400
as camadas max pooling.

00:01:07.434 --> 00:01:09.700
Na localização de cada janela,

00:01:09.734 --> 00:01:13.700
pegamos o maior pixel
de uma janela.

00:01:13.734 --> 00:01:17.767
Esse valor máximo pode ocorrer
em qualquer lugar da janela.

00:01:17.800 --> 00:01:21.134
O valor do nó max pooling
será o mesmo.

00:01:21.167 --> 00:01:23.900
Podemos traduzir a imagem
um pouco para a esquerda,

00:01:23.934 --> 00:01:26.834
para a direita,
para cima ou para baixo,

00:01:26.867 --> 00:01:30.634
desde que o valor máximo
fique dentro da janela.

00:01:30.667 --> 00:01:34.534
Aplicando muitas camadas
max pooling em uma sequência,

00:01:34.567 --> 00:01:37.634
cada uma seguida
de uma camada convolucional,

00:01:37.667 --> 00:01:40.734
podemos traduzir o objeto
que estiver à esquerda,

00:01:40.767 --> 00:01:43.467
em cima da imagem
ou embaixo da imagem

00:01:43.500 --> 00:01:47.134
e, ainda assim, a rede
conseguirá compreendê-lo.

00:01:47.167 --> 00:01:50.067
Esse é um problema
não trivial.

00:01:50.100 --> 00:01:54.067
O computador só vê
a matriz dos pixels.

00:01:54.100 --> 00:01:56.500
Transformar a escala,
a rotação

00:01:56.534 --> 00:01:58.534
ou a posição
de um objeto na imagem

00:01:58.567 --> 00:02:01.167
afetará muito
os valores dos pixels.

00:02:01.200 --> 00:02:05.634
Nós podemos ver
a diferença nas imagens,

00:02:05.667 --> 00:02:10.400
mas como você se sairia
se tivesse um arranjo numérico?

00:02:10.434 --> 00:02:12.500
Felizmente há uma boa técnica

00:02:12.534 --> 00:02:16.700
que torna os algoritmos
estatisticamente invariantes,

00:02:16.734 --> 00:02:20.134
mas isso soaria como trapaça.

00:02:20.167 --> 00:02:22.167
A ideia é a seguinte:

00:02:22.200 --> 00:02:26.067
se quisermos que a CNN
seja invariante de rotação,

00:02:26.100 --> 00:02:29.367
adicionamos imagens
ao conjunto de treinamento,

00:02:29.400 --> 00:02:33.467
fazendo rotações aleatórias
nas imagens de treinamento.

00:02:33.500 --> 00:02:35.967
Se quisermos mais
invariâncias de tradução,

00:02:36.000 --> 00:02:38.600
adicionamos mais imagens,

00:02:38.634 --> 00:02:43.267
criando traduções aleatórias
das imagens de treinamento.

00:02:43.300 --> 00:02:46.767
Assim expandimos
o conjunto de treinamento

00:02:46.800 --> 00:02:49.100
aumentando os dados.

00:02:49.134 --> 00:02:53.867
O aumento de dados ajuda
a evitar sobreajuste.

00:02:53.900 --> 00:02:57.734
Isso é porque o modelo vê
muitas imagens novas,

00:02:57.767 --> 00:03:00.500
assim,
ele generalizará melhor,

00:03:00.534 --> 00:03:04.501
e teremos melhor desempenho
no conjunto de dados de teste.

00:03:04.534 --> 00:03:06.434
Vamos aumentar
os dados de treinamento

00:03:06.467 --> 00:03:09.799
para vermos se os dez conjuntos
de treinamento do vídeo anterior

00:03:09.832 --> 00:03:12.767
podem melhorar
a precisão de teste.

00:03:12.800 --> 00:03:16.934
Usaremos o notebook Jupyter,
que pode ser baixado abaixo.

