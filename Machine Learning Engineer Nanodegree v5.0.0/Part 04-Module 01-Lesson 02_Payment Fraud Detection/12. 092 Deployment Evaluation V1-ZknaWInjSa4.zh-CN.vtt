WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.569
使用特殊格式的训练数据训练了 estimator 后

00:00:03.569 --> 00:00:07.605
下一步是部署模型来创建线性预测器

00:00:07.605 --> 00:00:09.540
只需传入关于

00:00:09.539 --> 00:00:12.854
要部署的实例类型的信息

00:00:12.855 --> 00:00:15.705
我将使用 t2.medium 实例

00:00:15.705 --> 00:00:17.969
这个默认实例对于这些练习

00:00:17.969 --> 00:00:20.789
以及一般的开发环境来说足够了

00:00:20.789 --> 00:00:22.710
大约 7 分钟后

00:00:22.710 --> 00:00:27.464
调用 deploy 将创建模型和具有某个名称的端点

00:00:27.464 --> 00:00:31.829
我可以使用该预测器端点对测试数据进行预测

00:00:31.829 --> 00:00:33.585
先简单测试下

00:00:33.585 --> 00:00:37.259
看看这里的预测器信息

00:00:37.259 --> 00:00:41.625
可以看出 LinearLeanerPredictor 需要一个 numpy ndarry 作为输入

00:00:41.625 --> 00:00:44.174
并返回 record 对象列表

00:00:44.174 --> 00:00:47.239
输入数组中的每个数据点对应一条记录

00:00:47.240 --> 00:00:50.900
在这里将测试特征转换成 numpy 数组

00:00:50.899 --> 00:00:53.000
我将传入第一行数据

00:00:53.000 --> 00:00:55.534
看看线性预测器会返回什么

00:00:55.534 --> 00:00:57.529
对于这一个数据点

00:00:57.530 --> 00:00:59.000
返回了预测标签

00:00:59.000 --> 00:01:01.884
值存储为 float32_tensor.

00:01:01.884 --> 00:01:03.679
标签为 0

00:01:03.679 --> 00:01:06.260
对应于有效交易

00:01:06.260 --> 00:01:08.060
除了预测的标签之外

00:01:08.060 --> 00:01:12.150
还可以查看这个分数 它可以告诉我更精确的值

00:01:12.150 --> 00:01:15.890
分数会四舍五入为预测标签

00:01:15.890 --> 00:01:20.079
所以分数可以更清晰地告诉我模型在预测标签时的自信程度

00:01:20.079 --> 00:01:23.420
在此例中 很接近 0 的值表示模型

00:01:23.420 --> 00:01:27.094
非常确信传入的数据点的确是有效交易

00:01:27.094 --> 00:01:29.599
接近 0.05 的更高值表示

00:01:29.599 --> 00:01:32.375
模型在预测时不确定性很大

00:01:32.375 --> 00:01:34.819
根据我对这个记录格式的了解

00:01:34.819 --> 00:01:36.569
我在下面创建了辅助函数

00:01:36.569 --> 00:01:39.214
evaluate 的参数包括部署的预测器

00:01:39.215 --> 00:01:41.105
测试特征和标签

00:01:41.105 --> 00:01:43.670
然后返回各种指标

00:01:43.670 --> 00:01:46.310
第一行代码

00:01:46.310 --> 00:01:49.475
会将测试数据分成批次 因为数据很多

00:01:49.474 --> 00:01:53.765
通过调用 predictor.predict(batch) 获得每个批次的预测

00:01:53.765 --> 00:01:56.484
这些批次每个有 100 个以上的数据点

00:01:56.484 --> 00:01:59.174
对于 prediction_batches 中的每个批次

00:01:59.174 --> 00:02:01.715
我将获得该批次中每个数据点的指针

00:02:01.715 --> 00:02:04.579
并通过调用 x.label 获得预测的标签

00:02:04.579 --> 00:02:08.530
然后将所有这些结果连接到一切 获得测试预测

00:02:08.530 --> 00:02:11.120
最后比较生成的测试预测

00:02:11.120 --> 00:02:14.645
与真实类别标签

00:02:14.645 --> 00:02:17.015
计算真正例 假正例

00:02:17.014 --> 00:02:20.254
真负例和假负例的数量

00:02:20.254 --> 00:02:21.769
然后根据这些数量

00:02:21.770 --> 00:02:25.640
计算测试数据的二元分类指标

00:02:25.639 --> 00:02:27.829
包括召回率 精确率和总准确率

00:02:27.830 --> 00:02:29.365
这里有个 verbose 参数

00:02:29.365 --> 00:02:33.200
默认设为 true 这时候将输出所有这三个指标

00:02:33.199 --> 00:02:37.414
接下来运行此代码 看看线性预测器的效果

00:02:37.414 --> 00:02:38.974
传入预测器

00:02:38.974 --> 00:02:43.460
特殊格式的测试特征和测试标签 并将 verbose 设为 true

00:02:43.460 --> 00:02:46.320
表示输出我感兴趣的指标

00:02:46.319 --> 00:02:48.469
运行此代码后 首先看到

00:02:48.469 --> 00:02:52.025
准确率非常高 达到 99.9%

00:02:52.025 --> 00:02:53.780
看看这个表格数据

00:02:53.780 --> 00:02:56.794
行表示真实标签

00:02:56.794 --> 00:02:59.274
0 表示有效交易 1 表示欺诈性交易

00:02:59.275 --> 00:03:02.060
列是预测标签

00:03:02.060 --> 00:03:05.030
这个值表示正确分类为有效交易的

00:03:05.030 --> 00:03:07.985
测试数据点的数量

00:03:07.985 --> 00:03:10.865
这个值表示正确分类为欺诈性交易的数量

00:03:10.865 --> 00:03:15.560
但是还看到有 33 个真实有效交易

00:03:15.560 --> 00:03:21.080
被错误地分类成欺诈性交易

00:03:21.080 --> 00:03:23.725
在欺诈性交易中 有32 个错误地分类成有效交易

00:03:23.724 --> 00:03:26.150
所以召回率和精确率的值

00:03:26.150 --> 00:03:28.760
比准确率的值低了很多

00:03:28.759 --> 00:03:30.620
即使准确率很高

00:03:30.620 --> 00:03:32.664
模型依然有改进的空间

00:03:32.664 --> 00:03:35.179
现在我已经评估完模型

00:03:35.180 --> 00:03:38.645
养成良好习惯 在评估完后始终记得删除端点

00:03:38.645 --> 00:03:41.030
在这里有个辅助函数

00:03:41.030 --> 00:03:44.110
它将接受预测器的端点并根据名称删除端点

00:03:44.110 --> 00:03:47.590
在这里调用该辅助函数 应该会看到端点删除了

00:03:47.590 --> 00:03:50.868
接下来 我们将讨论如何改进此模型

00:03:50.868 --> 00:03:53.675
包括解决训练集的类别不平衡性问题

00:03:53.675 --> 00:03:57.930
并根据开发目标优化此模型

