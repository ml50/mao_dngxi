WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.560
我们加载了数据

00:00:01.560 --> 00:00:05.790
这是第一个任务“计算欺诈性数据的百分比”的实现方式

00:00:05.790 --> 00:00:08.384
首先从 transaction_df 中

00:00:08.384 --> 00:00:14.054
使用 .value_counts 计算每个类别中的数据点出现次数

00:00:14.054 --> 00:00:15.990
返回一个计数数组

00:00:15.990 --> 00:00:20.579
可以从 counts[1] 获得欺诈性数据点计数 并从 counts[0] 获得有效性数据点计数

00:00:20.579 --> 00:00:22.274
欺诈性数据的百分比等于

00:00:22.274 --> 00:00:25.515
欺诈性计数除以总计数

00:00:25.515 --> 00:00:29.580
然后返回 fraudulent_percentage

00:00:29.579 --> 00:00:33.299
可以看出 在约 285,000 个数据点中

00:00:33.299 --> 00:00:38.924
有约 500 个欺诈性数据点 百分比约为 0.17%

00:00:38.924 --> 00:00:42.184
甚至不到 1%

00:00:42.185 --> 00:00:44.240
一方面 对于此人来说 这是好事

00:00:44.240 --> 00:00:48.365
我们不希望他多次遇到欺诈性交易

00:00:48.365 --> 00:00:50.995
但是对于机器学习来说就比较麻烦

00:00:50.994 --> 00:00:53.224
很多算法认为

00:00:53.225 --> 00:00:56.300
我们的数据在各个类别之间的分布是相对均匀的

00:00:56.299 --> 00:01:00.229
稍后我们将介绍如何处理这种类别不平衡性

00:01:00.229 --> 00:01:05.959
接着将此数据拆分为训练集和测试集 之后使用测试集评估模型

00:01:05.959 --> 00:01:10.369
下面说说我是如何根据传入的 train_frac 拆分数据的

00:01:10.370 --> 00:01:13.520
首先获取交易数据 dataframe

00:01:13.519 --> 00:01:17.685
并通过 df.as_matrix 将数据转换为矩阵

00:01:17.685 --> 00:01:22.310
这样便于使用 Numpy 函数随机重排和拆分数据

00:01:22.310 --> 00:01:25.189
接着 根据传入的随机 seed

00:01:25.189 --> 00:01:28.390
随机重排该矩阵中的所有数据

00:01:28.390 --> 00:01:30.445
设置 train_size

00:01:30.444 --> 00:01:32.750
表示训练数据的量

00:01:32.750 --> 00:01:35.129
等于矩阵中的行数乘以

00:01:35.129 --> 00:01:38.134
传入的 train_frac

00:01:38.135 --> 00:01:40.310
这个分数是一个小数值

00:01:40.310 --> 00:01:43.040
需要转型为整型

00:01:43.040 --> 00:01:46.280
因为我们的数据是离散的

00:01:46.280 --> 00:01:48.454
不能有一半的数据点

00:01:48.454 --> 00:01:50.000
它会向下舍入任何浮点值

00:01:50.000 --> 00:01:53.890
对于拆分数据来说 这么做没问题

00:01:53.890 --> 00:01:56.070
train_size 将为

00:01:56.069 --> 00:01:58.609
拆分矩阵数据的索引位置

00:01:58.609 --> 00:02:03.265
训练特征为直到索引 train_size 前的特征

00:02:03.265 --> 00:02:06.515
我知道类别标签在 dataframe 的最后一列

00:02:06.515 --> 00:02:09.800
-1 表示不包含

00:02:09.800 --> 00:02:11.135
最后一列

00:02:11.134 --> 00:02:15.324
然后在这里将最后一个值保存为类别标签

00:02:15.324 --> 00:02:18.919
测试特征和标签也相似

00:02:18.919 --> 00:02:20.780
获取剩余的数据行

00:02:20.780 --> 00:02:24.020
注意 这里是 train_size 在冒号前面

00:02:24.020 --> 00:02:25.370
这里是在冒号后面

00:02:25.370 --> 00:02:27.640
然后在这里获取最后的测试标签列

00:02:27.639 --> 00:02:31.625
最后 以特定的返回顺序返回这些值

00:02:31.625 --> 00:02:33.185
训练特征和标签

00:02:33.185 --> 00:02:36.395
然后是测试特征和标签 它们是单独的元组

00:02:36.395 --> 00:02:38.255
这样就完成了这个函数

00:02:38.254 --> 00:02:42.680
在下个单元格中调用该函数并测试形状

00:02:42.680 --> 00:02:45.040
拆分比例是默认的 7:3 比例

00:02:45.039 --> 00:02:48.409
70% 是训练数据 30% 是测试数据

00:02:48.409 --> 00:02:51.770
下面有几个测试部分 检查每个特征的形状是否正确

00:02:51.770 --> 00:02:55.760
以及标签是否的确为 0 和 1

00:02:55.759 --> 00:02:58.798
这个单元格会输出训练数据点的数量

00:02:58.799 --> 00:03:01.900
约为 200,000 然后是测试数据点的数量

00:03:01.900 --> 00:03:03.965
然后测试下第一项及其标签

00:03:03.965 --> 00:03:08.335
第一项应该有 30 个特征 并且有一个类别标签

00:03:08.335 --> 00:03:10.790
0 表示有效交易

00:03:10.789 --> 00:03:13.729
我们已经有了训练数据和测试数据

00:03:13.729 --> 00:03:16.144
这些数据差不多可以传入模型中了

00:03:16.145 --> 00:03:21.060
接下来 我将介绍如何构建和训练二元分类模型

