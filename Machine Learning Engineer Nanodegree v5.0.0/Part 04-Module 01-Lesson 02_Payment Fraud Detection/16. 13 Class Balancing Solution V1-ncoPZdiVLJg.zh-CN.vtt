WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.870
对于二元分类器训练过程中出现的类别不平衡性问题

00:00:03.870 --> 00:00:08.414
LinearLearner 提供了超参数 positive_example_weight_mult

00:00:08.414 --> 00:00:09.689
它表示在训练二元分类器时

00:00:09.689 --> 00:00:13.679
分配给正样本或欺诈性样本的权重

00:00:13.679 --> 00:00:17.759
负样本或有效数据的权重固定为 1

00:00:17.760 --> 00:00:20.429
该超参数的文档中指出

00:00:20.429 --> 00:00:22.800
“如果你希望算法选择一个权重

00:00:22.800 --> 00:00:25.230
使分类负样本与正样本的误差

00:00:25.230 --> 00:00:30.300
对训练损失的影响一样 则指定 balanced”

00:00:30.300 --> 00:00:33.270
我在这个单元格中像之前一样定义了平衡 estimator

00:00:33.270 --> 00:00:37.615
周期数和召回率优化参数与之前的一样

00:00:37.615 --> 00:00:39.980
不过还添加了一个超参数

00:00:39.979 --> 00:00:42.984
将 positive_example_weight_mult 设为 balanced

00:00:42.984 --> 00:00:47.079
然后像之前一样 训练并部署平衡 estimator

00:00:47.079 --> 00:00:48.649
创建一个平衡预测器

00:00:48.649 --> 00:00:51.214
然后像之前一样运行评估代码

00:00:51.215 --> 00:00:53.105
传入平衡预测器

00:00:53.104 --> 00:00:55.414
测试特征和测试标签

00:00:55.414 --> 00:00:59.450
可以看到召回率很高 并且精确率比上次高

00:00:59.450 --> 00:01:01.520
实际上 看看上次的指标后

00:01:01.520 --> 00:01:04.370
会发现我们将超过 3,000 个有效样本

00:01:04.370 --> 00:01:07.450
错误地分类成了欺诈性样本 所以精确率很低

00:01:07.450 --> 00:01:09.189
在这个平衡示例中

00:01:09.189 --> 00:01:13.340
我们将分类错误的样本数至少减少了 3 倍

00:01:13.340 --> 00:01:16.659
评估完这个优化过及平衡过的模型后

00:01:16.659 --> 00:01:18.334
删除端点

00:01:18.334 --> 00:01:20.569
注意 我们在训练时

00:01:20.569 --> 00:01:24.244
将召回率固定成了 0.9 即 90%

00:01:24.245 --> 00:01:28.579
但是当模型应用到测试数据上后 这个值可能会变化

00:01:28.579 --> 00:01:30.965
在实际任务中 经常你需要

00:01:30.965 --> 00:01:35.450
使用不平衡的流式数据 并根据特定指标判断模型的性能

00:01:35.450 --> 00:01:38.299
所以 知道如何根据特定指标优化模型

00:01:38.299 --> 00:01:41.899
并为训练模型平衡类别权重是很重要的技能

00:01:41.900 --> 00:01:43.385
接下来

00:01:43.385 --> 00:01:46.100
我将布置一个不同的任务 让你有机会练习所学的知识

00:01:46.099 --> 00:01:49.909
我发现实验和调整参数是很好的实践机会

00:01:49.909 --> 00:01:53.674
可以更直观地掌握建模技巧

00:01:53.674 --> 00:01:55.879
请尝试优化和平衡你设计的参数

00:01:55.879 --> 00:01:59.399
然后看看效果如何

