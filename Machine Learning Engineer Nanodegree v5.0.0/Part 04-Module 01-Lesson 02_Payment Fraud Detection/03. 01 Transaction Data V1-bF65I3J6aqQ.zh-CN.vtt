WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.609
这节课的所有练习都位于

00:00:02.609 --> 00:00:05.279
我们之前创建的 ML-case-studies Notebook 中

00:00:05.280 --> 00:00:08.630
在 Jupyter 中打开此 Notebook

00:00:08.630 --> 00:00:11.130
转到 Payment_Fraud_Detection 目录

00:00:11.130 --> 00:00:13.530
并打开 Fraud_Detection_Exercise Notebook

00:00:13.529 --> 00:00:15.794
对于欺诈检测任务

00:00:15.794 --> 00:00:19.184
我们将查看来自 Kaggle 的信用卡数据

00:00:19.184 --> 00:00:21.824
这个数据集包含成千上万的交易条目

00:00:21.824 --> 00:00:25.484
其中包含匿名特征和类别标签“欺诈性”或“有效性”

00:00:25.484 --> 00:00:27.975
我们将遵循典型的机器学习工作流程

00:00:27.975 --> 00:00:29.865
首先加载和探索数据

00:00:29.864 --> 00:00:34.034
然后拆分数据并传递给二元分类模型

00:00:34.034 --> 00:00:36.584
在此 notebook 中 我们首先将使用 SageMaker 的

00:00:36.585 --> 00:00:40.155
LinearLearner 训练和部署内置线性模型

00:00:40.155 --> 00:00:42.980
我们还会讨论欺诈检测面临的独特挑战性

00:00:42.979 --> 00:00:45.709
例如训练数据不平衡

00:00:45.710 --> 00:00:49.310
即有效交易的历史记录比欺诈性交易的要多

00:00:49.310 --> 00:00:51.905
这个 Notebook 的很大一部分内容是讨论

00:00:51.905 --> 00:00:55.030
如何根据数据或设计挑战改进模型

00:00:55.030 --> 00:00:57.380
并且我们将通过各种指标

00:00:57.380 --> 00:00:59.929
评估训练的模型

00:00:59.929 --> 00:01:03.189
这些指标不仅包括准确率 还有精确率和召回率好的

00:01:03.189 --> 00:01:06.230
在第一个单元格中正常加载资源

00:01:06.230 --> 00:01:09.180
在下个单元格中设置 SageMaker 变量

00:01:09.180 --> 00:01:11.820
包括 SageMaker 会话和角色

00:01:11.819 --> 00:01:15.229
这些变量定义了模型的训练方式和默认存储桶

00:01:15.230 --> 00:01:17.135
我们将在 S3 存储桶里

00:01:17.135 --> 00:01:20.109
存储训练数据以及保存的模型参数

00:01:20.109 --> 00:01:22.185
获得 SageMaker 资源后

00:01:22.185 --> 00:01:24.665
从网上加载数据

00:01:24.665 --> 00:01:28.670
从这个链接可以下载 creditcardfraud.zip 文件 解压缩该文件

00:01:28.670 --> 00:01:32.640
只需运行这个单元格一次 即可获得 creditcard.csv 文件

00:01:32.640 --> 00:01:37.069
然后将数据读取为 dataframe 并输出数据的形状

00:01:37.069 --> 00:01:40.309
可以看到 我们有约 28.5 万个数据点

00:01:40.310 --> 00:01:41.975
从前几行数据可以看到

00:01:41.974 --> 00:01:43.894
这些数据包含的特征

00:01:43.894 --> 00:01:45.810
包括从第一个交易开始的

00:01:45.810 --> 00:01:47.350
交易时间

00:01:47.349 --> 00:01:51.559
以及从 V1 到 V28 的匿名特征

00:01:51.560 --> 00:01:55.579
最后是交易额和类别标签

00:01:55.579 --> 00:01:59.614
总体来说 有 30 个输入特征和一个类别

00:01:59.614 --> 00:02:02.509
0 表示有效 所有这些数据点都是有效交易

00:02:02.510 --> 00:02:05.260
1 表示欺诈性交易

00:02:05.260 --> 00:02:08.210
这些匿名特征并不能提供太多信息

00:02:08.210 --> 00:02:11.855
但是可以查看每个类别的数据分布情况

00:02:11.854 --> 00:02:15.875
你的第一个任务是完成函数 fraudulent_percentage

00:02:15.875 --> 00:02:19.159
这个函数的参数是刚刚加载的 transaction_df

00:02:19.159 --> 00:02:23.210
它应该返回标为欺诈性的数据所占百分比

00:02:23.210 --> 00:02:25.745
我在下面提供了测试单元格

00:02:25.745 --> 00:02:28.795
当你实现完这个函数后 可以测试一下

00:02:28.794 --> 00:02:33.155
下一步是使用这些数据训练模型

00:02:33.155 --> 00:02:34.400
知道目标后

00:02:34.400 --> 00:02:36.200
再布置第二个任务

00:02:36.199 --> 00:02:38.944
请将这些数据划分为训练集和测试集

00:02:38.944 --> 00:02:41.814
即完成函数 train_test_split

00:02:41.814 --> 00:02:44.044
这个函数的参数也包括 transaction_df

00:02:44.044 --> 00:02:46.609
第二个参数是训练数据的比例

00:02:46.610 --> 00:02:48.710
剩下的是测试数据

00:02:48.710 --> 00:02:51.560
默认值 0.7 表示

00:02:51.560 --> 00:02:54.485
70% 用作训练数据

00:02:54.485 --> 00:02:56.990
30% 用作测试数据

00:02:56.990 --> 00:02:59.689
请计算欺诈性数据的百分比

00:02:59.689 --> 00:03:02.629
然后完成此函数以拆分数据

00:03:02.629 --> 00:03:04.680
我在 Notebook 中提供了一些指导说明

00:03:04.680 --> 00:03:06.830
如果你遇到问题或者想要检查你的代码

00:03:06.830 --> 00:03:09.510
请观看下个解答视频

